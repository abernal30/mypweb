<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>6 Credit analysis | Algorithms and Financial Programming in R</title>
<meta name="author" content="Arturo Bernal">
<meta name="description" content="In this chapter we will use the following libraries: library(openxlsx) library(caret) library(MASS) In this chapter, we will cover credit allocation analysis (loan origination). The database...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="6 Credit analysis | Algorithms and Financial Programming in R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://www.arturo-bernal.com/book/credit-analysis.html">
<meta property="og:image" content="https://www.arturo-bernal.com/book/images/coverf.png">
<meta property="og:description" content="In this chapter we will use the following libraries: library(openxlsx) library(caret) library(MASS) In this chapter, we will cover credit allocation analysis (loan origination). The database...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="6 Credit analysis | Algorithms and Financial Programming in R">
<meta name="twitter:description" content="In this chapter we will use the following libraries: library(openxlsx) library(caret) library(MASS) In this chapter, we will cover credit allocation analysis (loan origination). The database...">
<meta name="twitter:image" content="https://www.arturo-bernal.com/book/images/coverf.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Roboto-0.4.2/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-68765210-2', 'auto');
      ga('send', 'pageview');

    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Algorithms and Financial Programming in R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Algorithms and Financial Programming in R</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="r-basics.html"><span class="header-section-number">1</span> R Basics</a></li>
<li><a class="" href="clean.html"><span class="header-section-number">2</span> Big data and data cleaning with datapro</a></li>
<li><a class="" href="graphs.html"><span class="header-section-number">3</span> APIS and R graphs</a></li>
<li><a class="" href="logit.html"><span class="header-section-number">4</span> Machine learning with market direction prediction: Logit</a></li>
<li><a class="" href="big-data-and-machine-learning.html"><span class="header-section-number">5</span> Big data and machine learning</a></li>
<li><a class="active" href="credit-analysis.html"><span class="header-section-number">6</span> Credit analysis</a></li>
<li><a class="" href="rational-agent-and-behavioral-finance-in-investment.html"><span class="header-section-number">7</span> Rational agent and behavioral finance in investment</a></li>
<li><a class="" href="applied-market-anomalies.-momentum-market-anomalies.html"><span class="header-section-number">8</span> Applied market anomalies. Momentum market anomalies</a></li>
<li><a class="" href="portfolio-management-algorithms.html"><span class="header-section-number">9</span> Portfolio management algorithms</a></li>
<li><a class="" href="references.html"><span class="header-section-number">10</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/abernal30/BookAFP">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="credit-analysis" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Credit analysis<a class="anchor" aria-label="anchor" href="#credit-analysis"><i class="fas fa-link"></i></a>
</h1>
<p>In this chapter we will use the following libraries:</p>
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ycphs.github.io/openxlsx/index.html">openxlsx</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span></span></code></pre></div>
<p>In this chapter, we will cover credit allocation analysis (loan origination). The database credit.xlsx has historical information
on Lendingclub, <a href="https://www.lendingclub.com/" class="uri">https://www.lendingclub.com/</a> fintech marketplace bank
at scale. On the spreadsheets, you will find the variable description.
The original data set has at least 2 million observations and 150
variables. Inside the file “credit.xlsx,” you will find only 873
observations (rows) and 71 columns. Each row represents a
Lendingclub client. We previously made the data cleaning (missing
values, correlated variables, Zero- and Near Zero-Variance Predictors).
To know more about data cleaning, see the 2nd chapter of this book.</p>
<p>In the next output, we see the variables of Lendingclub’s customers when
they granted the loan. For example, the variable term is the term, in
years, of the loan, “annual_inc,” which is the customer’s annual income
when she got the loan.</p>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"https://raw.githubusercontent.com/abernal30/BookAFP/main/data/credit.csv"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">data</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    873 obs. of  10 variables:</span></span>
<span><span class="co">#&gt;  $ Default            : chr  "Fully Paid" "Fully Paid" "Fully Paid" "Fully Paid" ...</span></span>
<span><span class="co">#&gt;  $ term               : int  1 1 2 2 1 1 1 1 1 1 ...</span></span>
<span><span class="co">#&gt;  $ installment        : num  123 820 433 290 405 ...</span></span>
<span><span class="co">#&gt;  $ grade              : int  3 3 2 6 3 2 2 1 2 3 ...</span></span>
<span><span class="co">#&gt;  $ emp_title          : num  299 209 623 126 633 636 481 540 631 314 ...</span></span>
<span><span class="co">#&gt;  $ emp_length         : int  3 3 3 5 6 3 3 8 3 5 ...</span></span>
<span><span class="co">#&gt;  $ home_ownership     : int  1 1 1 1 3 1 1 3 1 1 ...</span></span>
<span><span class="co">#&gt;  $ annual_inc         : num  55000 65000 63000 104433 34000 ...</span></span>
<span><span class="co">#&gt;  $ verification_status: int  1 1 1 2 2 1 1 1 1 1 ...</span></span>
<span><span class="co">#&gt;  $ purpose            : int  3 10 4 6 3 3 6 2 2 9 ...</span></span></code></pre></div>
<p>The variable “Default”, winch originally has the name “loan_status”, it
has two labels:</p>
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">data</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Charged Off  Fully Paid </span></span>
<span><span class="co">#&gt;         145         728</span></span></code></pre></div>
<p>“Charge off” means that the credit grantor wrote your account off of
their receivables as a loss and is closed to future charges. When an
account displays a status of “charge off,” it is closed to future use,
although the customer still owns the debt. For this example, we will
consider Charged Off equivalent to Default and Fully Paid as no default.</p>
<p>In a previous output, we show that the “Default” variable class is
“character,” and a function we will apply below does only accept numeric
or factor variables. We transform that variable into “factor.”</p>
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">data</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<div id="prediction-with-the-logit-model" class="section level3" number="6.0.1">
<h3>
<span class="header-section-number">6.0.1</span> Prediction with the Logit model<a class="anchor" aria-label="anchor" href="#prediction-with-the-logit-model"><i class="fas fa-link"></i></a>
</h3>
<p>First, we split the data set into training and test, 80% of the training
and 20% of the test data set. For an explanation of this procedure, see
chapter <a href="logit.html#logit">Machine learning with market direction prediction: Logit</a>.</p>
<p>We use the function sample when the data set is not a time series. Which
randomly generates dim[1]*n numbers of the full data set. Where dim[1]
is the number of rows of the full data set, and n is a %, in this case,
80%.</p>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span> <span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">dim</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">train_sample</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">dim</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="va">dim</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">*</span><span class="fl">0.8</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">train_sample</span>, <span class="op">]</span></span>
<span><span class="va">test</span>  <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">train_sample</span>, <span class="op">]</span></span></code></pre></div>
<p>Because the function “sample” generates random numbers, we use
“set.seed” to specify seeds to control the results; in other words, we
will always get the same results, even when we generate random numbers.</p>
<p>We will run the following logit model:</p>
<p><span class="math display">\[Default=\alpha_{0}\ +\beta_{1}\ term_{1}+\beta_{2}\ grade_{2}+...+\beta_{n}\ variable_{n}+e\]</span>
Where <span class="math inline">\(e\)</span> is the error term.</p>
<p>The next code is to run the logit model using the train set:</p>
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="va">term</span><span class="op">+</span><span class="va">grade</span> ,data<span class="op">=</span> <span class="va">train</span> ,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = Default ~ term + grade, family = binomial(), data = train)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Deviance Residuals: </span></span>
<span><span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span></span>
<span><span class="co">#&gt; -2.3183   0.3755   0.4647   0.5723   1.3079  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  3.75411    0.34435  10.902  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; term        -0.69219    0.24816  -2.789  0.00528 ** </span></span>
<span><span class="co">#&gt; grade       -0.44522    0.09073  -4.907 9.25e-07 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 631.12  on 697  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 572.50  on 695  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 578.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></span></code></pre></div>
<p>The next code is to run the logit model with all the variables, using
the train set is:</p>
<p><span class="math display">\[Default=\alpha_{0}\ +\beta\ X+e\]</span> Where <span class="math inline">\(X\)</span> represents all the
variables inside the data bases, except “Default”.</p>
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_all</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span><span class="va">.</span> ,data<span class="op">=</span><span class="va">train</span> ,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The next step is to make the prediction on the test data set, based on
the the “model_all”.</p>
<div class="sourceCode" id="cb133"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">predict</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model_all</span>, newdata <span class="op">=</span> <span class="va">test</span>,type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">predict</span><span class="op">)</span></span>
<span><span class="co">#&gt;           10           18           21           23           24           26 </span></span>
<span><span class="co">#&gt; 1.000000e+00 2.220446e-16 1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00</span></span></code></pre></div>
<p>The “type = response” argument is to transform the results into
probability.</p>
<p>In the previous output, we see that our prediction is not of the type
“Fully Paid” or “Charged Off,” then we transform our forecast in that
categories. We set as threshold 0.5; if our prediction is higher than
0.5, then we transform it into “Fully Paid,” and otherwise “Charged
Off.” It is a common practice if you wonder why our threshold is 0.5.
Still, more importantly, after estimating the prediction accuracy of our
model, we could change this threshold to improve the prediction
performance.</p>
<div class="sourceCode" id="cb134"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">predicf_char</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">predict</span><span class="op">&gt;</span><span class="fl">.5</span>,<span class="st">"Fully Paid"</span>,<span class="st">"Charged Off"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">predicf_char</span><span class="op">)</span></span>
<span><span class="co">#&gt;            10            18            21            23            24 </span></span>
<span><span class="co">#&gt;  "Fully Paid" "Charged Off"  "Fully Paid"  "Fully Paid"  "Fully Paid" </span></span>
<span><span class="co">#&gt;            26 </span></span>
<span><span class="co">#&gt;  "Fully Paid"</span></span></code></pre></div>
</div>
<div id="measuring-model-performance" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Measuring model performance<a class="anchor" aria-label="anchor" href="#measuring-model-performance"><i class="fas fa-link"></i></a>
</h2>
<p>To measure the performance of our prediction, we will use the confusion
Matrix. Before that, we need to transform our prediction into a factor.</p>
<div class="sourceCode" id="cb135"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">predict_factor</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">predicf_char</span><span class="op">)</span></span>
<span><span class="fu">caret</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">predict_factor</span>,<span class="va">test</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span><span class="op">$</span><span class="va">table</span></span>
<span><span class="co">#&gt;              Reference</span></span>
<span><span class="co">#&gt; Prediction    Charged Off Fully Paid</span></span>
<span><span class="co">#&gt;   Charged Off          27          8</span></span>
<span><span class="co">#&gt;   Fully Paid            1        139</span></span></code></pre></div>
<p>The confusion Matrix categorizes our predictions according to whether
they match the actual value. One of the table’s dimensions indicates the
possible categories of predicted values, while the other shows the same
for real (reference) values.</p>
<p>There are other measures that the “confusionMatrix” functions show. For
this chapter, we are only concerned about Accuracy and Sensitivity.</p>
<div class="sourceCode" id="cb136"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">predict_factor</span>,<span class="va">test</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; Confusion Matrix and Statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              Reference</span></span>
<span><span class="co">#&gt; Prediction    Charged Off Fully Paid</span></span>
<span><span class="co">#&gt;   Charged Off          27          8</span></span>
<span><span class="co">#&gt;   Fully Paid            1        139</span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                Accuracy : 0.9486          </span></span>
<span><span class="co">#&gt;                  95% CI : (0.9046, 0.9762)</span></span>
<span><span class="co">#&gt;     No Information Rate : 0.84            </span></span>
<span><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 8.743e-06       </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                   Kappa : 0.8263          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;  Mcnemar's Test P-Value : 0.0455          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;             Sensitivity : 0.9643          </span></span>
<span><span class="co">#&gt;             Specificity : 0.9456          </span></span>
<span><span class="co">#&gt;          Pos Pred Value : 0.7714          </span></span>
<span><span class="co">#&gt;          Neg Pred Value : 0.9929          </span></span>
<span><span class="co">#&gt;              Prevalence : 0.1600          </span></span>
<span><span class="co">#&gt;          Detection Rate : 0.1543          </span></span>
<span><span class="co">#&gt;    Detection Prevalence : 0.2000          </span></span>
<span><span class="co">#&gt;       Balanced Accuracy : 0.9549          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;        'Positive' Class : Charged Off     </span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>The accuracy is, therefore, a proportion representing the number of true
positives and negatives divided by the total number of predictions. In
this case, our mode Accuracy is 0.9485714</p>
<p>The sensitivity of a model (also called the true positive rate) measures
the proportion of positive examples correctly classified. For this
example, at the end of the “confusionMatrix” output we see that the
‘Positive’ Class is “Charged Off”. Our mode Sensitivity is 0.9642857.</p>
</div>
<div id="prediction-with-linear-discriminant-analysis-lda" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Prediction with Linear Discriminant Analysis (LDA)<a class="anchor" aria-label="anchor" href="#prediction-with-linear-discriminant-analysis-lda"><i class="fas fa-link"></i></a>
</h2>
<p>Why do we need another method when we already have the logistic model?
There are several reasons <span class="citation">(<a href="references.html#ref-statistical_lerarning" role="doc-biblioref">James et al. 2017</a>)</span>:</p>
<p>• When the classes are well-separated, the parameter estimates for the
logistic regression model are surprisingly unstable. The linear
Discriminant Analysis method does not suffer from this problem.</p>
<p>• If the number of observations is small and the distribution of the
independent variables is approximately normal in each class, the linear
discriminant model is again more stable than the logistic regression
model.</p>
<p>For this chapter, we will use the LDA model to compare its Accuracy
against the Logit model.</p>
<p>The next code estimates the LDA model and makes the prediction:</p>
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_lda</span><span class="op">&lt;-</span><span class="fu">MASS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MASS/man/lda.html">lda</a></span><span class="op">(</span><span class="va">Default</span><span class="op">~</span><span class="va">.</span>,data<span class="op">=</span><span class="va">train</span><span class="op">)</span></span>
<span><span class="va">pred_lda</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model_lda</span>, newdata <span class="op">=</span> <span class="va">test</span><span class="op">)</span></span></code></pre></div>
<p>The object “pred_lda” is an R-list, which contains the prediction, but
also many other statistics, then to apply the “confusionMatrix” we need
to get the prediction results:</p>
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">pred_lda</span><span class="op">[[</span><span class="st">"class"</span><span class="op">]</span><span class="op">]</span>,<span class="va">test</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; Confusion Matrix and Statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              Reference</span></span>
<span><span class="co">#&gt; Prediction    Charged Off Fully Paid</span></span>
<span><span class="co">#&gt;   Charged Off          24          4</span></span>
<span><span class="co">#&gt;   Fully Paid            4        143</span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                Accuracy : 0.9543          </span></span>
<span><span class="co">#&gt;                  95% CI : (0.9119, 0.9801)</span></span>
<span><span class="co">#&gt;     No Information Rate : 0.84            </span></span>
<span><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 2.372e-06       </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                   Kappa : 0.8299          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;  Mcnemar's Test P-Value : 1               </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;             Sensitivity : 0.8571          </span></span>
<span><span class="co">#&gt;             Specificity : 0.9728          </span></span>
<span><span class="co">#&gt;          Pos Pred Value : 0.8571          </span></span>
<span><span class="co">#&gt;          Neg Pred Value : 0.9728          </span></span>
<span><span class="co">#&gt;              Prevalence : 0.1600          </span></span>
<span><span class="co">#&gt;          Detection Rate : 0.1371          </span></span>
<span><span class="co">#&gt;    Detection Prevalence : 0.1600          </span></span>
<span><span class="co">#&gt;       Balanced Accuracy : 0.9150          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;        'Positive' Class : Charged Off     </span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>The Accuracy of the LDA model is 0.9542857, and its Sensitivity is 0.8571429.</p>
<p>In this case, the LDA Accuracy is higher than the logit model; the
sensitivity is the opposite. Depending on what we are interested in, the
model better predicts performance. In “credit allocation,” we are
usually more concerned with the ‘Positive’ cases, in this case, “Charged
Off,” because of the default risk.</p>
<div id="cross-validation." class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> 3 Cross validation.<a class="anchor" aria-label="anchor" href="#cross-validation."><i class="fas fa-link"></i></a>
</h3>
<p>Cross-validation is a “resampling” method. It involves repeatedly
drawing samples from a training set and refitting a model of interest on each sample to obtain additional information about the model. Such an approach may allow us to get information that would not be available from fitting the model only once using the original training sample.</p>
<p>Instead of dividing the sample only once, this approach involves
randomly k-fold CV splits the set of observations into k groups, or
folds, of approximately equal size.</p>
<p>In other words, this procedure would validate it our Accuracy/sensitivity will be stable when we split the sample in training and test it several times. The Caret function “train” can optimize for Accuracy.</p>
<p>We start by applying it to the logit model:</p>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># similar to the previous models</span></span>
<span><span class="va">gbmFit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/train.html">train</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">train</span>,</span>
<span>                  </span>
<span>                 method <span class="op">=</span> <span class="st">"glm"</span>,</span>
<span>                 </span>
<span><span class="co"># in here we have the tuning parameters, in this case we use the "cv" method for cross, which is the number of times the model split the sample.                   </span></span>
<span>                            trControl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"cv"</span>, number <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,</span>
<span>                        trace<span class="op">=</span><span class="fl">0</span>,   metric<span class="op">=</span><span class="st">"Accuracy"</span><span class="op">)</span></span>
<span><span class="va">gbmFit1</span></span>
<span><span class="co">#&gt; Generalized Linear Model </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 698 samples</span></span>
<span><span class="co">#&gt;  70 predictor</span></span>
<span><span class="co">#&gt;   2 classes: 'Charged Off', 'Fully Paid' </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; No pre-processing</span></span>
<span><span class="co">#&gt; Resampling: Cross-Validated (10 fold) </span></span>
<span><span class="co">#&gt; Summary of sample sizes: 627, 628, 628, 629, 628, 629, ... </span></span>
<span><span class="co">#&gt; Resampling results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   Accuracy   Kappa    </span></span>
<span><span class="co">#&gt;   0.9470376  0.8144761</span></span></code></pre></div>
<p>And for the LDA:</p>
<div class="sourceCode" id="cb140"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># similar to the previous models</span></span>
<span><span class="va">gbmFit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/train.html">train</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">train</span>,</span>
<span>                  </span>
<span>                 method <span class="op">=</span> <span class="st">"lda"</span>,</span>
<span>                 </span>
<span><span class="co"># in here we have the tuning parameters, in this case we use the "cv" method for cross, which is the number of times the model split the sample.                   </span></span>
<span>                            trControl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"cv"</span>, number <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,</span>
<span>                        trace<span class="op">=</span><span class="fl">0</span>,   metric<span class="op">=</span><span class="st">"Accuracy"</span><span class="op">)</span></span>
<span><span class="va">gbmFit1</span></span>
<span><span class="co">#&gt; Linear Discriminant Analysis </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 698 samples</span></span>
<span><span class="co">#&gt;  70 predictor</span></span>
<span><span class="co">#&gt;   2 classes: 'Charged Off', 'Fully Paid' </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; No pre-processing</span></span>
<span><span class="co">#&gt; Resampling: Cross-Validated (10 fold) </span></span>
<span><span class="co">#&gt; Summary of sample sizes: 628, 629, 629, 628, 628, 628, ... </span></span>
<span><span class="co">#&gt; Resampling results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   Accuracy   Kappa    </span></span>
<span><span class="co">#&gt;   0.9527329  0.8275475</span></span></code></pre></div>
<p>Our results are consistent with the previous result; the Accuracy of the
LDA is higher than the Logit one.</p>
<p>To improve the accuracy, we could also apply variable selection methods,
such as glmStepAIC.</p>
<p><strong><em>Warning</em>:</strong> The following code takes 20 minutes to run, depending
on the processor.</p>
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gbmFit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/train.html">train</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">train</span>, method <span class="op">=</span> <span class="st">"glmStepAIC"</span>,</span>
<span>              </span>
<span>                 trControl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"cv"</span>, number <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,</span>
<span>                        trace<span class="op">=</span><span class="fl">0</span>,   metric<span class="op">=</span><span class="st">"Accuracy"</span><span class="op">)</span></span>
<span>    <span class="va">gbmFit1</span></span></code></pre></div>
<pre><code>## Generalized Linear Model with Stepwise Feature Selection
##
## 698 samples 
## 70 predictor 
## 2 classes: 'Charged Off', 'Fully Paid'
##
## No pre-processing Resampling: Cross-Validated (10 fold)
## Summary of sample sizes: 628, 629, 628, 628, 628, 628, ... 
## Resampling results:
##
## Accuracy   Kappa
## 0.9599149 0.8585923</code></pre>
<p>The accuracy of 0.9599 is higher than the Logit model, which includes all variables 0.9470.</p>
<p>To get the final model or the final variables, we apply the following:</p>
<div class="sourceCode" id="cb143"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">step_var</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">gbmFit1</span><span class="op">$</span><span class="va">finalModel</span><span class="op">$</span><span class="va">coefficients</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> </span>
<span><span class="va">step_var</span></span></code></pre></div>
<pre><code>#&gt;  [1] "term"                  "purpose"               "revol_bal"            
#&gt;  [4] "total_rec_int"         "recoveries"            "last_pymnt_amnt"      
#&gt;  [7] "last_fico_range_high"  "open_act_il"           "total_cu_tl"          
#&gt; [10] "num_accts_ever_120_pd" "num_sats"              "num_tl_op_past_12m"   
#&gt; [13] "total_bc_limit"</code></pre>
<p>If we want to use those variables to further improve the model:</p>
<div class="sourceCode" id="cb145"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">train_step</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">train</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span>,<span class="va">train</span><span class="op">[</span>,<span class="va">step_var</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">train_step</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">&lt;-</span><span class="st">"Default"</span></span>
<span><span class="va">test_step</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">test</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span>,<span class="va">test</span><span class="op">[</span>,<span class="va">step_var</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">test_step</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">&lt;-</span><span class="st">"Default"</span></span></code></pre></div>
<p>For example, if we run the LDA model with those variables again:</p>
<div class="sourceCode" id="cb146"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gbmFit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/train.html">train</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">train_step</span>,</span>
<span>                  </span>
<span>                 method <span class="op">=</span> <span class="st">"lda"</span>,</span>
<span>                 </span>
<span><span class="co"># in here we have the tuning parameters, in this case we use the "cv" method for cross, which is the number of times the model split the sample.                   </span></span>
<span>                            trControl <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"cv"</span>, number <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,</span>
<span>                        trace<span class="op">=</span><span class="fl">0</span>,   metric<span class="op">=</span><span class="st">"Accuracy"</span><span class="op">)</span></span>
<span><span class="va">gbmFit1</span></span>
<span><span class="co">#&gt; Linear Discriminant Analysis </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 698 samples</span></span>
<span><span class="co">#&gt;  13 predictor</span></span>
<span><span class="co">#&gt;   2 classes: 'Charged Off', 'Fully Paid' </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; No pre-processing</span></span>
<span><span class="co">#&gt; Resampling: Cross-Validated (10 fold) </span></span>
<span><span class="co">#&gt; Summary of sample sizes: 628, 628, 627, 629, 628, 628, ... </span></span>
<span><span class="co">#&gt; Resampling results:</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   Accuracy   Kappa    </span></span>
<span><span class="co">#&gt;   0.9612612  0.8568619</span></span></code></pre></div>
<p>We got a higher accuracy.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="big-data-and-machine-learning.html"><span class="header-section-number">5</span> Big data and machine learning</a></div>
<div class="next"><a href="rational-agent-and-behavioral-finance-in-investment.html"><span class="header-section-number">7</span> Rational agent and behavioral finance in investment</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li>
<a class="nav-link" href="#credit-analysis"><span class="header-section-number">6</span> Credit analysis</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#prediction-with-the-logit-model"><span class="header-section-number">6.0.1</span> Prediction with the Logit model</a></li></ul>
</li>
<li><a class="nav-link" href="#measuring-model-performance"><span class="header-section-number">6.1</span> Measuring model performance</a></li>
<li>
<a class="nav-link" href="#prediction-with-linear-discriminant-analysis-lda"><span class="header-section-number">6.2</span> Prediction with Linear Discriminant Analysis (LDA)</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#cross-validation."><span class="header-section-number">6.2.1</span> 3 Cross validation.</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/abernal30/BookAFP/blob/master/06-Credit-analysis.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/abernal30/BookAFP/edit/master/06-Credit-analysis.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Algorithms and Financial Programming in R</strong>" was written by Arturo Bernal. It was last built on 2023-02-11.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
