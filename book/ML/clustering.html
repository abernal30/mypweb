<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>6 Clustering | Machine learning introductory guide</title>
<meta name="author" content="L. Arturo Bernal">
<meta name="description" content="Unsupervised learning - Clustering Clustering is a technique that aims to group similar data points so that the points in the same group have similar features to those in the other groups. The...">
<meta name="generator" content="bookdown 0.33 with bs4_book()">
<meta property="og:title" content="6 Clustering | Machine learning introductory guide">
<meta property="og:type" content="book">
<meta property="og:url" content="https://www.arturo-bernal.com/book/clustering.html">
<meta property="og:image" content="https://www.arturo-bernal.com/book/images/Picture1.jpg">
<meta property="og:description" content="Unsupervised learning - Clustering Clustering is a technique that aims to group similar data points so that the points in the same group have similar features to those in the other groups. The...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="6 Clustering | Machine learning introductory guide">
<meta name="twitter:description" content="Unsupervised learning - Clustering Clustering is a technique that aims to group similar data points so that the points in the same group have similar features to those in the other groups. The...">
<meta name="twitter:image" content="https://www.arturo-bernal.com/book/images/Picture1.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Machine learning introductory guide</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Machine learning introductory guide</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="ml-in-the-bussines-lascape-and-data-collection.html"><span class="header-section-number">1</span> ML in the bussines lascape and data collection</a></li>
<li><a class="" href="training-and-evaluating-regression-models.html"><span class="header-section-number">2</span> Training and evaluating regression models</a></li>
<li><a class="" href="training-and-evaluating-classification-models.html"><span class="header-section-number">3</span> Training and evaluating classification models</a></li>
<li><a class="" href="cross-validation.html"><span class="header-section-number">4</span> Cross Validation</a></li>
<li><a class="" href="improving-performance.html"><span class="header-section-number">5</span> Improving Performance</a></li>
<li><a class="active" href="clustering.html"><span class="header-section-number">6</span> Clustering</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="clustering" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Clustering<a class="anchor" aria-label="anchor" href="#clustering"><i class="fas fa-link"></i></a>
</h1>
<p>Unsupervised learning - Clustering</p>
<p>Clustering is a technique that aims to group similar data points so that the points in the same group have similar features to those in the other groups. The group of similar data points is called a Cluster.</p>
<p>For example, suppose we have the following data frame, with hypothetical data of students ages and grades in course:</p>
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1100</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">20</span>, <span class="fl">3</span><span class="op">)</span>,<span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">95</span>, <span class="fl">4</span><span class="op">)</span>,<span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">y</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">y</span><span class="op">&gt;</span><span class="fl">100</span>,<span class="fl">100</span>,<span class="va">y</span><span class="op">)</span></span>
<span><span class="va">df</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>Age<span class="op">=</span><span class="va">x</span>, Grade<span class="op">=</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Ind"</span>,<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">df</span></span>
<span><span class="co">#&gt;        Age Grade</span></span>
<span><span class="co">#&gt; Ind 1   21   100</span></span>
<span><span class="co">#&gt; Ind 2   19    98</span></span>
<span><span class="co">#&gt; Ind 3   20    95</span></span>
<span><span class="co">#&gt; Ind 4   17    97</span></span>
<span><span class="co">#&gt; Ind 5   17    95</span></span>
<span><span class="co">#&gt; Ind 6   21    97</span></span>
<span><span class="co">#&gt; Ind 7   19    96</span></span>
<span><span class="co">#&gt; Ind 8   19    97</span></span>
<span><span class="co">#&gt; Ind 9   16    87</span></span>
<span><span class="co">#&gt; Ind 10  25    95</span></span>
<span><span class="co">#&gt; Ind 11  23    97</span></span>
<span><span class="co">#&gt; Ind 12  22   100</span></span></code></pre></div>
<p>For a betther undestandng of what is a plot, the following plot shows how each person is similar to other in terms of age and grade.</p>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span>,<span class="st">"Age"</span><span class="op">]</span>, <span class="va">df</span><span class="op">[</span>,<span class="st">"Grade"</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"blue"</span>, pch <span class="op">=</span> <span class="fl">1</span>, cex <span class="op">=</span> <span class="fl">1.5</span>,ylab<span class="op">=</span><span class="st">"Grade"</span>,xlab<span class="op">=</span><span class="st">"Age"</span>,ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">88</span>,<span class="fl">101</span><span class="op">)</span>,xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">16</span>,<span class="fl">26</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span>,<span class="st">"Age"</span><span class="op">]</span> <span class="op">+</span> <span class="fl">.3</span>, <span class="va">df</span><span class="op">[</span>,<span class="st">"Grade"</span><span class="op">]</span> <span class="op">+</span> <span class="fl">0.9</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-2-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>One one to identify if a person or a group of persons are similar in terms of age and grade to other, which is equivalent to say that are in the same cluster, is using the Euclidean Distance (ED):</p>
<p><span class="math display">\[d_{euc}(p,q)= \sqrt{ \sum_{i=1}^{n} (p_{i}-q_{i}})^{2}\]</span></p>
<p>where <span class="math inline">\(p_{i}\)</span>, <span class="math inline">\(p_{i}\)</span> are two points in the euclidean space. In our example, are two different persons of the data set. <span class="math inline">\(n\)</span> is the number of features, in our example are two, age anf grade. For example, the Euclidean Distance for person 1 and 2 is:</p>
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="op">(</span><span class="va">df</span><span class="op">[</span><span class="st">"Ind 1"</span>,<span class="st">"Age"</span><span class="op">]</span><span class="op">-</span><span class="va">df</span><span class="op">[</span><span class="st">"Ind 2"</span>,<span class="st">"Age"</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">+</span><span class="op">(</span><span class="va">df</span><span class="op">[</span><span class="st">"Ind 1"</span>,<span class="st">"Grade"</span><span class="op">]</span><span class="op">-</span><span class="va">df</span><span class="op">[</span><span class="st">"Ind 2"</span>,<span class="st">"Grade"</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2.828427</span></span></code></pre></div>
<p>The lower (higher) the ED between two persons, the more similars (different) they are, and is porbably that are grouped (not grouped) in the same cluster.</p>
<p>To estimate the Euclidean Distance for all the persons in the data set, we use the funciton “get_dist”, from the library “factoextra”:</p>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sthda.com/english/rpkgs/factoextra">factoextra</a></span><span class="op">)</span> <span class="co">#</span></span>
<span><span class="va">distance</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/dist.html">get_dist</a></span><span class="op">(</span><span class="va">df</span>, method <span class="op">=</span> <span class="st">"euclidean"</span><span class="op">)</span></span>
<span><span class="va">distance</span></span>
<span><span class="co">#&gt;            Ind 1     Ind 2     Ind 3     Ind 4     Ind 5     Ind 6     Ind 7</span></span>
<span><span class="co">#&gt; Ind 2   2.828427                                                            </span></span>
<span><span class="co">#&gt; Ind 3   5.099020  3.162278                                                  </span></span>
<span><span class="co">#&gt; Ind 4   5.000000  2.236068  3.605551                                        </span></span>
<span><span class="co">#&gt; Ind 5   6.403124  3.605551  3.000000  2.000000                              </span></span>
<span><span class="co">#&gt; Ind 6   3.000000  2.236068  2.236068  4.000000  4.472136                    </span></span>
<span><span class="co">#&gt; Ind 7   4.472136  2.000000  1.414214  2.236068  2.236068  2.236068          </span></span>
<span><span class="co">#&gt; Ind 8   3.605551  1.000000  2.236068  2.000000  2.828427  2.000000  1.000000</span></span>
<span><span class="co">#&gt; Ind 9  13.928388 11.401754  8.944272 10.049876  8.062258 11.180340  9.486833</span></span>
<span><span class="co">#&gt; Ind 10  6.403124  6.708204  5.000000  8.246211  8.000000  4.472136  6.082763</span></span>
<span><span class="co">#&gt; Ind 11  3.605551  4.123106  3.605551  6.000000  6.324555  2.000000  4.123106</span></span>
<span><span class="co">#&gt; Ind 12  1.000000  3.605551  5.385165  5.830952  7.071068  3.162278  5.000000</span></span>
<span><span class="co">#&gt;            Ind 8     Ind 9    Ind 10    Ind 11</span></span>
<span><span class="co">#&gt; Ind 2                                         </span></span>
<span><span class="co">#&gt; Ind 3                                         </span></span>
<span><span class="co">#&gt; Ind 4                                         </span></span>
<span><span class="co">#&gt; Ind 5                                         </span></span>
<span><span class="co">#&gt; Ind 6                                         </span></span>
<span><span class="co">#&gt; Ind 7                                         </span></span>
<span><span class="co">#&gt; Ind 8                                         </span></span>
<span><span class="co">#&gt; Ind 9  10.440307                              </span></span>
<span><span class="co">#&gt; Ind 10  6.324555 12.041595                    </span></span>
<span><span class="co">#&gt; Ind 11  4.000000 12.206556  2.828427          </span></span>
<span><span class="co">#&gt; Ind 12  4.242641 14.317821  5.830952  3.162278</span></span></code></pre></div>
<p>As we see in the output, the result shows the ED between each person. Is important to notice that the output is not a data frame, is a “dist” object:</p>
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">distance</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "dist"</span></span></code></pre></div>
<p>The previous outpt is not giving us infromation about how people are grouped in clusters, but the following plot does, using the function “fviz_dist”, wich has as first argument the “dist” object we made in the last “chunk”:</p>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/dist.html">fviz_dist</a></span><span class="op">(</span><span class="va">distance</span>,  gradient <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>low <span class="op">=</span> <span class="st">"#00AFBB"</span>, mid <span class="op">=</span> <span class="st">"white"</span>, high <span class="op">=</span> <span class="st">"#FC4E07"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-6-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>In the previous plot, the red color squares are persons with a higher ED and the blue ones lower ones.</p>
<p>In terms of the scatter plot we made before, if we take the individual pairs that has a ED less than 2, for example, we get the following results:</p>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span>,<span class="st">"Age"</span><span class="op">]</span>, <span class="va">df</span><span class="op">[</span>,<span class="st">"Grade"</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"blue"</span>, pch <span class="op">=</span> <span class="fl">1</span>, cex <span class="op">=</span> <span class="fl">1.5</span>,ylab<span class="op">=</span><span class="st">"Grade"</span>,xlab<span class="op">=</span><span class="st">"Age"</span>,ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">86</span>,<span class="fl">101</span><span class="op">)</span>,xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">16</span>,<span class="fl">26</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span>,<span class="st">"Age"</span><span class="op">]</span> <span class="op">+</span> <span class="fl">.3</span>, <span class="va">df</span><span class="op">[</span>,<span class="st">"Grade"</span><span class="op">]</span> <span class="op">+</span> <span class="fl">0.6</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span><span class="va">ind</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>,<span class="st">"Age"</span><span class="op">]</span>, <span class="va">df</span><span class="op">[</span><span class="va">ind</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>,<span class="st">"Grade"</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"orange"</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span><span class="va">ind</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span>,<span class="st">"Age"</span><span class="op">]</span>, <span class="va">df</span><span class="op">[</span><span class="va">ind</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span>,<span class="st">"Grade"</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"red"</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span><span class="va">ind</span><span class="op">[</span><span class="fl">3</span>, <span class="op">]</span>,<span class="st">"Age"</span><span class="op">]</span>, <span class="va">df</span><span class="op">[</span><span class="va">ind</span><span class="op">[</span><span class="fl">3</span>, <span class="op">]</span>,<span class="st">"Grade"</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"red"</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span><span class="va">ind</span><span class="op">[</span><span class="fl">4</span>, <span class="op">]</span>,<span class="st">"Age"</span><span class="op">]</span>, <span class="va">df</span><span class="op">[</span><span class="va">ind</span><span class="op">[</span><span class="fl">4</span>, <span class="op">]</span>,<span class="st">"Grade"</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"red"</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-8-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#segments(x0 = 19, y0 = 96,x1=20,y1=95) </span></span></code></pre></div>
<p>We see that the red dots are kind of grouped between them, and also the yellow ones. In this sense, we could say that the individuals in red dots could be a cluster, and the individuals in yellow other cluster. We could repeat the procees for the no-color individuales, but for the moment we waned to explian how clusters are formed.</p>
<div id="agglomerative-hierarchical-clustering" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Agglomerative hierarchical clustering<a class="anchor" aria-label="anchor" href="#agglomerative-hierarchical-clustering"><i class="fas fa-link"></i></a>
</h2>
<p>As we prove in the last method, we need a partition to define the similarity beetween two individuals, to be in th sale cluster. Hierarchical clustering algorithms doesn´t need a predefined partition to generate the clusters.</p>
<p>First, using a particular proximity measure a dissimilarity matrix is constructed and all the data points are visually represented at the bottom of the dendrogram. The closest sets of clusters are merged at each level and then the dissimilarity matrix is updated correspondingly. This process of agglomerative merging is carried on until the final maximal cluster (that contains all the data objects in a single cluster) is obtained. This would represent the apex of our dendrogram and mark the completion of the merging process. We will now discuss the different kinds of proximity measures which can be used in agglomerative hierarchical clustering. Subsequently, we will also provide a complete version of the agglomerative hierarchical clustering algorithm in</p>
<p>The most popular agglomerative clustering methods are single link and complete link clusterings. In single link clustering [36, 46], the similarity of two clusters is the similarity between their most similar (nearest neighbor) members. This method intuitively gives more importance to the regions where clusters are closest, neglecting the overall structure of the cluster. Hence, this method falls under the category of a local similarity-based clustering method. Because of its local behavior, single linkage is capable of effectively clustering nonelliptical, elongated shaped groups of data objects. However, one of the main drawbacks of this method is its sensitivity to noise and outliers in the data.</p>
<p>Complete link clustering [27] measures the similarity of two clusters as the similarity of their most dissimilar members. This is equivalent to choosing the cluster pair whose merge has the smallest diameter. As this method takes the cluster structure into consideration it is nonlocal in behavior and generally obtains compact shaped clusters. However, similar to single link clustering, this method is also sensitive to outliers. Both single link and complete link clustering have their graph-theoretic interpretations [16], where the clusters obtained after single link clustering would correspond to the connected components of a graph and those obtained through complete link would correspond to the maximal cliques of the graph.</p>
<p>The Lance and Williams recurrence formula gives the distance between a group k and a group (ij) formed by the fusion of two groups (i and j) as :</p>
<p><span class="math display">\[ d_{k(ij)}= \alpha\ d_{ki}+\beta\ d_{ij}+\gamma\ |d_{ki}-d_{kj}|, \]</span></p>
<p>where <span class="math inline">\(d_{ij}\)</span> is s the distance between groups i and j. Lance and Williams used the formula to define a new ‘flexible’ scheme, with parameter values αi + αj + β = 1, αi = αj, β &lt; 1, γ = 0. By allowing β to vary, clustering schemes with various characteristics can be obtained. They suggest small negative values for β, such as −0.25, although Scheibler and Schneider (1985) suggest −0.50 <span class="citation">(<a href="clustering.html#ref-Everitt" role="doc-biblioref">Brian S. Everitt 2011</a>)</span>.</p>
<p>hClustering &lt;- hclust(distance object,method)
method=c(ward.D”, “ward.D2”, “single”, “complete”, “average”, “mcquitty” , “median” or “centroid” )</p>
<p>plot(hClustering object)</p>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hClustering</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span><span class="op">(</span><span class="va">distance</span> ,method<span class="op">=</span><span class="st">"single"</span><span class="op">)</span> <span class="co"># cuidado por que le pusimos distance también al de teens</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">hClustering</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-9-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>This chart can be used to visually inspect the number of clusters that would be created for a selected distance threshold . The number of vertical lines a hypothetical straight, horizontal line will pass through is the number of clusters created for that distance threshold value. All data points (leaves) from that branch would be labeled as that cluster that the horizontal line passed through.</p>
<p>members of each cluster
memb &lt;-cutree(hClustering object, k = )</p>
<p>k= número de clusters que se desean</p>
<p>h= cut number of the dendrogram</p>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">memb</span> <span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span><span class="op">(</span><span class="va">hClustering</span>, k <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">memb</span><span class="op">)</span></span>
<span><span class="co">#&gt; Ind 1 Ind 2 Ind 3 Ind 4 Ind 5 Ind 6 </span></span>
<span><span class="co">#&gt;     1     1     1     1     1     1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">tail</a></span><span class="op">(</span><span class="va">memb</span><span class="op">)</span></span>
<span><span class="co">#&gt;  Ind 7  Ind 8  Ind 9 Ind 10 Ind 11 Ind 12 </span></span>
<span><span class="co">#&gt;      1      1      2      3      1      1</span></span></code></pre></div>
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cent</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">k</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">cent</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">cent</span>, <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colMeans</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span><span class="va">memb</span> <span class="op">==</span> <span class="va">k</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
</div>
<div id="k-means-clustering" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> K-Means Clustering<a class="anchor" aria-label="anchor" href="#k-means-clustering"><i class="fas fa-link"></i></a>
</h2>
<p>K-means clustering is the most commonly used unsupervised machine learning algorithm for partitioning a given data set into a set of k groups (i.e. k clusters), where k represents the number of groups pre-specified by the analyst. It classifies objects in multiple groups (i.e., clusters), such that objects within the same cluster are as similar as possible (i.e., high intra-class similarity), whereas objects from different clusters are as dissimilar as possible (i.e., low inter-class similarity). In k-means clustering, each cluster is represented by its center (i.e, centroid) which corresponds to the mean of points assigned to the cluster.</p>
<p>The Basic Idea</p>
<p>The basic idea behind k-means clustering consists of defining clusters so that the total intra-cluster variation (known as total within-cluster variation) is minimized. There are several k-means algorithms available. The standard algorithm is the Hartigan-Wong algorithm (1979), which defines the total within-cluster variation as the sum of squared distances Euclidean distances between items and the corresponding centroid:</p>
<p><span class="math display">\[ W(C_{k})=\sum_{x_{i}\in C_{k}}(x_{i}- \mu_{k})^2\]</span></p>
<p><span class="math inline">\(x_{i}\)</span> is a data point belonging to the cluster Ck.</p>
<p>_{k} is the mean value of the points assigned to the cluster Ck</p>
<p>Each observation (xi) is assigned to a given cluster such that the sum of squares (SS) distance of the observation to their assigned cluster centers (μk) is minimized.</p>
<p>We define the total within-cluster variation as follows:
<span class="math display">\[ tot.withiness=\sum_{k=1}^k W(C_{k})=\sum_{k=1}^k \sum_{x_{i}\in C_{k}}(x_{i}- \mu_{k})^2\]</span></p>
<p>The total within-cluster sum of square measures the compactness (i.e goodness) of the clustering and we want it to be as small as possible.</p>
<p>kmeans(df object, centers = )
centers is number of clusters</p>
<p>nstart, Select randomly k objects from the data set as the initial cluster centers or means</p>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="co"># regresamos a df con dos variables</span></span>
<span><span class="va">teens</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"https://raw.githubusercontent.com/abernal30/ml_book/main/teens_clean.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">teens_na</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/na.fail.html">na.omit</a></span><span class="op">(</span><span class="va">teens</span><span class="op">)</span></span>
<span><span class="co">#dim arroja el npumero de renglones y columas de un data frame</span></span>
<span><span class="va">dim</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">teens_na</span><span class="op">)</span></span>
<span><span class="co"># genera números del 1 al 27,276(dim[1]) pero solo arrojame 1,000. </span></span>
<span><span class="va">samp</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">dim</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="fl">10000</span><span class="op">)</span></span>
<span><span class="co"># Del objeto teens_na, toma solo las observaciones que hay en samp</span></span>
<span><span class="va">teens_2</span><span class="op">&lt;-</span><span class="va">teens_na</span><span class="op">[</span><span class="va">samp</span>,<span class="op">]</span></span>
<span><span class="va">teens_2</span><span class="op">[</span>,<span class="st">"gender"</span><span class="op">]</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">teens_2</span><span class="op">[</span>,<span class="st">"gender"</span><span class="op">]</span><span class="op">==</span><span class="st">"F"</span>,<span class="fl">1</span>,<span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">km</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/kmeans.html">kmeans</a></span><span class="op">(</span><span class="va">teens_2</span>, centers <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="co"># centers es el número de clusters</span></span></code></pre></div>
<p>fviz_cluster(kmenas object, data =, stand=F)</p>
<p>ylim=c(90,101),xlim=c(17,27)</p>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="va">km</span>, data <span class="op">=</span> <span class="va">teens_2</span> , stand<span class="op">=</span><span class="cn">F</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-13-1.png" width="90%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_nbclust.html">fviz_nbclust</a></span><span class="op">(</span><span class="va">teens_2</span> , <span class="va">kmeans</span>, method <span class="op">=</span> <span class="st">"wss"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-14-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Elbow Method</p>
<p>Recall that, the basic idea behind cluster partitioning methods, such as k-means clustering, is to define clusters such that the total intra-cluster variation (known as total within-cluster variation or total within-cluster sum of square) is minimized:</p>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_nbclust.html">fviz_nbclust</a></span><span class="op">(</span><span class="va">teens_2</span>, <span class="va">kmeans</span>, method <span class="op">=</span> <span class="st">"wss"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-15-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Average Silhouette Method</p>
<p>In short, the average silhouette approach measures the quality of a clustering. That is, it determines how well each object lies within its cluster. A high average silhouette width indicates a good clustering. The average silhouette method computes the average silhouette of observations for different values of k. The optimal number of clusters k is the one that maximizes the average silhouette over a range of possible values for k.2</p>
<p>We can use the silhouette function in the cluster package to compuate the average silhouette width. The following code computes this approach for 1-15 clusters. The results show that 2 clusters maximize the average silhouette values with 4 clusters coming in as second optimal number of clusters.</p>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_nbclust.html">fviz_nbclust</a></span><span class="op">(</span><span class="va">df</span>, <span class="va">kmeans</span>, method <span class="op">=</span> <span class="st">"silhouette"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-16-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="cluster-intuition" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Cluster intuition<a class="anchor" aria-label="anchor" href="#cluster-intuition"><i class="fas fa-link"></i></a>
</h2>
<p>We do the cluster intuition only for the k-means, but it could apply for other methods, such as hierarchical clustering.</p>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">teens_scale</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">teens_2</span><span class="op">[</span>,<span class="fl">2</span><span class="op">:</span><span class="fl">41</span><span class="op">]</span>, <span class="va">scale</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">teens_scale</span><span class="op">)</span></span>
<span><span class="co">#&gt;      gender             age               friends          basketball     </span></span>
<span><span class="co">#&gt;  Min.   :-2.0727   Min.   :-3.306980   Min.   :-0.8569   Min.   :-0.3403  </span></span>
<span><span class="co">#&gt;  1st Qu.: 0.4824   1st Qu.:-0.829209   1st Qu.:-0.7455   1st Qu.:-0.3403  </span></span>
<span><span class="co">#&gt;  Median : 0.4824   Median :-0.007369   Median :-0.2720   Median :-0.3403  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.000000   Mean   : 0.0000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.: 0.4824   3rd Qu.: 0.843353   3rd Qu.: 0.3687   3rd Qu.:-0.3403  </span></span>
<span><span class="co">#&gt;  Max.   : 0.4824   Max.   : 2.396008   Max.   :11.8721   Max.   :15.4215  </span></span>
<span><span class="co">#&gt;     football           soccer           softball         volleyball     </span></span>
<span><span class="co">#&gt;  Min.   :-0.3696   Min.   :-0.2452   Min.   :-0.2245   Min.   :-0.2259  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.3696   1st Qu.:-0.2452   1st Qu.:-0.2245   1st Qu.:-0.2259  </span></span>
<span><span class="co">#&gt;  Median :-0.3696   Median :-0.2452   Median :-0.2245   Median :-0.2259  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.3696   3rd Qu.:-0.2452   3rd Qu.:-0.2245   3rd Qu.:-0.2259  </span></span>
<span><span class="co">#&gt;  Max.   :13.8005   Max.   :28.5005   Max.   :16.2346   Max.   :17.2642  </span></span>
<span><span class="co">#&gt;     swimming        cheerleading       baseball          tennis       </span></span>
<span><span class="co">#&gt;  Min.   :-0.2829   Min.   :-0.211   Min.   :-0.193   Min.   :-0.1663  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.2829   1st Qu.:-0.211   1st Qu.:-0.193   1st Qu.:-0.1663  </span></span>
<span><span class="co">#&gt;  Median :-0.2829   Median :-0.211   Median :-0.193   Median :-0.1663  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.000   Mean   : 0.000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.2829   3rd Qu.:-0.211   3rd Qu.:-0.193   3rd Qu.:-0.1663  </span></span>
<span><span class="co">#&gt;  Max.   :15.8853   Max.   :16.050   Max.   :25.838   Max.   :22.9600  </span></span>
<span><span class="co">#&gt;      sports             cute              sex               sexy        </span></span>
<span><span class="co">#&gt;  Min.   :-0.2982   Min.   :-0.4074   Min.   :-0.2128   Min.   :-0.2697  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.2982   1st Qu.:-0.4074   1st Qu.:-0.2128   1st Qu.:-0.2697  </span></span>
<span><span class="co">#&gt;  Median :-0.2982   Median :-0.4074   Median :-0.2128   Median :-0.2697  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.2982   3rd Qu.:-0.4074   3rd Qu.:-0.2128   3rd Qu.:-0.2697  </span></span>
<span><span class="co">#&gt;  Max.   :25.1558   Max.   :18.1970   Max.   :46.3166   Max.   :22.5086  </span></span>
<span><span class="co">#&gt;       hot              kissed            dance              band        </span></span>
<span><span class="co">#&gt;  Min.   :-0.2614   Min.   :-0.1958   Min.   :-0.3761   Min.   :-0.2958  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.2614   1st Qu.:-0.1958   1st Qu.:-0.3761   1st Qu.:-0.2958  </span></span>
<span><span class="co">#&gt;  Median :-0.2614   Median :-0.1958   Median :-0.3761   Median :-0.2958  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.2614   3rd Qu.:-0.1958   3rd Qu.:-0.3761   3rd Qu.:-0.2958  </span></span>
<span><span class="co">#&gt;  Max.   :18.5623   Max.   :45.3319   Max.   :18.7830   Max.   :19.2610  </span></span>
<span><span class="co">#&gt;     marching           music              rock             god         </span></span>
<span><span class="co">#&gt;  Min.   :-0.1366   Min.   :-0.6308   Min.   :-0.339   Min.   :-0.4049  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.1366   1st Qu.:-0.6308   1st Qu.:-0.339   1st Qu.:-0.4049  </span></span>
<span><span class="co">#&gt;  Median :-0.1366   Median :-0.6308   Median :-0.339   Median :-0.4049  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.1366   3rd Qu.: 0.1974   3rd Qu.:-0.339   3rd Qu.: 0.4508  </span></span>
<span><span class="co">#&gt;  Max.   :33.7073   Max.   :21.7306   Max.   :24.272   Max.   :21.8440  </span></span>
<span><span class="co">#&gt;      church            jesus            bible             hair        </span></span>
<span><span class="co">#&gt;  Min.   :-0.2773   Min.   :-0.194   Min.   :-0.105   Min.   :-0.4028  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.2773   1st Qu.:-0.194   1st Qu.:-0.105   1st Qu.:-0.4028  </span></span>
<span><span class="co">#&gt;  Median :-0.2773   Median :-0.194   Median :-0.105   Median :-0.4028  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.000   Mean   : 0.000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.2773   3rd Qu.:-0.194   3rd Qu.:-0.105   3rd Qu.:-0.4028  </span></span>
<span><span class="co">#&gt;  Max.   :47.2192   Max.   :49.328   Max.   :37.729   Max.   :17.0580  </span></span>
<span><span class="co">#&gt;      dress             blonde             mall            shopping      </span></span>
<span><span class="co">#&gt;  Min.   :-0.2432   Min.   :-0.1838   Min.   :-0.3705   Min.   :-0.4936  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.2432   1st Qu.:-0.1838   1st Qu.:-0.3705   1st Qu.:-0.4936  </span></span>
<span><span class="co">#&gt;  Median :-0.2432   Median :-0.1838   Median :-0.3705   Median :-0.4936  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.2432   3rd Qu.:-0.1838   3rd Qu.:-0.3705   3rd Qu.: 0.8737  </span></span>
<span><span class="co">#&gt;  Max.   :20.2934   Max.   :39.8700   Max.   :16.5196   Max.   :10.4445  </span></span>
<span><span class="co">#&gt;     clothes          hollister        abercrombie           die         </span></span>
<span><span class="co">#&gt;  Min.   :-0.3166   Min.   :-0.2004   Min.   :-0.1825   Min.   :-0.3078  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.3166   1st Qu.:-0.2004   1st Qu.:-0.1825   1st Qu.:-0.3078  </span></span>
<span><span class="co">#&gt;  Median :-0.3166   Median :-0.2004   Median :-0.1825   Median :-0.3078  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.3166   3rd Qu.:-0.2004   3rd Qu.:-0.1825   3rd Qu.:-0.3078  </span></span>
<span><span class="co">#&gt;  Max.   :16.1428   Max.   :22.1627   Max.   :23.7896   Max.   :26.2269  </span></span>
<span><span class="co">#&gt;      death             drunk             drugs             female       </span></span>
<span><span class="co">#&gt;  Min.   :-0.2529   Min.   :-0.2217   Min.   :-0.1757   Min.   :-2.0727  </span></span>
<span><span class="co">#&gt;  1st Qu.:-0.2529   1st Qu.:-0.2217   1st Qu.:-0.1757   1st Qu.: 0.4824  </span></span>
<span><span class="co">#&gt;  Median :-0.2529   Median :-0.2217   Median :-0.1757   Median : 0.4824  </span></span>
<span><span class="co">#&gt;  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  </span></span>
<span><span class="co">#&gt;  3rd Qu.:-0.2529   3rd Qu.:-0.2217   3rd Qu.:-0.1757   3rd Qu.: 0.4824  </span></span>
<span><span class="co">#&gt;  Max.   :30.9186   Max.   :19.6631   Max.   :32.2532   Max.   : 0.4824</span></span></code></pre></div>
<p>teen_clusters &lt;- kmeans(data, k)</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2345</span><span class="op">)</span></span>
<span><span class="co">#Ayer  </span></span>
<span><span class="va">teen_clusters</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/kmeans.html">kmeans</a></span><span class="op">(</span><span class="va">teens_scale</span>, <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">centroids</span><span class="op">&lt;-</span><span class="va">teen_clusters</span><span class="op">$</span><span class="va">centers</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">centroids</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "matrix" "array"</span></span></code></pre></div>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_cluster.html">fviz_cluster</a></span><span class="op">(</span><span class="va">teen_clusters</span>, data <span class="op">=</span> <span class="va">teens_2</span> , stand<span class="op">=</span><span class="cn">F</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-19-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Transforming into matrix, for making a plot.
as.matrix(teen_clusters$centers)</p>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/barplot.html">barplot</a></span><span class="op">(</span>height <span class="op">=</span><span class="va">centroids</span>,main<span class="op">=</span><span class="st">"Centroids"</span>,legend.text <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>        beside <span class="op">=</span> <span class="cn">TRUE</span>,col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>,<span class="st">"blue"</span><span class="op">)</span>,las<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-20-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Function to make a bar plot</p>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># data is a matrix object with the centroids</span></span>
<span><span class="co"># name is the plot name (main argument)</span></span>
<span><span class="va">my_plot</span><span class="op">&lt;-</span><span class="kw">function</span><span class="op">(</span><span class="va">data</span>,<span class="va">name</span><span class="op">)</span><span class="op">{</span></span>
<span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/barplot.html">barplot</a></span><span class="op">(</span>height <span class="op">=</span><span class="va">data</span>,main<span class="op">=</span><span class="va">name</span>,legend.text <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>        beside <span class="op">=</span> <span class="cn">TRUE</span>,col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>,<span class="st">"blue"</span><span class="op">)</span>,las<span class="op">=</span><span class="fl">2</span><span class="op">)</span><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">se</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">1</span><span class="op">)</span> </span>
<span><span class="va">hc_caract</span><span class="op">&lt;-</span><span class="va">centroids</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gender"</span>,<span class="st">"age"</span>,<span class="st">"friends"</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="fu">my_plot</span><span class="op">(</span><span class="va">hc_caract</span>,<span class="st">"Características generales"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06_clustering_files/figure-html/unnamed-chunk-22-1.png" width="90%" style="display: block; margin: auto;"></div>

<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-AFP" class="csl-entry">
Bernal, Arturo. 2023. <em>Algorithms and Financial Programming in r</em>. <a href="https://www.arturo-bernal.com/book/AFP/index.html">https://www.arturo-bernal.com/book/AFP/index.html</a>.
</div>
<div id="ref-Everitt" class="csl-entry">
Brian S. Everitt, Morven Leese &amp; Daniel Stahl, Sabine Landau. 2011. <em>Cluster Analysis</em>. Chichester, West Sussex: John Wiley &amp; Sons.
</div>
<div id="ref-BF" class="csl-entry">
Burton, Edwin T., and Sunit N. Shah. 2013. <em>Behavioral Finance</em>. Hoboken, New Jersey: John Wiley &amp; Sons.
</div>
<div id="ref-Geron" class="csl-entry">
Géron, Aurélien. 2023. <em>Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. Sebastopol, CA: O’Reilly Media, Inc.
</div>
<div id="ref-statistical_lerarning" class="csl-entry">
James, G., D. Witten, T. Hastie, and R. Tibshirani. 2017. <em>An Introduction to Statistical Learning with Applications in r</em>. Springer. <a href="https://www.springer.com/series/417">https://www.springer.com/series/417</a>.
</div>
<div id="ref-c3" class="csl-entry">
Krishnan, Nikhil. 2020. <em>Enterprise AI and Machine Learning for Managers</em>. Redwood City, CA. <a href="https://c3.ai/enterprise-ai-and-machine-learning-for-managers/">https://c3.ai/enterprise-ai-and-machine-learning-for-managers/</a>.
</div>
<div id="ref-R-caret" class="csl-entry">
Kuhn, Max. 2019. <em>The Caret Package</em>. <a href="https://topepo.github.io/caret/index.html">https://topepo.github.io/caret/index.html</a>.
</div>
<div id="ref-Lantz" class="csl-entry">
Lantz, Brett. 2019. <em>Machine Learning with r Second Edition</em>. Birmingham, UK: Packt Publishing.
</div>
<div id="ref-glm" class="csl-entry">
McCullagh, P., and J. A. Nelder FRS. 1989. <em>Generalized Linear Models</em>. Chapman &amp; Hall/CRC.
</div>
<div id="ref-Roc" class="csl-entry">
Robin, Xavier, Natacha Turck, Alexandre Hainard, Natalia Tiberti, Frédérique Lisacek, Jean-Charles Sanchez, and Markus Müller. 2011. <span>“pROC: An Open-Source Package for r and s+ to Analyze and Compare ROC Curves.”</span> <em>BMC Bioinformatics</em> 12: 77.
</div>
<div id="ref-Suzuky" class="csl-entry">
Suzuky, Joe. 2022. <em>Statistical Learning with Math and Python</em>. Singapore, Singapore: Springer Nature Singapore.
</div>
<div id="ref-wooldridge" class="csl-entry">
Wooldridge, Jeffrey M. 2020. <em>Introductory Econometrics: A Modern Approach</em>. South-Western Cengage Learning.
</div>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="improving-performance.html"><span class="header-section-number">5</span> Improving Performance</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#clustering"><span class="header-section-number">6</span> Clustering</a></li>
<li><a class="nav-link" href="#agglomerative-hierarchical-clustering"><span class="header-section-number">6.1</span> Agglomerative hierarchical clustering</a></li>
<li><a class="nav-link" href="#k-means-clustering"><span class="header-section-number">6.2</span> K-Means Clustering</a></li>
<li><a class="nav-link" href="#cluster-intuition"><span class="header-section-number">6.3</span> Cluster intuition</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Machine learning introductory guide</strong>" was written by L. Arturo Bernal. It was last built on 2023-03-27.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
