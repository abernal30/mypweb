<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 4 Prepare the Data for Machine Learning Algorithms | Machine learning introductory guide</title>
<meta name="author" content="L. Arturo Bernal">
<meta name="description" content="4.1 Data Cleaning Common data quality issues: There might be missing or erroneous values in the data set There might be categorical (Textual, Boolean) values in the data set and not all algorithms...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="Chapter 4 4 Prepare the Data for Machine Learning Algorithms | Machine learning introductory guide">
<meta property="og:type" content="book">
<meta property="og:url" content="https://www.arturo-bernal.com/book/prepare-the-data-for-machine-learning-algorithms.html">
<meta property="og:image" content="https://www.arturo-bernal.com/book/images/Picture1.jpg">
<meta property="og:description" content="4.1 Data Cleaning Common data quality issues: There might be missing or erroneous values in the data set There might be categorical (Textual, Boolean) values in the data set and not all algorithms...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 4 Prepare the Data for Machine Learning Algorithms | Machine learning introductory guide">
<meta name="twitter:description" content="4.1 Data Cleaning Common data quality issues: There might be missing or erroneous values in the data set There might be categorical (Textual, Boolean) values in the data set and not all algorithms...">
<meta name="twitter:image" content="https://www.arturo-bernal.com/book/images/Picture1.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Roboto-0.4.2/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-68765210-2', 'auto');
      ga('send', 'pageview');

    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Machine learning introductory guide</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Machine learning introductory guide</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="big-picture.html"><span class="header-section-number">1</span> Big picture</a></li>
<li><a class="" href="data-collection.html"><span class="header-section-number">2</span> Data collection</a></li>
<li><a class="" href="discover-and-visualize-the-data-to-gain-insights.html"><span class="header-section-number">3</span> 3 Discover and Visualize the Data to Gain Insights</a></li>
<li><a class="active" href="prepare-the-data-for-machine-learning-algorithms.html"><span class="header-section-number">4</span> 4 Prepare the Data for Machine Learning Algorithms</a></li>
<li><a class="" href="select-and-train-and-evaluate-the-model.html"><span class="header-section-number">5</span> 5 Select and Train and evaluate the Model</a></li>
<li><a class="" href="fine-tune-or-tune-the-ml-model.html"><span class="header-section-number">6</span> 6 Fine-Tune or Tune the ML Model</a></li>
<li><a class="" href="references.html"><span class="header-section-number">7</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/abernal30/BookAFP">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="prepare-the-data-for-machine-learning-algorithms" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> 4 Prepare the Data for Machine Learning Algorithms<a class="anchor" aria-label="anchor" href="#prepare-the-data-for-machine-learning-algorithms"><i class="fas fa-link"></i></a>
</h1>
<div id="data-cleaning" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Data Cleaning<a class="anchor" aria-label="anchor" href="#data-cleaning"><i class="fas fa-link"></i></a>
</h2>
<p>Common data quality issues:</p>
<ol style="list-style-type: lower-roman">
<li>There might be missing or erroneous values in the data set</li>
<li>There might be categorical (Textual, Boolean) values in the data set and not all algorithms work well with textual values.</li>
<li>Some features might have larger values than others and are required to be transformed for equal importance.</li>
</ol>
</div>
<div id="missing-values" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Missing values<a class="anchor" aria-label="anchor" href="#missing-values"><i class="fas fa-link"></i></a>
</h2>
<p>Most Machine Learning algorithms cannot work with missing values, so analyze the best way to deal white them. We saw earlier that the total_bedrooms attribute has some missing values, so let’s fix this. You have, at least, three options:</p>
<ol style="list-style-type: lower-roman">
<li>Get rid of the corresponding districts (rows).</li>
<li>Get rid of the whole attribute (column).</li>
<li>Set the values to some value (zero, the mean, the median, etc.).</li>
</ol>
</div>
<div id="handling-text-and-categorical-attributes" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Handling Text and Categorical Attributes<a class="anchor" aria-label="anchor" href="#handling-text-and-categorical-attributes"><i class="fas fa-link"></i></a>
</h2>
<p>There might be missing or erroneous values in the data set
There might be categorical (Textual, Boolean) values in the data set and not all algorithms work well with textual values.
Some features might have larger values than others and are required to be transformed for equal importance.</p>
<p>If you run a regression including ocean_proximity, you will notice that the regression estimates a coefficient by each category of the variable ocean_proximity. When applying Machine Learning ML for forecasting pourpuses, is more convenient to transform the categorical . We need only one coefficient associated with the variable ocean_proximity. Then we need to transform the variable into numeric.</p>
<p>According to Jame et al. (2017), the expected test of the MSE, for a given value of x(0), can be decomposed into the sum of three fundamental quantities:</p>
<p><span class="math display">\[E (y_{0}-\hat{f(x_{0}))^{2}}= Var(\hat{f(x_{0}))}+[Bias\ \hat{f(x_{0}))}]^2+Var[\epsilon]\]</span>
where <span class="math inline">\(E (y_{0}-\hat{f(x_{0}))^{2}}\)</span> is the expected test MSE. It has the meaning of the expected average test MSE that we would obtain if we repeatedly estimated test MSE <em>f</em> using a large number of training sets, and tested at x0. The overall expected test MSE can be computed by averaging.</p>
<p>Variance refers to the amount by which <span class="math inline">\(\hat{f}\)</span> would change if we estimated it using a different training data set. Since the training data are used to fit the statistical learning method, different training data sets will result in a different <span class="math inline">\(\hat{f}\)</span>.</p>
<p>On the other hand, bias refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model. For example, linear regression assumes that there is a linear relationship between Y and X1,X2, . . . , Xp. It is unlikely that any real-life problem truly has such a simple linear relationship, and so performing linear regression will undoubtedly result in some bias in the estimate of <em>f</em>.</p>
<p>Finally, <span class="math inline">\(\epsilon\)</span> is the error term.</p>
<p>When the number of observations, n, is much larger than the number of independent variables, <em>x</em>, then the least squares estimates tend to also have low variance, <span class="math inline">\(Var(\hat{f(x_{0}))}\)</span>, and consequently reducing expected test of the MSE, <span class="math inline">\(E (y_{0}-\hat{f(x_{0}))^{2}}\)</span>, improving the accuracy. However, the more the number of <em>x</em>, relative to the number of observations, the then there can be a lot of variability in the least squares fit, resulting in overfitting and consequently poor predictions on future observations not used in model training. In terms of the equation</p>
<p><span class="math display">\[Var(\hat{f(x_{i})}) = Var(\hat{\beta_{0}}+\hat{\beta_{1}}x_{1}+,..,+\hat{\beta_{n}}x_{n})\]</span></p>
<p>Then, the more parameters would be estimated, the biger the variance would be, and</p>
<p>When do we not apply when we are applying Ordinary Least Squares OLS looking for a causality, or trying to explain the dependent variable,</p>
<p>When you looked at the top five rows, you probably noticed that the values in the ocean_proximity column were repetitive, which means that it is probably a categorical attribute. You can find out what categories exist and how many districts belong to each category applying the duplicated function:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">col</span><span class="op">=</span><span class="st">"ocean_proximity"</span></span>
<span><span class="va">house_train</span><span class="op">[</span>,<span class="va">col</span><span class="op">]</span><span class="op">[</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/duplicated.html">duplicated</a></span><span class="op">(</span><span class="va">house_train</span><span class="op">[</span>,<span class="va">col</span><span class="op">]</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<pre><code>## [1] "INLAND"     "&lt;1H OCEAN"  "NEAR BAY"   "NEAR OCEAN" "ISLAND"</code></pre>
<p>If you run a regression including ocean_proximity, you will notice that the regression estimates a coefficient by each category of the variable ocean_proximity. When applying Machine Learning ML for forecasting pourpuses, is more convenient to transform the categorical . We need only one coefficient associated with the variable ocean_proximity. Then we need to transform the variable into numeric.</p>
<p>When do we not apply when we are applying Ordinary Least Squares OLS looking for a causality, or trying to explain the dependent variable,</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dep</span><span class="op">&lt;-</span><span class="st">"median_house_value"</span></span>
<span><span class="va">model</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">median_house_value</span><span class="op">~</span><span class="va">.</span>,data<span class="op">=</span><span class="va">house_train</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = median_house_value ~ ., data = house_train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -406981  -41703   -9752   28771  453689 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               -2.432e+06  9.861e+04 -24.662  &lt; 2e-16 ***
## longitude                 -2.759e+04  1.141e+03 -24.185  &lt; 2e-16 ***
## latitude                  -2.605e+04  1.128e+03 -23.096  &lt; 2e-16 ***
## housing_median_age         1.069e+03  4.835e+01  22.103  &lt; 2e-16 ***
## total_rooms                2.955e+00  1.057e+00   2.796  0.00518 ** 
## total_bedrooms             1.355e+01  8.978e+00   1.510  0.13118    
## population                -4.696e+01  1.349e+00 -34.808  &lt; 2e-16 ***
## households                 1.174e+02  9.481e+00  12.383  &lt; 2e-16 ***
## median_income              4.200e+04  4.232e+02  99.249  &lt; 2e-16 ***
## ocean_proximityINLAND     -3.486e+04  1.940e+03 -17.972  &lt; 2e-16 ***
## ocean_proximityISLAND      2.265e+05  4.781e+04   4.739 2.17e-06 ***
## ocean_proximityNEAR BAY   -4.954e+03  2.114e+03  -2.343  0.01913 *  
## ocean_proximityNEAR OCEAN  4.077e+03  1.724e+03   2.365  0.01805 *  
## rooms_per_household        2.595e+03  3.163e+02   8.205 2.47e-16 ***
## bedrooms_per_room          2.970e+05  1.547e+04  19.197  &lt; 2e-16 ***
## population_per_household   5.979e+02  1.254e+02   4.766 1.89e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 67560 on 16320 degrees of freedom
##   (176 observations deleted due to missingness)
## Multiple R-squared:  0.6584, Adjusted R-squared:  0.6581 
## F-statistic:  2097 on 15 and 16320 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>For this case, the objective is to make a forecast, so is convenient to transform the categorical values into numeric. We apply the function asnum from the library dataclean.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.arturo-bernal.com/book/clean.html">datapro</a></span><span class="op">)</span></span>
<span><span class="va">house_train</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/datapro/man/asnum.html">asnum</a></span><span class="op">(</span><span class="va">house_train</span><span class="op">)</span></span>
<span><span class="va">dep</span><span class="op">&lt;-</span><span class="st">"median_house_value"</span></span>
<span><span class="va">model</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">median_house_value</span><span class="op">~</span><span class="va">.</span>,data<span class="op">=</span><span class="va">house_train</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = median_house_value ~ ., data = house_train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -435692  -42148  -10821   29840  455544 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)              -3.584e+06  7.403e+04 -48.417  &lt; 2e-16 ***
## longitude                -4.146e+04  8.458e+02 -49.023  &lt; 2e-16 ***
## latitude                 -4.100e+04  7.901e+02 -51.898  &lt; 2e-16 ***
## housing_median_age        1.137e+03  4.772e+01  23.835  &lt; 2e-16 ***
## total_rooms               2.336e+00  1.068e+00   2.188   0.0287 *  
## total_bedrooms            1.412e+01  9.073e+00   1.556   0.1198    
## population               -4.767e+01  1.363e+00 -34.978  &lt; 2e-16 ***
## households                1.221e+02  9.579e+00  12.743  &lt; 2e-16 ***
## median_income             4.319e+04  4.215e+02 102.454  &lt; 2e-16 ***
## ocean_proximity          -5.589e+01  4.052e+02  -0.138   0.8903    
## rooms_per_household       2.920e+03  3.192e+02   9.149  &lt; 2e-16 ***
## bedrooms_per_room         3.335e+05  1.551e+04  21.504  &lt; 2e-16 ***
## population_per_household  5.758e+02  1.268e+02   4.542 5.62e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 68290 on 16323 degrees of freedom
##   (176 observations deleted due to missingness)
## Multiple R-squared:  0.6509, Adjusted R-squared:  0.6506 
## F-statistic:  2536 on 12 and 16323 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Now we see that the ocean_proximity variable onpy have one coefficient.</p>
</div>
<div id="feature-scaling" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> Feature Scaling<a class="anchor" aria-label="anchor" href="#feature-scaling"><i class="fas fa-link"></i></a>
</h2>
<p>One of the most important transformations you need to apply to your data is feature scaling. With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales. This is the case for the housing data: the total number of rooms ranges from about 6 to 39,320, while the median incomes only range from 0 to 15. Note that scaling the target values (y, dependent variable) is generally not required.</p>
<p>There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.</p>
<p>Min-max scaling (many people call this normalization) is the simplest: values are shifted and rescaled so that they end up ranging from 0 to 1. We do this by subtracting the min value and dividing by the max minus the min.</p>
<p>Standardization. first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance.</p>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="discover-and-visualize-the-data-to-gain-insights.html"><span class="header-section-number">3</span> 3 Discover and Visualize the Data to Gain Insights</a></div>
<div class="next"><a href="select-and-train-and-evaluate-the-model.html"><span class="header-section-number">5</span> 5 Select and Train and evaluate the Model</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#prepare-the-data-for-machine-learning-algorithms"><span class="header-section-number">4</span> 4 Prepare the Data for Machine Learning Algorithms</a></li>
<li><a class="nav-link" href="#data-cleaning"><span class="header-section-number">4.1</span> Data Cleaning</a></li>
<li><a class="nav-link" href="#missing-values"><span class="header-section-number">4.2</span> Missing values</a></li>
<li><a class="nav-link" href="#handling-text-and-categorical-attributes"><span class="header-section-number">4.3</span> Handling Text and Categorical Attributes</a></li>
<li><a class="nav-link" href="#feature-scaling"><span class="header-section-number">4.4</span> Feature Scaling</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/abernal30/BookAFP/blob/master/01-ml.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/abernal30/BookAFP/edit/master/01-ml.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Machine learning introductory guide</strong>" was written by L. Arturo Bernal. It was last built on 2023-02-13.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
