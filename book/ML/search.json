[{"path":"index.html","id":"machine-learning-introductory-guide","chapter":"Machine learning introductory guide","heading":"Machine learning introductory guide","text":"book Machine learning introductory guide!work Aturo Bernal\nVisit GitHub repository site.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"text examples aim generate basic guide Machine Learning (ML) methodology. writing book inspired students AI concentration Tecnologico de Monterrey spring 2022.document follows practical example: ) continuous variables California Housing Prices data set presented (Géron 2023); ii) categorical variables, follow Lending Club fintech data set Kaggle analyze credit default, financial institution grants personal loans.following steps may differ books, data scientists, experts many ways deal whit machine learning. precisely richness area expertise. existed one way apply machine learning, everybody use !!R files stored GitHub repository site.","code":""},{"path":"preface.html","id":"outline","chapter":"Preface","heading":"Outline","text":"","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"ml-in-the-bussines-lascape-and-data-collection","chapter":"1 ML in the bussines lascape and data collection","heading":"1 ML in the bussines lascape and data collection","text":"","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"machine-learning-ml","chapter":"1 ML in the bussines lascape and data collection","heading":"1.1 Machine learning (ML)","text":"short, machine learning problem generally relates prediction data available. Machine Learning science (art) programming computers can learn data (Géron 2023). extracting knowledge data, research field intersection statistics, artificial intelligence, computer science. also known predictive analytics statistical learning (Muller?).\nMachine learning programming, programming problems require ML. detect problem facing ML problem, need objective, benefit company (client) apply business (Burton Shah 2013).paragraph, describe examples. describing examples, use terminology may sound unfamiliar , cover chapters.Understanding goal allows us determine kind data expect handle models apply. Suppose facing problem housing market, business objective detect investment opportunities buying sub-valuated (price) houses predicting housing prices. example, expect housing price data, housing location latitude, longitude, median age z, total rooms, etc. case, may apply supervised models linear regression evaluate model performance RMSE. Another example financial sector predicting new bank customer default loan (repay loan ). case, classification problem, use models logit LDA measure performance Confusion Matrix.\nhand, housing prices example, already information mentioned last paragraph, want know crime affects price areas. solve linear regression, wúltnd ML problem, causality one. ML problem want predict house prices certain areas crime increased. Even ML problem, wouldn´t necessarily benefit client us. example, client housing builder, help decide build. Still, client unaffected relationship crime-house prices, ML problem, benefiting client us.conclusion, handling data running algorithms, suggest establishing business goal, detecting ML problem, benefit company (client).","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"diferrence-between-machine-leagning-and-causality-approach","chapter":"1 ML in the bussines lascape and data collection","heading":"1.2 Diferrence between Machine Leagning and causality approach","text":"","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"business-objectives-and-data-sources","chapter":"1 ML in the bussines lascape and data collection","heading":"1.3 Business objectives and data sources","text":"book, use cross-sectional data set consisting sample houses bank clients taken given time: ) house pricing; ii) credit analysis. time series objectives consist observations variable several variables time, see chapters four five book (Bernal 2023).","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"variables-terminology-and-notation","chapter":"1 ML in the bussines lascape and data collection","heading":"1.4 Variables terminology and notation","text":"Many models cover book kind:\\[y=\\alpha_{0}\\ +\\beta_{1}\\ x_{1}+\\beta_{2}\\ x_{2}+...+\\beta_{n}\\ x_{n}+e\\]\n\\(y\\) called dependent variable, also materials , called explained, output variable response variable. hand, \\(x\\) called independent variables input variables, predictors features. \\(\\beta´s\\) parameters estimated, \\(e\\) error term.regression, idea estimate parameters \\(\\beta_{1}, \\beta_{2},...,\\beta_{n}\\), predict value \\(y\\). happens, represent predicted values estimated parameters :\\[\\hat{y}=\\beta_{0}\\ +\\hat{\\beta_{1}}\\ x_{1}+\\hat{\\beta_{1}}\\ x_{2}+...+\\ \\hat{\\beta_{1}}\\ x_{n}\\]\nAlso, compare \\(y_{}\\) predicted value, call residual, usually denoted \\(\\hat{e}\\). defined :\\[\\hat{e_{}}=y_{}-\\hat{y_{}}=y_{}-\\beta_{0}\\ -\\hat{\\beta_{1}}\\ x_{1i}-\\hat{\\beta_{1}}\\ x_{2i}-,...,-\\ \\hat{\\beta_{1}}\\ x_{ni}\\]\nwords, \\(\\hat{e_{}}\\) residual observation. example, data set \\(n\\) variables \\(m\\) observations, \\(m\\) residuals.","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"house-pricing","chapter":"1 ML in the bussines lascape and data collection","heading":"1.4.1 House pricing","text":"case, facing problem housing market, business objective detect investment opportunities, buying sub-valuated (price) houses predicting median housing price.can get data GitHub:housing data house media prices, houses location latitude x, longitude y, housing median age z, total rooms, etc. apply following model.\\[median\\_house\\_value=\\beta_{0}\\ +\\beta_{1}\\ longitude+\\beta_{2}\\ latitude+...+\\beta_{n}\\ variable_{n}+e\\]","code":"\nhouse<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/housing.csv\")\nstr(house)\n#> 'data.frame':    584 obs. of  52 variables:\n#>  $ Id           : int  1 2 3 4 5 6 7 8 9 10 ...\n#>  $ SalePrice    : int  181500 223500 140000 250000 307000 129900 118000 345000 279500 325300 ...\n#>  $ MSSubClass   : int  20 60 70 60 20 50 190 60 20 60 ...\n#>  $ MSZoning     : int  4 4 4 4 4 5 4 4 4 4 ...\n#>  $ LotFrontage  : int  80 68 60 84 75 51 50 85 91 101 ...\n#>  $ LotArea      : int  9600 11250 9550 14260 10084 6120 7420 11924 10652 14215 ...\n#>  $ LotShape     : int  4 1 1 1 4 4 4 1 1 1 ...\n#>  $ LotConfig    : int  3 5 1 3 5 5 1 5 5 1 ...\n#>  $ Neighborhood : int  25 6 7 14 21 18 4 16 6 16 ...\n#>  $ Condition1   : int  2 3 3 3 3 1 1 3 3 3 ...\n#>  $ BldgType     : int  1 1 1 1 1 1 2 1 1 1 ...\n#>  $ HouseStyle   : int  3 6 6 6 3 1 2 6 3 6 ...\n#>  $ OverallQual  : int  6 7 7 8 8 7 5 9 7 8 ...\n#>  $ OverallCond  : int  8 5 5 5 5 5 6 5 5 5 ...\n#>  $ YearRemodAdd : int  1976 2002 1970 2000 2005 1950 1950 2006 2007 2006 ...\n#>  $ RoofStyle    : int  2 2 2 2 2 2 2 4 2 2 ...\n#>  $ Exterior1st  : int  9 13 14 13 13 4 9 15 13 13 ...\n#>  $ MasVnrType   : int  3 2 3 2 4 3 3 4 4 2 ...\n#>  $ MasVnrArea   : int  0 162 0 350 186 0 0 286 306 380 ...\n#>  $ ExterQual    : int  4 3 4 3 3 4 4 1 3 3 ...\n#>  $ ExterCond    : int  5 5 5 5 5 5 5 5 5 5 ...\n#>  $ Foundation   : int  2 3 1 3 3 1 1 3 3 3 ...\n#>  $ BsmtQual     : int  3 3 4 3 1 4 4 1 3 1 ...\n#>  $ BsmtExposure : int  2 3 4 1 1 4 4 4 1 1 ...\n#>  $ BsmtFinType1 : int  1 3 1 3 3 6 3 3 6 6 ...\n#>  $ BsmtFinSF1   : int  978 486 216 655 1369 0 851 998 0 0 ...\n#>  $ BsmtUnfSF    : int  284 434 540 490 317 952 140 177 1494 1158 ...\n#>  $ HeatingQC    : int  1 1 3 1 1 3 1 1 1 1 ...\n#>  $ CentralAir   : int  2 2 2 2 2 2 2 2 2 2 ...\n#>  $ Electrical   : int  5 5 5 5 5 2 5 5 5 5 ...\n#>  $ X1stFlrSF    : int  1262 920 961 1145 1694 1022 1077 1182 1494 1158 ...\n#>  $ X2ndFlrSF    : int  0 866 756 1053 0 752 0 1142 0 1218 ...\n#>  $ BsmtFullBath : int  0 1 1 1 1 0 1 1 0 0 ...\n#>  $ BsmtHalfBath : int  1 0 0 0 0 0 0 0 0 0 ...\n#>  $ FullBath     : int  2 2 1 2 2 2 1 3 2 3 ...\n#>  $ HalfBath     : int  0 1 0 1 0 0 0 0 0 1 ...\n#>  $ BedroomAbvGr : int  3 3 3 4 3 2 2 4 3 4 ...\n#>  $ KitchenQual  : int  4 3 3 3 3 4 4 1 3 3 ...\n#>  $ TotRmsAbvGrd : int  6 6 7 9 7 8 5 11 7 9 ...\n#>  $ Fireplaces   : int  1 1 1 1 1 2 2 2 1 1 ...\n#>  $ FireplaceQu  : int  5 5 3 5 3 5 5 3 3 3 ...\n#>  $ GarageType   : int  2 2 6 2 2 6 2 4 2 4 ...\n#>  $ GarageYrBlt  : int  1976 2001 1998 2000 2004 1931 1939 2005 2006 2005 ...\n#>  $ GarageFinish : int  2 2 3 2 2 3 2 1 2 2 ...\n#>  $ GarageArea   : int  460 608 642 836 636 468 205 736 840 853 ...\n#>  $ PavedDrive   : int  3 3 3 3 3 3 3 3 3 3 ...\n#>  $ WoodDeckSF   : int  298 0 0 192 255 90 0 147 160 240 ...\n#>  $ OpenPorchSF  : int  0 42 35 84 57 0 4 21 33 154 ...\n#>  $ MoSold       : int  5 9 2 12 8 4 1 7 8 11 ...\n#>  $ YrSold       : int  2007 2008 2006 2008 2007 2008 2008 2006 2007 2006 ...\n#>  $ SaleType     : int  9 9 9 9 9 9 9 7 7 7 ...\n#>  $ SaleCondition: int  5 5 1 5 5 1 5 6 6 6 ..."},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"the-credit-analysis","chapter":"1 ML in the bussines lascape and data collection","heading":"1.4.2 The credit analysis","text":"credit analysis case, interested predicting new bank customer default loan (repay loan ). classification problem, use models logit LDA. can get data also GitHub.database historical information Lendingclub, https://www.lendingclub.com/ fintech marketplace bank scale. original data set least 2 million observations 150 variables. find 873 observations (rows) 71 columns. row represents Lendingclub client. previously made data cleaning (missing values, correlated variables, Zero- Near Zero-Variance Predictors).case, model .\\[Default=\\beta_{0}\\ +\\beta_{1}\\ term_{1}+\\beta_{2}\\ grade_{2}+...+\\beta_{n}\\ variable_{n}+e\\]variable “Default” winch originally name “loan_status”; two labels:“Charge ” means credit grantor wrote account receivables loss closed future charges. account displays status “charge ,” closed future use, although customer still owns debt. example, consider Charged equivalent Default Fully Paid default.previous output, show “Default” variable class “character,” function apply accept numeric factor variables. transform variable “factor.”","code":"\ncredit<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/credit.csv\")\nstr(credit[,1:5])\n#> 'data.frame':    873 obs. of  5 variables:\n#>  $ Default    : chr  \"Fully Paid\" \"Fully Paid\" \"Fully Paid\" \"Fully Paid\" ...\n#>  $ term       : int  1 1 2 2 1 1 1 1 1 1 ...\n#>  $ installment: num  123 820 433 290 405 ...\n#>  $ grade      : int  3 3 2 6 3 2 2 1 2 3 ...\n#>  $ emp_title  : num  299 209 623 126 633 636 481 540 631 314 ...\ntable(credit[,\"Default\"])\n#> \n#> Charged Off  Fully Paid \n#>         145         728\ncredit[,\"Default\"]<-factor(credit[,\"Default\"])"},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"take-a-quick-look-at-the-data-structure","chapter":"1 ML in the bussines lascape and data collection","heading":"1.5 Take a Quick Look at the Data Structure","text":"ML literature suggests looking data structure see issues, numerical categorical variables, missing values, etc. several books cover , cover book. suggest chapter two book (Bernal 2023). However, include section book? expect book introductory guide ML. , book’s structure steps develop ML analysis without redundant materials.","code":""},{"path":"training-and-evaluating-regression-models.html","id":"training-and-evaluating-regression-models","chapter":"2 Training and evaluating regression models","heading":"2 Training and evaluating regression models","text":"","code":""},{"path":"training-and-evaluating-regression-models.html","id":"model-training","chapter":"2 Training and evaluating regression models","heading":"2.1 Model training","text":"goal machine learning models regression predict dependent variable, \\(y\\). example, house pricing data set described chapter 1, defined dependent variable “SalePrice”, independent variables MSSubClass, MSZoning others data set.\\[SalePrice=\\beta_{0}+\\beta_{1}\\ MSSubClass + \\beta_{2}\\ MSZoning+ ....+x_{n}+ e\\]\\(e\\) error term. regression model aims estimate parameters \\(\\beta_{1}, \\beta_{2},...,\\beta_{n}\\), predict SalePrice. following predicted model. call training.\\[\\hat{SalePrice}=\\hat{\\beta_{0}}+\\hat{\\beta_{1}}MSSubClass+\\hat{\\beta_{2}}MSZoning+....+\\hat{\\beta_{n}}x_{n} \\]hat parameters indicates estimated parameters.\nNote: learning ML, convenient understand models step step. familiar estimating regression prediction, can skip following steps Training test set (Back testing).exemplify ML regression models works, first estimate two independent variables: MSSubClass MSZoning.\\[SalePrice=\\beta_{0}+\\beta_{1}\\ MSSubClass + \\beta_{2}\\ MSZoning + \\epsilon \\]R, use “lm” function run regression model Ordinary Least squaresAs result, get following estimated model:\\[`\\hat{r con[2]`}= 354837.1+-233.4\\ MSSubClass + -29665.2\\ MSZoning\\]Machine Learning (ML), concerned coefficient significance; chapter one, explain differences Machine Learning models causality approach ones explain . ML models, predict dependent variable, case, SalePrice, given certain features independent variables.Suppose want predict SalePrice values variables MSSubClass MSZoning 20 4, respectively. following formula predicts SalePrice taking parameters OLS regression:SalePrice=354837.1+354837.1 * 20+-29665.2*4 = 231508.1The result 231508.1 predicts SalePrice variables MSSubClass MSZoning take values 20 4, respectively.Remember previous result exposition proposes. use “predict” function, gives us result. must add arguments OLS model object data frame features want predict.still determining previous prediction good. moment, can compare observation “house” data set, example, first one:prediction far SalePrice observation “house” data set. course, need add independent variables procedures, cover subsequent sections.","code":"\nhouse<-read.csv(\"data/house_clean.csv\")\n#house<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/housing.csv\")\n\nhouse_model<-lm(SalePrice~MSSubClass+MSZoning,data=house)\nsummary(house_model)\n#> \n#> Call:\n#> lm(formula = SalePrice ~ MSSubClass + MSZoning, data = house)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -169125  -58658  -26555   43751  532828 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 354837.1    30654.8  11.575  < 2e-16 ***\n#> MSSubClass    -233.4      102.0  -2.289   0.0224 *  \n#> MSZoning    -29665.2     7528.4  -3.940 9.12e-05 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 90790 on 581 degrees of freedom\n#> Multiple R-squared:  0.03625,    Adjusted R-squared:  0.03294 \n#> F-statistic: 10.93 on 2 and 581 DF,  p-value: 2.194e-05\npredict(house_model,house_test)\n#>        1 \n#> 231508.1\nhead(house[1,2:4])\n#>   SalePrice MSSubClass MSZoning\n#> 1    181500         20        4"},{"path":"training-and-evaluating-regression-models.html","id":"training-and-test-set-back-testing","chapter":"2 Training and evaluating regression models","heading":"2.1.1 Training and test set (Back testing)","text":"previous section, made one prediction compared given observation. machine learning literature common apply testing procedure several observations. book, call back-testing, divides data set training testing, often called in_sample out_sample. previous example, house_test must data frame. However, instead one observation two independent variables, contain many observations independent variables.answer need back-testing, think want validate prediction performance, least two alternatives:Alternative 1: Estimate ML model, make prediction wait time, example, 30 days, verify prediction good ; forecast good (close real value), train test , let’s say 30 days .Alternative 2 (one apply): Take aside observations, assuming observations don’t know store data frame called “test.” Train test ML model. making good prediction, train test model get good prediction performance.common practice divide data set training (80% observations) testing (20%). However, authors suggest splitting Training Set, Validation Set Test Set (Lantz 2019). latter case, proposal train model training set (example, 60% data), cross-validation (procedure cover ) validation set (example, 20% data), model good prediction performance, test test set (20% data).book, use methods. start chapter first one, cross-validation chapter, cover second one.housing prices data set, split randomly 80%, applying function sample.“set.seed” function helps us control results getting aleatory partition data; otherwise, get different result every time run R chunk. spirit book compare various methods methodologies without concern possible differences models processes result random partition.compare original house data set previous output, “rownames” (ID) different order selected randomly. Another important distinction observations house_test data set complement house_train. words, observations (IDs) training set aren’t test, vice versa.","code":"\nset.seed (26)\ndim<-dim(house)\ntrain_sample<-sample(dim[1],dim[1]*.8)\nhouse_train <- house[train_sample, ]\nhouse_test  <- house[-train_sample, ]\nhead(house_train[,1:5])\n#>      Id SalePrice MSSubClass MSZoning LotFrontage\n#> 64   64    163000         20        4          80\n#> 540 540    170000         80        4         102\n#> 200 200    155000         70        5          50\n#> 171 171    142000         20        4          65\n#> 41   41    250000         60        2          75\n#> 268 268    155000         60        4          70\nhead(house_test[,1:5])\n#>    Id SalePrice MSSubClass MSZoning LotFrontage\n#> 17 17    165500         20        4          70\n#> 20 20    153000         20        4          74\n#> 26 26    385000         20        4          68\n#> 31 31    317000         60        4          76\n#> 42 42    190000         20        4         105\n#> 43 43    383970         60        4          77"},{"path":"training-and-evaluating-regression-models.html","id":"performance-measure","chapter":"2 Training and evaluating regression models","heading":"2.1.2 Performance Measure","text":"","code":""},{"path":"training-and-evaluating-regression-models.html","id":"rmse","chapter":"2 Training and evaluating regression models","heading":"2.1.3 RMSE","text":"previous section, discussed whether prediction good (prediction performance). section formally defines metrics prediction performance.first metric Root Mean Square Error (RMSE). mathematical formula compute RMSE :\\[RMSE =\\sqrt{\\frac{1}{n}\\ \\sum_{=1}^{n} (y_{}-\\hat{y_{}})^{2}} \\]\\(\\hat{y_{}}\\) prediction ith observation, \\(y_{}\\) ith observation independent variable store test set, n number observations.\\[\\hat{y_{}}=\\hat{\\beta_{0}}+\\hat{\\beta_{1}}x_{1}+,..,+\\hat{\\beta_{n}}x_{n}\\]can estimate RMSE using training data set. generally, care well model works training set. Rather, interested model performance tested unseen data; , try RMSE test data set validation set cross-validation. lower test RMSE, better prediction.estimate RMSE housing example. time use variables data set. train model, use training data set. “lm” function requires adding dot symbol “~.”make prediction, use test data set.previous output, numbers prediction (17,20,26,31, etc.) row number test data frame model predicted. calling RMSE test test test data set. code estimate RMSE :ML’s main idea minimize RMSE test possible. subsequent sections, show accomplish .","code":"\nhouse_model<-lm(SalePrice~.,data=house_train)\nsummary(house_model)\n#> \n#> Call:\n#> lm(formula = SalePrice ~ ., data = house_train)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -311484  -19921   -1159   18474  219630 \n#> \n#> Coefficients:\n#>                 Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)    1.535e+06  3.384e+06   0.454  0.65040    \n#> Id            -1.208e+01  1.268e+01  -0.953  0.34119    \n#> MSSubClass    -2.860e+02  1.367e+02  -2.092  0.03706 *  \n#> MSZoning      -1.286e+03  4.747e+03  -0.271  0.78667    \n#> LotFrontage   -3.126e+02  1.021e+02  -3.061  0.00235 ** \n#> LotArea        5.531e-01  2.113e-01   2.618  0.00918 ** \n#> LotShape      -2.770e+03  1.680e+03  -1.649  0.09984 .  \n#> LotConfig     -1.144e+03  1.422e+03  -0.805  0.42134    \n#> Neighborhood   3.287e+02  4.110e+02   0.800  0.42439    \n#> Condition1    -1.679e+03  2.579e+03  -0.651  0.51547    \n#> BldgType       1.202e+03  4.281e+03   0.281  0.77909    \n#> HouseStyle    -2.336e+03  1.830e+03  -1.276  0.20267    \n#> OverallQual    1.797e+04  3.096e+03   5.806 1.28e-08 ***\n#> OverallCond    9.543e+03  2.960e+03   3.224  0.00136 ** \n#> YearRemodAdd  -1.525e+01  2.074e+02  -0.074  0.94142    \n#> RoofStyle      3.244e+03  2.784e+03   1.165  0.24465    \n#> Exterior1st   -1.142e+03  7.714e+02  -1.481  0.13937    \n#> MasVnrType     1.049e+03  3.500e+03   0.300  0.76450    \n#> MasVnrArea     5.071e+01  1.210e+01   4.189 3.42e-05 ***\n#> ExterQual     -8.256e+03  4.918e+03  -1.679  0.09400 .  \n#> ExterCond      6.708e+02  3.758e+03   0.178  0.85842    \n#> Foundation     7.901e+03  5.232e+03   1.510  0.13179    \n#> BsmtQual      -1.073e+04  3.331e+03  -3.222  0.00137 ** \n#> BsmtExposure  -5.919e+03  2.114e+03  -2.801  0.00534 ** \n#> BsmtFinType1  -3.214e+03  1.588e+03  -2.024  0.04361 *  \n#> BsmtFinSF1    -2.507e+01  9.435e+00  -2.657  0.00819 ** \n#> BsmtUnfSF     -1.827e+01  9.992e+00  -1.828  0.06825 .  \n#> HeatingQC     -6.688e+02  1.636e+03  -0.409  0.68287    \n#> CentralAir     4.803e+03  2.020e+04   0.238  0.81217    \n#> Electrical     7.323e+02  3.113e+03   0.235  0.81414    \n#> X1stFlrSF      3.447e+01  1.291e+01   2.671  0.00786 ** \n#> X2ndFlrSF      2.999e+01  1.101e+01   2.724  0.00672 ** \n#> BsmtFullBath   1.070e+04  6.443e+03   1.661  0.09749 .  \n#> BsmtHalfBath   4.813e+03  8.795e+03   0.547  0.58453    \n#> FullBath       1.772e+04  6.958e+03   2.547  0.01123 *  \n#> HalfBath       1.030e+04  6.666e+03   1.545  0.12303    \n#> BedroomAbvGr  -5.016e+03  4.631e+03  -1.083  0.27937    \n#> KitchenQual   -7.330e+03  3.546e+03  -2.067  0.03936 *  \n#> TotRmsAbvGrd   5.196e+03  2.754e+03   1.887  0.05987 .  \n#> Fireplaces     1.291e+04  6.274e+03   2.057  0.04029 *  \n#> FireplaceQu   -3.753e+03  2.213e+03  -1.696  0.09072 .  \n#> GarageType    -4.360e+02  1.880e+03  -0.232  0.81674    \n#> GarageYrBlt   -1.237e+02  1.902e+02  -0.650  0.51576    \n#> GarageFinish  -2.065e+03  3.550e+03  -0.582  0.56114    \n#> GarageArea     4.217e+01  1.718e+01   2.454  0.01453 *  \n#> PavedDrive     3.140e+03  8.320e+03   0.377  0.70602    \n#> WoodDeckSF     1.127e+01  1.993e+01   0.566  0.57191    \n#> OpenPorchSF   -1.189e+01  3.404e+01  -0.349  0.72699    \n#> MoSold        -4.744e+02  7.750e+02  -0.612  0.54080    \n#> YrSold        -6.036e+02  1.682e+03  -0.359  0.71984    \n#> SaleType      -1.475e+03  1.799e+03  -0.820  0.41280    \n#> SaleCondition  4.838e+03  2.319e+03   2.087  0.03752 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 44510 on 415 degrees of freedom\n#> Multiple R-squared:  0.7822, Adjusted R-squared:  0.7554 \n#> F-statistic: 29.22 on 51 and 415 DF,  p-value: < 2.2e-16\nhouse_predict<-predict(house_model,house_test)\nhead(house_predict)\n#>       17       20       26       31       42       43 \n#> 152651.6 135846.9 321903.0 312590.4 219878.9 331208.6\nchp3_swr<-sqrt(mean((house_test[,\"SalePrice\"]-house_predict)^2 ,na.rm = T))\nchp3_swr\n#> [1] 47889.11"},{"path":"training-and-evaluating-regression-models.html","id":"mean-absolute-error-mae","chapter":"2 Training and evaluating regression models","heading":"2.1.4 Mean absolute error (MAE)","text":"RMSE generally preferred performance measure regression models. However, measuring model performance MAE useful data outliers.\\[MAE =\\frac{1}{n}\\ \\sum_{=1}^{n} |y_{}-\\hat{y_{}}|\\]\nexample, Mean absolute error test (MAE) :","code":"\nmean(abs(house_test[,\"SalePrice\"]-house_predict),na.rm = T)\n#> [1] 28038.65"},{"path":"training-and-evaluating-regression-models.html","id":"r-squared","chapter":"2 Training and evaluating regression models","heading":"2.1.5 R-squared","text":"called Goodness--Fit measure. define R-squared follows:\n\\[R^2=SSE/SST\\]interpret fraction sample variation dependent variable \\(y\\), explained independent variable \\(X\\). \\(SST\\) total sum squares,\\[SST=\\frac{1}{n}\\ \\sum_{=1}^{n}(y_{}-\\overline{y})^{2},\\]\\(\\overline{y}\\) sample average \\(y_{}\\). indicator SST measures total sample variation \\(y_{}\\). measure SSE explained sum squares,\\[SSE=\\frac{1}{n}\\ \\sum_{=1}^{n}(\\hat{y_{}}-\\overline{y})^{2}.\\]\nSSE measures sample variation \\(\\hat{y_{}}\\) (Wooldridge 2020).","code":""},{"path":"training-and-evaluating-regression-models.html","id":"model-selection","chapter":"2 Training and evaluating regression models","heading":"2.1.6 Model Selection","text":"can improve RMSE several ways. first one applying ML methodologies. section starts subset selection, Regularization dimension Reduction.subset selection consists independent variables selection among available independent variables, helps improve model’s predictability performance. housing example 51 independent variables, including ID. must careful choosing among variables. see define train_RMSE:\\[train\\_RMSE =\\sqrt{\\frac{1}{n}\\ \\sum_{=1}^{n} (y_{}-\\hat{y_{}})^{2}}=\\sqrt{\\frac{1}{n}\\ train\\_RSS}\\]:\\[train\\_RSS = \\sum_{=1}^{n} (y_{}-\\hat{y_{}})^{2}=e_{1}^2+e_{2}^2+,..+e_{n}^2 \\]\n\\(train\\_RSS\\) explained sum squares residual sum squares training data set. consequence, RMSE decrease \\(train\\_RSS\\) decrease. According (James et al. 2017), \\(train\\_RSS\\) decrease number independent variables included models increases, even variables unrelated independent variable (significant). Therefore, use statistics select best model training data set, always end model involving variables. problem low \\(RSS\\) indicates model low training error, whereas wish choose model low test error (James et al. 2017). problem overfitting data, term explain (Suzuky 2022).solve , indicators looks minimize RSS penalize inclusion independent variables, example, Akaike Information Criterion AIC:solve problem, use indicators aim minimize RSS, penalizing inclusion independent variables, example, Akaike Information Criterion AIC:\\[AIC=\\frac{1}{n \\hat{\\sigma^2}}(RSS+2d\\hat{\\sigma^2})\\]\\(\\hat{\\sigma^2}\\) estimate variance error term, \\(d\\) number predictors, \\(n\\) number observations. AIC adds penalty \\(2d\\hat{\\sigma^2}\\) training RSS adjust training error tends underestimate test error. penalty increases number predictors model increases; intended adjust corresponding decrease training RSS (statistical_learning?). decision criteria model lower AIC.use function step, chooses variables according AIC.trace=F argument printing models algorithm evaluates. direction=“,” selection methods. Forward selection begins model containing independent variables adds predictors model one time predictors model; finally selects model (combination variables) lowest AIC. important notice algorithm selected among possible combinations. example, case 51 vaiiravles, imply \\(2^{51}=2.2518e+15\\). instead, evaluate \\(RSS = \\sum_{k=o}^{p-1} (p-k)=1+p(p+1)/2=1+50(50+1)/2=1327\\) models (statistical_learning?).hand, backward begins full least squares model containing \\(p\\) predictors interactively removes least useful predictor, one time. “” argument implies applies procedures, forward backward.exposition purposes, print AIC criterion two models, one 51 variables one variable selection based AIC.expected, model using step function lowest AIC. Also, estimate RMSE test data set step model, get:lower one full variables model.","code":"\nstep_house<-step(house_model,house_train,trace = F,direction=\"both\")\nsummary(step_house)\n#> \n#> Call:\n#> lm(formula = SalePrice ~ MSSubClass + LotFrontage + LotArea + \n#>     LotShape + HouseStyle + OverallQual + OverallCond + Exterior1st + \n#>     MasVnrArea + ExterQual + Foundation + BsmtQual + BsmtExposure + \n#>     BsmtFinType1 + BsmtFinSF1 + BsmtUnfSF + X1stFlrSF + X2ndFlrSF + \n#>     BsmtFullBath + FullBath + HalfBath + KitchenQual + TotRmsAbvGrd + \n#>     Fireplaces + FireplaceQu + GarageArea + SaleCondition, data = house_train)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -320194  -19377   -1434   17833  220366 \n#> \n#> Coefficients:\n#>                 Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)    4.120e+04  4.318e+04   0.954 0.340604    \n#> MSSubClass    -2.299e+02  6.787e+01  -3.388 0.000768 ***\n#> LotFrontage   -3.216e+02  9.392e+01  -3.424 0.000674 ***\n#> LotArea        5.828e-01  2.036e-01   2.862 0.004411 ** \n#> LotShape      -2.812e+03  1.537e+03  -1.829 0.068033 .  \n#> HouseStyle    -2.889e+03  1.553e+03  -1.860 0.063500 .  \n#> OverallQual    1.893e+04  2.922e+03   6.478 2.49e-10 ***\n#> OverallCond    9.620e+03  2.386e+03   4.032 6.53e-05 ***\n#> Exterior1st   -1.302e+03  7.056e+02  -1.845 0.065677 .  \n#> MasVnrArea     5.605e+01  1.050e+01   5.338 1.51e-07 ***\n#> ExterQual     -8.628e+03  4.554e+03  -1.894 0.058823 .  \n#> Foundation     8.200e+03  4.347e+03   1.886 0.059902 .  \n#> BsmtQual      -1.178e+04  3.121e+03  -3.774 0.000182 ***\n#> BsmtExposure  -5.687e+03  2.000e+03  -2.844 0.004665 ** \n#> BsmtFinType1  -3.146e+03  1.507e+03  -2.088 0.037393 *  \n#> BsmtFinSF1    -2.498e+01  8.965e+00  -2.786 0.005571 ** \n#> BsmtUnfSF     -2.111e+01  9.549e+00  -2.211 0.027582 *  \n#> X1stFlrSF      3.817e+01  1.159e+01   3.292 0.001074 ** \n#> X2ndFlrSF      2.565e+01  9.388e+00   2.732 0.006540 ** \n#> BsmtFullBath   9.998e+03  5.832e+03   1.714 0.087191 .  \n#> FullBath       1.689e+04  5.966e+03   2.831 0.004847 ** \n#> HalfBath       1.139e+04  6.012e+03   1.895 0.058711 .  \n#> KitchenQual   -7.131e+03  3.345e+03  -2.132 0.033563 *  \n#> TotRmsAbvGrd   4.149e+03  2.422e+03   1.713 0.087404 .  \n#> Fireplaces     1.359e+04  6.017e+03   2.259 0.024362 *  \n#> FireplaceQu   -4.135e+03  2.073e+03  -1.995 0.046680 *  \n#> GarageArea     4.338e+01  1.484e+01   2.923 0.003649 ** \n#> SaleCondition  4.348e+03  2.211e+03   1.967 0.049854 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 43750 on 439 degrees of freedom\n#> Multiple R-squared:  0.7774, Adjusted R-squared:  0.7637 \n#> F-statistic: 56.79 on 27 and 439 DF,  p-value: < 2.2e-16\nprint(extractAIC(step_house)[2])\n#> [1] 10008.02\nprint(extractAIC(house_model)[2])\n#> [1] 10045.9\nstep_house_predict<-predict(step_house,house_test)\nmean(abs(house_test[,\"SalePrice\"]-step_house_predict),na.rm = T)\n#> [1] 28117.64\nsqrt(mean((house_test[,\"SalePrice\"]-house_predict)^2 ,na.rm = T))\n#> [1] 47889.11"},{"path":"training-and-evaluating-regression-models.html","id":"overfittingunderfitting","chapter":"2 Training and evaluating regression models","heading":"2.1.7 Overfitting/Underfitting","text":"Overfitting occurs ML model trained learn noise (.e., non-representative data result chance) rather patterns trends data. following text (James et al. 2017):“general rule, use flexible methods, variance increase bias decrease. case, increase flexibility, bias tends initially decrease faster variance increases.Consequently, expected test MSE declines. However, point increasing flexibility little impact bias starts significantly increase variance.happens test MSE increases” .TTo explain better, use MSE decomposition. expected MSE decomposed following.\\[E(MSE) =E(\\frac{1}{n}\\ \\sum_{=1}^{n} (y-\\hat{y})^2)= E(\\epsilon^2)+E ((y-\\hat{y})^2)=Var(e)+Var(\\hat{y})+[Bias(\\hat{y})]^2\\]\n\\[Bias(\\hat{y})=y-E(\\hat{y})\\]\\[Var(\\hat{y})=E((y-E(\\hat{y}))^2)\\]See proof Appendix chapter.idea evaluating methodologies based notion Bias-Variance Trade-:\\(Var[e]\\) variance error term, call irreducible part.\\(E (y_{0}-\\hat{y})^{2}\\) average MSE test—————esto ———Models frequently overfit small number training samples relative flexibility complexity model. model considered high variance low bias.supervised model overfit typically perform well data model trained , perform poorly data model seen (Krishnan 2020).Underfitting occurs machine learning model capture variations data – variations data caused noise. model considered high bias, low variance.\nsupervised model underfit typically perform poorly data model trained , data model seen . Examples overfitting, underfitting, good balanced model (Krishnan 2020).","code":"\nset.seed (26)\ndim<-dim(house)\ntrain_sample<-sample(dim[1],dim[1]*.8)\nhouse_train <- house[train_sample, ]\nhouse_test  <- house[-train_sample, ]\n#indes<-\"OverallQual\"\n#indes<-\"YearRemodAdd\"\n#indes<-\"X2ndFlrSF\"\nindes<-\"GarageArea\"\nform<-as.formula(paste(\"SalePrice\", \"~\", indes))\nmod<-lm(form, data = house_train)\n\nmod2<-lm(form, data = house_test)\nplot(form, data = ,house_test,ylim=c(91000,350000),xlim=c(200,900))\nabline(mod)\nabline(mod2)\n\n#plot(form, data = ,house_train)\nmod<-lm(form, data = house_train)\n#abline(mod)\nmod2<-lm(form, data = house_test)\nplot(form, data = ,house_test)\nabline(mod)\nabline(mod2)\n#indes<-\"OverallQual\"\n#indes<-\"YearRemodAdd\"\nindes<-\"X2ndFlrSF\"\n#indes<-\"GarageArea\"\nplot(house_train[,\"SalePrice\"],house_train[,indes])\nabline(a = 500, b = 1)\nplot(house_test[,\"SalePrice\"],house_test[,indes])\nh_vars<-c(\"SalePrice\",colnames(house_train[45:49]))\n\npanel.cor <- function(x, y, digits = 2, prefix = \"\", cex.cor, ...)\n{\n    usr <- par(\"usr\"); on.exit(par(usr))\n    par(usr = c(0, 1, 0, 1))\n    r <- abs(cor(x, y,use=\"pairwise.complete.obs\"))\n    txt <- format(c(r, 0.123456789), digits = digits)[1]\n    txt <- paste0(prefix, txt)\n    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\n    text(0.5, 0.5, txt, cex = cex.cor * r)\n}\npairs(na.omit(house_train[,h_vars]),upper.panel=panel.cor)\n#knitr::include_graphics('images/overfit.jpg')"},{"path":"training-and-evaluating-regression-models.html","id":"regularization-models","chapter":"2 Training and evaluating regression models","heading":"2.1.8 Regularization models","text":"Regularization method balance overfitting underfitting model training. overfitting\nunderfitting problems ultimately cause poor predictions new data.Regularization technique adjust closely model trained fit historical data. One way apply\nregularization adding parameter penalizes loss function tuned model overfit.allows use regularization parameter affects closely model trained fit historical\ndata. regularization prevents overfitting, less regularization prevents underfitting. Balancing \nregularization parameter helps find good tradeoff bias variance.","code":"\nsummary(house[,\"SalePrice\"])\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>   62383  159988  193690  222864  266625  755000"},{"path":"training-and-evaluating-regression-models.html","id":"appendix","chapter":"2 Training and evaluating regression models","heading":"2.2 Appendix","text":"","code":""},{"path":"training-and-evaluating-regression-models.html","id":"proof-of-emse-varepsilonvarhatybiashaty2","chapter":"2 Training and evaluating regression models","heading":"2.2.1 Proof of \\(E(MSE) =Var(\\epsilon)+Var(\\hat{y})+[Bias(\\hat{y})]^2\\)","text":"\\[E ((y-\\hat{y})^2)=E((y-E(\\hat{y})+E(\\hat{y})-\\hat{y})^2)=(y-E(\\hat{y}))^2+E((E(\\hat{y})-y)^2)+2E(y-E(\\hat{y}))\\ E(E(\\hat{y})-\\hat{y})\\]\\[2E(y-E(\\hat{y}))\\ E(E(\\hat{y})-\\hat{y})=2E(y-E(\\hat{y}))\\ (E(\\hat{y})-E(\\hat{y}))=0\\]\\[2E(y-E(\\hat{y}))\\ E(E(\\hat{y})-\\hat{y})=2E(y-E(\\hat{y}))\\ (E(\\hat{y})-E(\\hat{y}))=0\\]","code":""},{"path":"training-and-evaluating-classification-models.html","id":"training-and-evaluating-classification-models","chapter":"3 Training and evaluating classification models","heading":"3 Training and evaluating classification models","text":"linear regression, OLS, dependent variable continuous, SalePrice variable, sense house price $62,383 $755000. However, situations dependent variable two categories: women men, finance, signal buy sell, etc. case, call variables categorical. One popular classification models logistic regression linear discriminant analysis.","code":""},{"path":"training-and-evaluating-classification-models.html","id":"logit-model","chapter":"3 Training and evaluating classification models","heading":"3.1 Logit model","text":"section work credit data set. Remember describe credit data set chapter one, define model:\\[ Default=\\beta_{0}+\\beta_{1}\\ x_{1} + \\beta_{2}\\ x_{2}+ ....+\\beta_{n} x_{n}+\\epsilon \\]algorithm procedures runs binary response models, logit, first transforms categories, case “Charged ” “Fully Paid”, numerical values, zero one. assigns probability \\(y\\) takes value one \\(P(y=1)= \\pi\\) takes value zero \\(P(y=0)= 1-\\pi\\). statistical analysis aims investigate relationship probability \\(\\pi(X)\\) independent variables \\(X=x_{1}, x_{2}...x_{n}\\) . convenient construct model capable describing effect \\(pi\\) changes \\(X=x_{1}, x_{2}...x_{n}\\), form function \\(g(\\pi)\\) (McCullagh FRS 1989).logic model function \\(g(\\pi)=\\log{(\\pi/(1-\\pi))}\\)\\[g(\\pi)=\\log{(\\pi/(1-\\pi))}=beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n} \\]Taking exponential sides, get:\\[\\pi/(1-\\pi)= \\exp{(beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n})}\\]get probability, need transformation like :\\[\\pi= \\frac{\\exp{(beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n})}}{1+\\exp{(beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n})}}\\]variable default categorical variable becasue takes folowing two values:function run logistic model R doesn´t accept character values, numeric factor. transform variable “factor.”split training test data sets, housing example.function run logistic model “glm”.paragraph , explain warning red: “glm.fit: fitted probabilities numerically 0 1 occurred”.use predict function make prediction.parameters estimate “glm” function, adding family=binomial() type= “response”, parameters equation.\\[\\pi= \\frac{\\exp{(beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n})}}{1+\\exp{(beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n})}}\\]Consequently, make prediction, get probability.However, expected prediction either Charged Fully Paid, prediction numbers cero one.Finally, must still resolve whether prediction Charged Fully Paid. transform following code.transform forecast category, establish threshold 0.5; prediction higher 0.5, convert “Fully Paid” otherwise “Charged .” “ok” wonder threshold 0.5. estimating prediction accuracy model, change threshold improve prediction performance.suggest verifying comparing resulting structure original data structure. case, “Charged ” 82 % observations (144 / (144+31)).complete data set (train + test), percentage 83%, consistent result. inconsistent result 87% prediction.","code":"\ncredit<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/credit.csv\")\n\nc2<-ifelse(credit[,\"Default\"]==\"Charged Off\" ,\"No_default\",\"default\") \ncredit[,\"Default\"]<-c2\ntable(credit[,\"Default\"])\n#> \n#>    default No_default \n#>        728        145\ncredit[,\"Default\"]<-factor(credit[,\"Default\"])\n\nset.seed (43)\ndim<-dim(credit)\ntrain_sample<-sample(dim[1],dim[1]*.8)\ncredit_train <- credit[train_sample, ]\ncredit_test  <- credit[-train_sample, ]\ncredit_model<-glm(Default ~ .,data= credit_train ,family=binomial())\nsummary(credit_model)\n#> \n#> Call:\n#> glm(formula = Default ~ ., family = binomial(), data = credit_train)\n#> \n#> Deviance Residuals: \n#>        Min          1Q      Median          3Q         Max  \n#> -8.169e-05  -2.100e-08  -2.100e-08  -2.100e-08   6.626e-05  \n#> \n#> Coefficients:\n#>                         Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)            2.897e+02  2.242e+06   0.000    1.000\n#> term                   8.976e+01  6.971e+04   0.001    0.999\n#> installment            1.223e-02  2.300e+02   0.000    1.000\n#> grade                 -1.242e+01  3.695e+04   0.000    1.000\n#> emp_title             -1.979e-02  2.551e+02   0.000    1.000\n#> emp_length            -8.469e-01  2.485e+04   0.000    1.000\n#> home_ownership        -9.860e+00  2.016e+04   0.000    1.000\n#> annual_inc             9.569e-05  3.390e+00   0.000    1.000\n#> verification_status   -4.514e+00  3.047e+04   0.000    1.000\n#> purpose                4.467e+00  2.071e+04   0.000    1.000\n#> title                 -1.085e+00  2.569e+04   0.000    1.000\n#> zip_code               2.512e-02  8.173e+02   0.000    1.000\n#> addr_state            -2.288e-01  3.921e+03   0.000    1.000\n#> dti                    1.426e+00  8.380e+03   0.000    1.000\n#> delinq_2yrs            3.129e+00  2.009e+04   0.000    1.000\n#> earliest_cr_line      -3.055e-02  3.341e+02   0.000    1.000\n#> fico_range_high       -5.329e-02  3.646e+03   0.000    1.000\n#> inq_last_6mths         2.822e+00  4.734e+04   0.000    1.000\n#> pub_rec                6.300e-01  1.310e+05   0.000    1.000\n#> revol_bal             -1.205e-03  4.719e+00   0.000    1.000\n#> revol_util            -8.785e-02  8.591e+03   0.000    1.000\n#> total_acc              1.151e+01  5.819e+04   0.000    1.000\n#> total_rec_int         -4.211e-03  1.308e+01   0.000    1.000\n#> recoveries             1.110e-01  2.909e+02   0.000    1.000\n#> last_pymnt_d           7.074e-01  2.275e+03   0.000    1.000\n#> last_pymnt_amnt       -6.044e-03  1.338e+01   0.000    1.000\n#> last_credit_pull_d     7.841e-01  4.390e+03   0.000    1.000\n#> last_fico_range_high  -6.891e-01  4.561e+02  -0.002    0.999\n#> last_fico_range_low    4.923e-03  2.849e+02   0.000    1.000\n#> tot_coll_amt           1.224e-03  2.466e+00   0.000    1.000\n#> tot_cur_bal            2.562e-05  3.973e-01   0.000    1.000\n#> open_acc_6m            1.177e+01  6.376e+04   0.000    1.000\n#> open_act_il            6.880e+00  3.555e+04   0.000    1.000\n#> open_il_12m           -9.614e+00  1.184e+05   0.000    1.000\n#> open_il_24m            6.398e+00  4.427e+04   0.000    1.000\n#> mths_since_rcnt_il     3.689e-01  1.095e+03   0.000    1.000\n#> total_bal_il           1.374e-04  2.479e+00   0.000    1.000\n#> il_util                3.744e-01  3.611e+03   0.000    1.000\n#> open_rv_12m           -1.147e+01  7.695e+04   0.000    1.000\n#> open_rv_24m            1.252e+01  4.016e+04   0.000    1.000\n#> max_bal_bc             5.577e-04  1.057e+01   0.000    1.000\n#> all_util               3.889e-01  4.471e+03   0.000    1.000\n#> total_rev_hi_lim       3.081e-04  3.123e+00   0.000    1.000\n#> inq_fi                -1.414e-02  1.968e+04   0.000    1.000\n#> total_cu_tl            3.728e+00  9.716e+03   0.000    1.000\n#> inq_last_12m           8.275e-01  3.789e+04   0.000    1.000\n#> acc_open_past_24mths  -1.146e+01  4.153e+04   0.000    1.000\n#> avg_cur_bal           -1.149e-04  1.849e+00   0.000    1.000\n#> bc_open_to_buy        -5.062e-04  1.554e+01   0.000    1.000\n#> bc_util               -5.402e-02  1.391e+03   0.000    1.000\n#> mo_sin_old_il_acct    -5.365e-02  4.233e+02   0.000    1.000\n#> mo_sin_old_rev_tl_op   6.397e-03  8.812e+02   0.000    1.000\n#> mo_sin_rcnt_rev_tl_op  2.013e-01  3.696e+03   0.000    1.000\n#> mo_sin_rcnt_tl         3.205e-02  2.013e+03   0.000    1.000\n#> mort_acc              -1.140e+01  7.505e+04   0.000    1.000\n#> mths_since_recent_bc   8.572e-03  3.642e+03   0.000    1.000\n#> mths_since_recent_inq -1.035e+00  4.052e+03   0.000    1.000\n#> num_accts_ever_120_pd -4.406e+00  2.104e+04   0.000    1.000\n#> num_actv_bc_tl         2.636e+00  7.399e+04   0.000    1.000\n#> num_bc_sats           -4.123e+00  8.698e+04   0.000    1.000\n#> num_bc_tl              3.302e+00  4.186e+04   0.000    1.000\n#> num_il_tl             -1.397e+01  6.543e+04   0.000    1.000\n#> num_op_rev_tl          6.232e+00  6.346e+04   0.000    1.000\n#> num_rev_accts         -1.211e+01  4.019e+04   0.000    1.000\n#> num_rev_tl_bal_gt_0    8.575e-01  6.424e+04   0.000    1.000\n#> num_sats              -5.882e+00  3.720e+04   0.000    1.000\n#> num_tl_op_past_12m     5.371e+00  9.234e+04   0.000    1.000\n#> pct_tl_nvr_dlq         1.125e-01  3.589e+03   0.000    1.000\n#> percent_bc_gt_75      -4.595e-02  3.134e+03   0.000    1.000\n#> pub_rec_bankruptcies  -7.226e+00  1.451e+05   0.000    1.000\n#> total_bc_limit         1.527e-04  1.590e+01   0.000    1.000\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 6.3112e+02  on 697  degrees of freedom\n#> Residual deviance: 8.7225e-08  on 627  degrees of freedom\n#> AIC: 142\n#> \n#> Number of Fisher Scoring iterations: 25\ncredit_predict<-predict(credit_model, newdata=credit_test, type=\"response\")\nhead(credit_predict)\n#>           15           19           24           26           32           34 \n#> 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16\nsummary(credit_predict)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>  0.0000  0.0000  0.0000  0.1754  0.0000  1.0000\ntable(credit[,\"Default\"])\n#> \n#>    default No_default \n#>        728        145\ncredit_predict_char<-ifelse(credit_predict>.5,\"No_default\",\"default\")\ntable(credit_predict_char)\n#> credit_predict_char\n#>    default No_default \n#>        144         31"},{"path":"training-and-evaluating-classification-models.html","id":"performance-measure-in-clasification","chapter":"3 Training and evaluating classification models","heading":"3.2 Performance Measure in clasification","text":"Now measure prediction accuracy, applying confusion Matrix:Confusion matrixIt table categorizes predictions according whether match actual value. One table’s dimensions indicates possible categories predicted values, shows actual values. Although seen 2 x 2 confusion matrices far, matrix can created models predict number class values. following figure shows generic confusion matrix.\nFigure 3.1: Confusion matrix.\nTrue Positive (TP): Correctly classified class interest. True Negative (TN) Correctly classified class interest. False Positive (FP) Incorrectly classified class interest. False Negative (FN): Incorrectly classified class interest.use confusionMatrix function library “caret” credit analysis example. first argument prediction, second argument reference, case, variable “Default” credit_test data set; variables must factors, true variable inside credit_test.review consistency data structure. case, consistent. important keep consistency levels; case, write first “Charged ” reference data set starts label first:Finally, apply function. case, assuming positive class, class interest, “Charged ”:several indicators output, “confusing.” analyze parts. start table:matrix’s left-superior/right-inferior numbers true positive/true negative number observations prediction equals reference. left-inferior/ right-superior numbers matrix true positive/ true negative number observations prediction “” equal reference.numbers get following metrics.accuracy :\\[ accuracy =\\frac{TP+TN}{TP+TN+FP+FN}\\]","code":"\nlibrary(\"caret\")\nDefaultf<-factor(credit_predict_char,levels=c(\"No_default\",\"default\"))\ntable(Defaultf)\n#> Defaultf\n#> No_default    default \n#>         31        144\nhead(credit_test[,\"Default\"])\n#> [1] default default default default default default\n#> Levels: default No_default\nconfu<-confusionMatrix(Defaultf,credit_test[,\"Default\"],positive=\"default\")\nconfu\n#> Confusion Matrix and Statistics\n#> \n#>             Reference\n#> Prediction   default No_default\n#>   default        141          3\n#>   No_default       6         25\n#>                                           \n#>                Accuracy : 0.9486          \n#>                  95% CI : (0.9046, 0.9762)\n#>     No Information Rate : 0.84            \n#>     P-Value [Acc > NIR] : 8.743e-06       \n#>                                           \n#>                   Kappa : 0.8166          \n#>                                           \n#>  Mcnemar's Test P-Value : 0.505           \n#>                                           \n#>             Sensitivity : 0.9592          \n#>             Specificity : 0.8929          \n#>          Pos Pred Value : 0.9792          \n#>          Neg Pred Value : 0.8065          \n#>              Prevalence : 0.8400          \n#>          Detection Rate : 0.8057          \n#>    Detection Prevalence : 0.8229          \n#>       Balanced Accuracy : 0.9260          \n#>                                           \n#>        'Positive' Class : default         \n#> \nconfu$table\n#>             Reference\n#> Prediction   default No_default\n#>   default        141          3\n#>   No_default       6         25\nconfu$table[1]+confu$table[2]\n#> [1] 147\nconfu$overall[1]\n#>  Accuracy \n#> 0.9485714"},{"path":"training-and-evaluating-classification-models.html","id":"the-accuracy","chapter":"3 Training and evaluating classification models","heading":"3.2.1 The accuracy:","text":"proportion true positives true negatives, divided total number predictions. beginning tempting tuning model increase Accuracy, increase true predictions default default, fin. However, machine larning clasficiation theory suggest considering measures.therms confusion matrix, sum green squares toal number observations.\nFigure 3.2: Confusion matrix.\nexplain may need measures, example, imagine scenario company concern default rates, increasing. first thought correct , tuning model predict almost always new customer going pay, “Charge ”. consequence, model discriminating bad new customers, probably ´t pay loan, also good ones. problem bank, ot may end business, bank ´t make loans, winch negative effect profits.contrary, tuning model predict almost always new customer going pay, cause granting loans customers probably sould pay, also negative profits .","code":""},{"path":"training-and-evaluating-classification-models.html","id":"the-sensitivity-or-recall-also-called-the-true-positive-rate","chapter":"3 Training and evaluating classification models","heading":"3.2.2 The sensitivity or Recall (also called the true positive rate)","text":"Measures well predicting variable interest regarding total positive observations reference:\\[ Sensitivity\\ \\ Recall =\\frac{TP}{TP+FN}\\]\nFigure 3.3: Confusion matrix.\nimportance measure relative important analysis. example, imagine scenario company concern default rates, increasing. Mabe first tougth correct , restrictive model toIn case, may problematic predicting someone going pay credit ( “Fully Paid”) reality going pay (“Charged ”) predicting someone going pay credit (“Charged ”) reality pay ( “Fully Paid”). case, sensitivity good indicator.sensitivity 95.92% may high expected, example, follow 95% higher rule. hand, scenario company low default rate expecting expand business. problematic predict someone going pay credit (“Charged ”) reality, pay ( “Fully Paid”).case, class interest may “Fully Paid.”Sensitivity ´s good measure, wee need complement ones, issues, even high, 100%, ´n necessarily mean good. example suppose unlikely case predictions positive ones, every person going pay loan, let´s call noisy model:sensitivity 100%, something wrong, among things rejecting credit application, whic problem ending business negative effect profits. prevent , something similar, metrics Precision.","code":"\nconfu$byClass[1]\n#> Sensitivity \n#>   0.9591837\npre_pos<-rep(\"default\",length(Defaultf))\npre_pos_f<-factor(pre_pos,levels=c(\"default\",\"No_default\"))\n\nnoisy<-confusionMatrix(pre_pos_f,credit_test[,\"Default\"],positive=\"default\")\nnoisy\n#> Confusion Matrix and Statistics\n#> \n#>             Reference\n#> Prediction   default No_default\n#>   default        147         28\n#>   No_default       0          0\n#>                                          \n#>                Accuracy : 0.84           \n#>                  95% CI : (0.7771, 0.891)\n#>     No Information Rate : 0.84           \n#>     P-Value [Acc > NIR] : 0.5502         \n#>                                          \n#>                   Kappa : 0              \n#>                                          \n#>  Mcnemar's Test P-Value : 3.352e-07      \n#>                                          \n#>             Sensitivity : 1.00           \n#>             Specificity : 0.00           \n#>          Pos Pred Value : 0.84           \n#>          Neg Pred Value :  NaN           \n#>              Prevalence : 0.84           \n#>          Detection Rate : 0.84           \n#>    Detection Prevalence : 1.00           \n#>       Balanced Accuracy : 0.50           \n#>                                          \n#>        'Positive' Class : default        \n#> "},{"path":"training-and-evaluating-classification-models.html","id":"precision-or-positive-predicted-values","chapter":"3 Training and evaluating classification models","heading":"3.2.3 Precision or Positive Predicted Values","text":"Measures well predicting variable interest regarding total positive observations prediction:\\[ Precision =\\frac{TP}{TP+FP}\\]proportion true positive predictions positive predictions.Sensitivity Precision similar measure proportion true positives, , former total positive values reference latter total positive values prediction.example, precision penalize model like noisy one, 0.84. intended indicate interesting relevant model’s results , whether predictions diluted meaningless noise (Lantz 2019).Precision original model :higher Precision model also something good . example, model predicted positive predictions, like 2, chance two well classified, TP 2, FP zero, Precision 100%. reference, 28 positive observations total, like example, mean short number positive observations predicting. term bank-business, imply model able identify large portion customers default credit, side problem negative profits.need balance sensitivity (Recall) precision.\ngood classification model may achieve 100% precision 100% sensitivity, reality unlikely happens. Models usually trade precision recall; typically higher precision, lower recall, vicevers. noisy model precision 0.84% sensitivity 95.92% (Krishnan 2020).","code":"\npre<-round(confu$byClass[3],4)\npre\n#> Pos Pred Value \n#>         0.9792#> [1] 0.9792"},{"path":"training-and-evaluating-classification-models.html","id":"the-f1-score","chapter":"3 Training and evaluating classification models","heading":"3.2.4 The F1 Score","text":"metric measure balanced relationship sensitivity (Recall) precision. formula called harmonic mean.\nFigure 3.4: Confusion matrix.\nmodel high F1 score precision recall high. However, model low F1 score one factor low, even 100 percent (Krishnan 2020). example, F1 Score :","code":"\nround(2*(sen*pre_v)/(sen+pre_v),4)\n#> [1] 1.9386"},{"path":"training-and-evaluating-classification-models.html","id":"the-specificity-true-negative-rate-measures-the-proportion-of-negatives-that-were-correctly-classified","chapter":"3 Training and evaluating classification models","heading":"3.2.5 The specificity (true negative rate) measures the proportion of negatives that were correctly classified:","text":"\\[ specificity =\\frac{TN}{TN+FP}\\]latter implies 95.92% time, predicting well class “Fully Paid.","code":"\nconfu$byClass[2]\n#> Specificity \n#>   0.8928571"},{"path":"training-and-evaluating-classification-models.html","id":"kappa","chapter":"3 Training and evaluating classification models","heading":"3.2.6 kappa","text":"Adjusts accuracy taking account class imbalance, refers trouble associated data large majority records belonging single class. kappa statistic adjust data sets severe class imbalance classifier can obtain high accuracy simply always guessing frequent class (Lantz 2019). call agreement actual proportions classes.\\[\\kappa=\\frac{Pr()-Pr(e)}{1-Pr(e)} \\]\nPr() proportion actual agreement Pr(e) refers expected agreement classifier true values, assumption chosen random","code":"Poor agreement = less than 0.20\nFair agreement = 0.20 to 0.40\nModerate agreement = 0.40 to 0.60\nGood agreement = 0.60 to 0.80\nVery good agreement = 0.80 to 1.00"},{"path":"training-and-evaluating-classification-models.html","id":"the-roc-curve","chapter":"3 Training and evaluating classification models","heading":"3.2.7 The ROC Curve","text":"receiver operating characteristic (ROC) looks similar balance, Precision/Recall, Recall false positive rate (FPR). focus total\\[false\\_positive\\_rate (FPR)=(1-Specificity)= \\frac{FP}{FP+TN}\\]therms confusion matrix, blue vector grey one. proportion TP, well positive predicted, positive total reference proportion FP, bad positive predicted, negative total reference.\nFigure 3.5: Confusion matrix.\nuse function “roc” “pROC” library (Robin et al. 2011).\nfirst argument reference (“response”) second one prediction(“predictor”), probablity.Also need add levels:apply function:reults, message direction comparing group median higher take direction accordingly. used generates Sensitivities specificity’s given probabilities (Thresholds). Remember previous chunk trasnform prediction, porbability, labels c(“Fully Paid”,“Charged ”), used code like :ifelse(credit_predict>.5,“Fully Paid”,“Charged ”). example, arbitrarily selected Thresholds 0.5. function generates several thresholds considering means two consecutive values observed data. example generated 17 thresholds, estimate 17 sensitibities `specificity’s.print.thres.pattern=“thresholds: %.3f : %.3f : %.3f”)Best = “T” argument controls optimal threshold determined.“youden” Youden’s J statistic (Youden, 1950) employed. optimal cut-threshold maximizes distance identity (diagonal) line. Can shortened “y”. optimality criterion :\\[max(sensitivities + specificities)\\]“closest.topleft” optimal threshold point closest top-left part plot perfect sensitivity specificity. Can shortened “c” “t”.\noptimality criterion (Robin et al. 2011):\\[min((1-sensitivities)^2 + (1-specificities)^2)\\]","code":"\nlibrary(pROC)\nref<- credit_test[,\"Default\"]\npredict_glm<-predict(credit_model, newdata=credit_test, type=\"response\")\nhead(predict_glm)\n#>           15           19           24           26           32           34 \n#> 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16\nlevels(ref)\n#> [1] \"default\"    \"No_default\"\nroc0<-roc(ref, predict_glm, levels = rev(levels(ref)),ret=\"coords\") \nroc0\n#> \n#> Call:\n#> roc.default(response = ref, predictor = predict_glm, levels = rev(levels(ref)),     ret = \"coords\")\n#> \n#> Data: predict_glm in 28 controls (ref No_default) > 147 cases (ref default).\n#> Area under the curve: 0.982\n# This function prints the ROC Curve. \n# roc0  is a object type \"roc\"\n# p is a vector of probabilities \n# best is a method to estimate the best model (see an expination below)\nMy_roc<-function(roc0,best=c(\"FALSE\",\"youden\",\"closest.topleft\"))\n  {\n  yl<-\"Recall or sensitivity\"\n  xl<-\"False pos or (1-specificity)\"\n  pat<-\"thresholds: %.3f \\n\\nSp: %.3f \\nSens: %.3f\"\n  if (best==F){\n    plot(roc0,print.auc=TRUE, ylab=yl, xlab=xl,auc.polygon=TRUE, \n         \n         legacy.axes=T,\n         auc.polygon.col=\"lightblue\",\n         print.thres = c(.5),\n         print.thres.pattern=pat,\n         max.auc.polygon=TRUE,\n         print.thres.pch=16)\n     \n\n  } else if (best==\"youden\") {  \n    plot(roc0,  ylab=yl, xlab=xl, print.thres=\"best\", print.thres.best.method=\"youden\", \n         legacy.axes=TRUE, \n         print.auc=TRUE, auc.polygon=TRUE,auc.polygon.col=\"lightblue\",\n         print.thres.cex = .9 ,print.thres.pattern=pat,max.auc.polygon=TRUE,print.thres.pch=16)\n  } else if (best==\"closest.topleft\")  {\n    plot(roc0,  ylab=yl, xlab=xl, print.thres=\"best\", \n         legacy.axes=TRUE, \n         print.thres.best.method=\"closest.topleft\",print.auc=TRUE,\n         auc.polygon=TRUE,auc.polygon.col=\"lightblue\",\n         print.thres.cex = .9,\n         print.thres.pattern=pat,max.auc.polygon=TRUE,print.thres.pch=16)\n}\n}\n\nMy_roc(roc0,best=FALSE)\nMy_roc(roc0,best=\"youden\")\nMy_roc(roc0,best=\"closest.topleft\")"},{"path":"cross-validation.html","id":"cross-validation","chapter":"4 Cross Validation","heading":"4 Cross Validation","text":"","code":""},{"path":"cross-validation.html","id":"regression-cross-validation","chapter":"4 Cross Validation","heading":"4.1 Regression Cross Validation","text":"previous chapter, split sample training testing. partition different samples? Remember last chapter, got RMSE house_test data set 4.7889106^{4}. used another seed partition got lower, worse, higher RMSE? Don´t think better make many partitions estimate time RMSE verify consistent RMSE ? cross-validation. Instead dividing sample , cross-validation involves splitting sample several times estimating RMSE, MAE R-squared . several cross validations methods. common Leave-One-Cross-Validation (LOOCV) k-Fold Cross-Validation (k-fold).","code":""},{"path":"cross-validation.html","id":"leave-one-out-cross-validation-loocv","chapter":"4 Cross Validation","heading":"4.1.1 Leave-One-Out Cross-Validation (LOOCV)","text":"Understanding question. “id” previous output order (.e., 1,2,3,…,n)?Continuing housing example, split sample “n” parts. “n” number rows data set. Cross-validation training dataset; case, \\(n\\) 584.first fold partition taking first observation. see previous output, 1rst observation one id=77.first fold partition taking first observation. see previous output, 1rst observation one id=77.second fold taking second, one id=480And , get \\(n\\) folds, case, 467. One folds, usually first, validation set (like test data set). \\(n−1\\) model must trained tested, making prediction fold1 estimating performance metric, RMSE. example:processes repeat n-2 folds, training fold3 testing fold1. end, get n-1 performance measures. average RMSEs LOOCV.\\[LOOCV =\\frac{1}{n}\\ \\sum_{=1}^{n} RMSE_{} \\]last formula, use RMSE, metric, MAE Rsquared.Fortunately, function “train” library “caret” formerly described processes (Kuhn 2019).train function similar structure “lm” function.train(SalePrice ~ ., data = house_train,\nmethod = “lm”,\ntrControl = )first argument equation, second database. cross-validation, use train data set need specify model, case, “lm”. function allows 238 writing book, “lm” one . name says, argument “trControl” control cross-validation parameters.convenience, library developers suggest separating “trControl” argument argument ruled another function, “trainControl”, many parameters. start creating object function, argument method, case, “LOOCV”.use function train, specifying model “lm”, trControl use object fitControl.previous result, got RMSE 5.4486353^{4}, average n-1 RMSE. see implication previous result, remember previous chapter, got RMSE house_test data set 4.7889106^{4}, result one partition. last result, cross-validation, tells us, case, taking RMSE 4.7889106^{4} -estimating (thinking good model ) (thinking good model ) model performance.arguments “trainControl” function, preprocessing, indicate want process data, example, center scale.“preprocessing” message previous output indicates didn´t select option. preprocess option improve model performance. example, adding “nzv”, Zero- Near Zero-Variance Predictors, BoxCox transforming Predictors preprocess. explanation preprocess alternatives, see library Caret (Kuhn 2019).Another alternative preProcess=c(“center”, “scale”,“YeoJohnson”)\n“center”, “scale” centering scaling methods. “YeoJohnson” another transforming Predictors preprocess option.see previous output, “Preprocessing” indicates four variables removed, suggests improve model performance removing four variables. get remaining variables, use code:Regarding re-sampling: cross-validation name method. summary sample sizes always \\(n−1\\), case case 466. RMSE 466 average \\(n−1\\) test predictions. Finally, message “tuning parameter ‘intercept’ …”, “trControl” argument “train” function accepts arguments parameter tuning process, cover next chapter.Finally, message “Tuning parameter ‘intercept’ held constant value TRUE” argument changed tuning parameters, cover next chapter.","code":"#>      Id SalePrice MSSubClass MSZoning\n#> 64   64    163000         20        4\n#> 540 540    170000         80        4\n#> 200 200    155000         70        5\n#> 171 171    142000         20        4\n#> 41   41    250000         60        2\n#> 268 268    155000         60        4\n#>      Id SalePrice MSSubClass MSZoning\n#> 77   77    274900         20        4\n#> 480 480    186700         20        4\n#> 452 452    135000         50        4\n#> 580 580    240000         60        4\n#> 139 139    207000        120        5\n#> 162 162    245500        120        4\nfold1<- house_train[2:dim[1],] \nhead(fold1[,1:4])\n#>      Id SalePrice MSSubClass MSZoning\n#> 540 540    170000         80        4\n#> 200 200    155000         70        5\n#> 171 171    142000         20        4\n#> 41   41    250000         60        2\n#> 268 268    155000         60        4\n#> 566 566    175900        120        4\ntail(fold1[,1:4])\n#>      Id SalePrice MSSubClass MSZoning\n#> 77   77    274900         20        4\n#> 480 480    186700         20        4\n#> 452 452    135000         50        4\n#> 580 580    240000         60        4\n#> 139 139    207000        120        5\n#> 162 162    245500        120        4\nfold2<- house_train[c(1,3:dim[1]),] \nhead(fold2[,1:4])\n#>      Id SalePrice MSSubClass MSZoning\n#> 64   64    163000         20        4\n#> 200 200    155000         70        5\n#> 171 171    142000         20        4\n#> 41   41    250000         60        2\n#> 268 268    155000         60        4\n#> 566 566    175900        120        4\ntail(fold2[,1:4])\n#>      Id SalePrice MSSubClass MSZoning\n#> 77   77    274900         20        4\n#> 480 480    186700         20        4\n#> 452 452    135000         50        4\n#> 580 580    240000         60        4\n#> 139 139    207000        120        5\n#> 162 162    245500        120        4\nhouse_model<-lm(SalePrice~.,data=fold2)\nhouse_predict<-predict(house_model,fold1)\nsqrt(mean((fold1[,\"SalePrice\"]-house_predict)^2 ,na.rm = T))\n#> [1] 41984.83\nlibrary(caret)\n\nfitControl <- trainControl(method = \"LOOCV\")                   \ngbmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"lm\", \n                 trControl = fitControl)\ngbmFit1\n#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Leave-One-Out Cross-Validation \n#> Summary of sample sizes: 466, 466, 466, 466, 466, 466, ... \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   54486.35  0.6468026  31103.23\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\n\ngbmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"lm\", \n                 trControl = fitControl, preProcess= c(\"BoxCox\",\"nzv\"))\n\ngbmFit1\n#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> Pre-processing: Box-Cox transformation (36), remove (4) \n#> Resampling: Leave-One-Out Cross-Validation \n#> Summary of sample sizes: 466, 466, 466, 466, 466, 466, ... \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   50277.51  0.6939262  29454.77\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\nhead(gbmFit1$finalModel$xNames)\n#> [1] \"Id\"          \"MSSubClass\"  \"MSZoning\"    \"LotFrontage\" \"LotArea\"    \n#> [6] \"LotShape\""},{"path":"cross-validation.html","id":"k-fold-cross-validation-k-foldcv","chapter":"4 Cross Validation","heading":"4.1.2 k-fold Cross Validation (k-FoldCV)","text":"k-FoldCV similar LOOCV, except instead making \\(n\\) partitions, just requires \\(k\\). difference LOOCV usually, \\(k\\) less \\(n\\); example, \\(k=10\\). Another difference \\(k\\) partitions randomly selected. example, first partition called Fold1. takes database, example, house_train, randomly splits 80% training 20% validation data set. model estimated training, prediction validated validation set estimating metrics. process repeated \\(k\\) times.see , “train” function rule determine % training validation sets. following formula summarizes procedure RMSE.\\[k-FoldCV =\\frac{1}{k}\\ \\sum_{=1}^{k} RMSE_{} \\]use “train” function example LOOCV method. apply ten folds \\(k=10\\)case, k-FoldCV method “cv.” argument “number” indicates number folds \\(k\\)arguments “train” function similar LOOCV method.previous output, “Summary sample sizes” shows, fold, number observations training set, case 90% sample size, case 467. Resampling results, RMSE, Rsquared MAE average 10 folds. next plot, show 10 results.“train” function programmed different partitions number k-folds. example, k=5 partition 80. \\(k\\), % partition.Authors (James et al. 2017), consider k-FoldCV advantage less computationally intensive method like LOOCV. Also, exemplifies results k-Fol=10 LOOV similar regarding bias-variance trade-.“train” function allows repetition fold. example, want repeat fold two times, need add arguments, method = “repeatedcv”, number repeats, case, 2. result, end 20 results.algorithm “train” function developed, get different results use k=20 k=10 repeated 2 times.example, following plots, upper side, show different examples “repeatedcv”. bottom, show different examples similar, number, “cv” méthod. cases seed.results cv method concentrated bottom. Meanwhile, repeated-cv dispersion higher. result, RMSE average lower “cv”.valid question , better method? need evaluate model test data set (validation) answer . now, answer results tell us , depending resampling method, getting quite different results, implies probably need something else get stable results methods.example, can make cross-validation variable selection.Remember RMSE variables 5.3829898^{4}. get variables final model:","code":"\nk<-10\nfitControl <- trainControl(method = \"cv\",\n                           number = k)\nset.seed (26)\n\nlmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"lm\", \n                 trControl = fitControl)\nlmFit1\n#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE     Rsquared   MAE     \n#>   53829.9  0.7130432  32074.47\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE#> [1] \"420 467 90\"\ny<-as.data.frame(lmFit1$resample)[,\"RMSE\"] # this data frame has the RMSE results \np1<-lmFit1$results[,\"RMSE\"] # this object has the average RMSE \n\nplot(y, ylab=\"RMSE\", xlab=\"k-Folds\", pch = 16, main= paste(\"k-FoldsCV results for k=\",k))\nabline(p1,0,col=\"black\",lwd=2,lty = 2)\nlegend(x= \"topright\", legend = c(paste(\"average RMSE\",round(p1,0))),lty = 2,lwd=2,col=c(\"black\"))\ntext(x =3, y = p1*1.1, labels = round(p1,0),pos = 3)#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold, repeated 2 times) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   52572.29  0.7112406  31826.41\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\nk2<-10\nset.seed (26)\nfitControl3 <- trainControl(method = \"cv\",\n                           number = k2)\n\nstep <- train(SalePrice ~ ., data = house_train, \n                 method = \"lmStepAIC\", \n                 trControl = fitControl3, trace=F)\nstep\n#> Linear Regression with Stepwise Selection \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE     Rsquared   MAE     \n#>   53183.1  0.7218324  31441.74\nmo<-colnames(step$finalModel$model)[-1]\nmo\n#>  [1] \"MSSubClass\"    \"LotFrontage\"   \"LotArea\"       \"LotShape\"     \n#>  [5] \"HouseStyle\"    \"OverallQual\"   \"OverallCond\"   \"Exterior1st\"  \n#>  [9] \"MasVnrArea\"    \"ExterQual\"     \"Foundation\"    \"BsmtQual\"     \n#> [13] \"BsmtExposure\"  \"BsmtFinType1\"  \"BsmtFinSF1\"    \"BsmtUnfSF\"    \n#> [17] \"X1stFlrSF\"     \"X2ndFlrSF\"     \"BsmtFullBath\"  \"FullBath\"     \n#> [21] \"HalfBath\"      \"KitchenQual\"   \"TotRmsAbvGrd\"  \"Fireplaces\"   \n#> [25] \"FireplaceQu\"   \"GarageArea\"    \"SaleCondition\""},{"path":"cross-validation.html","id":"stochastic-gradient-boosting","chapter":"4 Cross Validation","heading":"4.1.3 Stochastic Gradient Boosting","text":"https://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdfesto —————\n##> Linear Regression Stepwise Selection\n##>\n##> 467 samples\n##> 51 predictor\n##>\n##> pre-processing\n##> Resampling: Cross-Validated (10 fold, repeated 10 times)\n##> Summary sample sizes: 420, 421, 421, 419, 420, 421, …\n##> Resampling results:\n##>\n##> RMSE Rsquared MAE\n##> 50981 0.7143878 30917.71","code":"\nset.seed (26)\nfitControl <- trainControl(method = \"cv\",\n                           number = 10)\n\ngbmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"gbm\", \n                 trControl = fitControl,\n                 ## This last option is actually one\n                 ## for gbm() that passes through\n                 verbose = FALSE)\ngbmFit1\n#> Stochastic Gradient Boosting \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results across tuning parameters:\n#> \n#>   interaction.depth  n.trees  RMSE      Rsquared   MAE     \n#>   1                   50      47239.17  0.7444321  30600.93\n#>   1                  100      46147.22  0.7537532  29225.96\n#>   1                  150      45741.85  0.7555015  28969.01\n#>   2                   50      45232.87  0.7570658  28665.82\n#>   2                  100      44866.17  0.7601488  27908.81\n#>   2                  150      45748.88  0.7554831  27734.49\n#>   3                   50      44032.44  0.7708265  27661.85\n#>   3                  100      43706.40  0.7775313  26762.67\n#>   3                  150      44620.73  0.7733739  27046.71\n#> \n#> Tuning parameter 'shrinkage' was held constant at a value of 0.1\n#> \n#> Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n#> RMSE was used to select the optimal model using the smallest value.\n#> The final values used for the model were n.trees = 100, interaction.depth =\n#>  3, shrinkage = 0.1 and n.minobsinnode = 10.\nmin(gbmFit1$results[,\"RMSE\"])\n#> [1] 43706.4##> Call:\n##> lm(formula = .outcome ~ MSSubClass + LotFrontage + LotArea + \n##>    LotShape + HouseStyle + OverallQual + OverallCond + Exterior1st + \n##>    MasVnrArea + ExterQual + Foundation + BsmtQual + BsmtExposure + \n##>    BsmtFinType1 + BsmtFinSF1 + BsmtUnfSF + X1stFlrSF + X2ndFlrSF + \n##>    BsmtFullBath + FullBath + HalfBath + KitchenQual + TotRmsAbvGrd + \n##>    Fireplaces + FireplaceQu + GarageArea + SaleCondition, data = dat)\n##>\n##> Coefficients:\n##>  (Intercept)     MSSubClass    LotFrontage        LotArea       LotShape  \n##> HouseStyle  \n##>    4.120e+04     -2.299e+02     -3.216e+02      5.828e-01     -2.812e+03     \n##> -2.889e+03  \n##>  OverallQual    OverallCond    Exterior1st     MasVnrArea      ExterQual     \n##> Foundation  \n##>    1.893e+04      9.620e+03     -1.302e+03      5.605e+01     -8.628e+03      \n##> 8.200e+03  \n##>     BsmtQual   BsmtExposure   BsmtFinType1     BsmtFinSF1      BsmtUnfSF      \n##> X1stFlrSF  \n##>   -1.178e+04     -5.687e+03     -3.146e+03     -2.498e+01     -2.111e+01      \n##> 3.817e+01  \n##>    X2ndFlrSF   BsmtFullBath       FullBath       HalfBath    KitchenQual   \n##> TotRmsAbvGrd  \n##>    2.565e+01      9.998e+03      1.689e+04      1.139e+04     -7.131e+03      \n##> 4.149e+03  \n##>   Fireplaces    FireplaceQu     GarageArea  SaleCondition  \n##>    1.359e+04     -4.135e+03      4.338e+01      4.348e+03  "},{"path":"cross-validation.html","id":"classification-cross-validation","chapter":"4 Cross Validation","heading":"4.2 Classification Cross-Validation","text":"Finally use functions trainControl train cross validation.start aplying logit model. default, metric verofy predictive power Accuracy.Also specify ROC, sensitivity specificity metrics.can use models gbm.LDA","code":"\ncredit<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/credit.csv\")\n\nc2<-ifelse(credit[,\"Default\"]==\"Charged Off\" ,\"No_default\",\"default\") \ncredit[,\"Default\"]<-c2\ncredit[,\"Default\"]<-factor(credit[,\"Default\"])\n\nset.seed (43)\ndim<-dim(credit)\ntrain_sample<-sample(dim[1],dim[1]*.8)\ncredit_train <- credit[train_sample, ]\ncredit_test  <- credit[-train_sample, ]\nfitControl <- trainControl(method = \"cv\",\n                           number = 10, \n                           classProbs = T ) \n\nglmFit <- train(Default~ ., data = credit_train, \n                 method = \"glm\", \n                 trControl = fitControl,\n                family=binomial())\nglmFit        \n#> Generalized Linear Model \n#> \n#> 698 samples\n#>  70 predictor\n#>   2 classes: 'default', 'No_default' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 628, 628, 629, 628, 627, 628, ... \n#> Resampling results:\n#> \n#>   Accuracy   Kappa    \n#>   0.9399764  0.7908423\n\nfitControl_Roc <- trainControl(method = \"cv\",\n                           number = 10, \n                           classProbs = T,\n                           summaryFunction = twoClassSummary ) \n\nglmFit <- train(Default~ ., data = credit_train, \n                 method = \"glm\", \n                 trControl = fitControl_Roc,\n                 metric = \"ROC\",\n                family=binomial())\nglmFit        \n#> Generalized Linear Model \n#> \n#> 698 samples\n#>  70 predictor\n#>   2 classes: 'default', 'No_default' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 628, 628, 628, 628, 628, 628, ... \n#> Resampling results:\n#> \n#>   ROC        Sens       Spec     \n#>   0.9591776  0.9638515  0.8613636\ngbmFit <- train(Default~ ., data = credit_train, \n                 method = \"gbm\", \n                 trControl = fitControl_Roc ,verbose = FALSE)\n\n#verbose = FALSE\ngbmFit \n#> Stochastic Gradient Boosting \n#> \n#> 698 samples\n#>  70 predictor\n#>   2 classes: 'default', 'No_default' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 627, 628, 628, 628, 628, 628, ... \n#> Resampling results across tuning parameters:\n#> \n#>   interaction.depth  n.trees  ROC        Sens       Spec     \n#>   1                   50      0.9944136  0.9879603  0.8560606\n#>   1                  100      0.9954822  0.9862653  0.8719697\n#>   1                  150      0.9953124  0.9879895  0.8719697\n#>   2                   50      0.9969223  0.9896844  0.9234848\n#>   2                  100      0.9960390  0.9879603  0.9143939\n#>   2                  150      0.9964807  0.9931327  0.9143939\n#>   3                   50      0.9958871  0.9914085  0.9159091\n#>   3                  100      0.9960366  0.9879603  0.9068182\n#>   3                  150      0.9967525  0.9914085  0.9068182\n#> \n#> Tuning parameter 'shrinkage' was held constant at a value of 0.1\n#> \n#> Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n#> ROC was used to select the optimal model using the largest value.\n#> The final values used for the model were n.trees = 50, interaction.depth =\n#>  2, shrinkage = 0.1 and n.minobsinnode = 10.\nset.seed(825)\nldaFit <- train(Default~ ., data = credit_train, \n                 method = \"lda\", \n                 trControl = fitControl_Roc ,\n                  metric = \"ROC\")\nldaFit\n#> Linear Discriminant Analysis \n#> \n#> 698 samples\n#>  70 predictor\n#>   2 classes: 'default', 'No_default' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 628, 628, 629, 628, 628, 629, ... \n#> Resampling results:\n#> \n#>   ROC        Sens       Spec     \n#>   0.9844228  0.9742256  0.8469697\nset.seed(825)\nfdaFit <- train(Default~ ., data = credit_train, \n                 method = \"fda\", \n                 trControl = fitControl_Roc ,\n                  metric = \"ROC\")\nfdaFit\n#> Flexible Discriminant Analysis \n#> \n#> 698 samples\n#>  70 predictor\n#>   2 classes: 'default', 'No_default' \n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 628, 628, 629, 628, 628, 629, ... \n#> Resampling results across tuning parameters:\n#> \n#>   nprune  ROC        Sens       Spec     \n#>    2      0.9037095  0.9706897  0.7454545\n#>   21      0.9978178  0.9914378  0.9151515\n#>   41      0.9971116  0.9914378  0.9227273\n#> \n#> Tuning parameter 'degree' was held constant at a value of 1\n#> ROC was used to select the optimal model using the largest value.\n#> The final values used for the model were degree = 1 and nprune = 21.\nresamps <- resamples(list(Logit = glmFit,\n                          GBM = gbmFit,\n                          LDA=ldaFit,\n                          Logit=glmFit,\n                          Fda=fdaFit))\n\ntheme1 <- trellis.par.get()\ntheme1$plot.symbol$col = rgb(.2, .2, .2, .4)\ntheme1$plot.symbol$pch = 16\ntheme1$plot.line$col = rgb(1, 0, 0, .7)\ntheme1$plot.line$lwd <- 2\ntrellis.par.set(theme1)\nbwplot(resamps, layout = c(3, 1))"},{"path":"cross-validation.html","id":"evaluate-your-system-on-the-test-set","chapter":"4 Cross Validation","heading":"4.2.1 Evaluate Your System on the Test Set","text":"","code":"\nlibrary(pROC)\nclas_test<-function(model,data,levelss,dep,pos){\n  \ncredit_predict<-predict(model, newdata=data,type = \"raw\")\nDefaultf<-factor(credit_predict,levels=levelss)\nconfu<-confusionMatrix(Defaultf,credit_test[,dep],positive=pos)\nsen<-round(as.vector(confu$byClass[1])*100,2)\n\nref<- data[,dep]\npredict_glm<-predict(model, newdata=data, type=\"prob\")\nroc0<-roc(ref, predict_glm[,1], levels = rev(levels(ref)),ret=\"coords\")\nAUC<-round(as.vector(roc0$auc),4)*100\n\n\nprint(paste(model$method,\"Sensibility=\",sen))\nprint(paste(model$method,\"AUC=\",AUC))\n\n}\nclas_test(glmFit,credit_test,c(\"default\",\"No_default\"),\"Default\",\"default\")\n#> [1] \"glm Sensibility= 95.92\"\n#> [1] \"glm AUC= 98.2\"\nclas_test(gbmFit,credit_test,c(\"default\",\"No_default\"),\"Default\",\"default\")\n#> [1] \"gbm Sensibility= 97.96\"\n#> [1] \"gbm AUC= 99.59\"\nclas_test(ldaFit,credit_test,c(\"default\",\"No_default\"),\"Default\",\"default\")\n#> [1] \"lda Sensibility= 96.6\"\n#> [1] \"lda AUC= 98.1\"\nclas_test(fdaFit,credit_test,c(\"default\",\"No_default\"),\"Default\",\"default\")\n#> [1] \"fda Sensibility= 98.64\"\n#> [1] \"fda AUC= 99.73\""},{"path":"improving-performance.html","id":"improving-performance","chapter":"5 Improving Performance","heading":"5 Improving Performance","text":"","code":""},{"path":"improving-performance.html","id":"parameter-tuning","chapter":"5 Improving Performance","heading":"5.1 PARAMETER TUNING","text":"Hyperparameters model parameters specified training model – .e., parameters different model parameters – weights AI/ML model learns model training.many machine learning problems, finding best hyperparameters iterative potentially time-intensive process called “hyperparameter optimization.Hyperparameters directly impact performance trained machine-learning model. Choosing right hyperparameters can dramatically improve prediction accuracy. However, can challenging optimize often large combination possible hyperparameter values.Tuning machine learning model iterative process. Data scientists typically run numerous experiments train evaluate models, trying different features, different loss functions, different AI/ML models, adjusting model parameters hyperparameters. Examples steps involved tuning training machine learning model include feature engineering, loss function formulation, model testing selection, regularization, selection hyperparameters Krishnan (2022).Let’s assume now shortlist promising models. help now fine-tuned . Let’s look ways can .retrieved optimum values individual model parameters, can use grid search obtain combination hyperparameter (parameters also known hyperparameters) values model can give us highest accuracy.Grid Search evaluates possible combinations parameter values.Grid Search exhaustive uses brute force evaluate accurate values. Therefore computationally intensive task.","code":"\nhouse<-read.csv(\"data/house_clean.csv\")\n#house<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/housing.csv\")\nset.seed (26)\ndim<-dim(house)\ntrain_sample<-sample(dim[1],dim[1]*.8)\nhouse_train <- house[train_sample, ]\nhouse_test  <- house[-train_sample, ]\nlibrary(caret)\nset.seed (26)\nfitControl <- trainControl(method = \"cv\",\n                           number = 10)\n\ngbmFit <- train(SalePrice ~ ., data = house_train, \n                 method = \"gbm\", \n                 trControl = fitControl, \n                 verbose = FALSE)\ngbmFit\n#> Stochastic Gradient Boosting \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results across tuning parameters:\n#> \n#>   interaction.depth  n.trees  RMSE      Rsquared   MAE     \n#>   1                   50      47239.17  0.7444321  30600.93\n#>   1                  100      46147.22  0.7537532  29225.96\n#>   1                  150      45741.85  0.7555015  28969.01\n#>   2                   50      45232.87  0.7570658  28665.82\n#>   2                  100      44866.17  0.7601488  27908.81\n#>   2                  150      45748.88  0.7554831  27734.49\n#>   3                   50      44032.44  0.7708265  27661.85\n#>   3                  100      43706.40  0.7775313  26762.67\n#>   3                  150      44620.73  0.7733739  27046.71\n#> \n#> Tuning parameter 'shrinkage' was held constant at a value of 0.1\n#> \n#> Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n#> RMSE was used to select the optimal model using the smallest value.\n#> The final values used for the model were n.trees = 100, interaction.depth =\n#>  3, shrinkage = 0.1 and n.minobsinnode = 10.\nmin(gbmFit$results[,\"RMSE\"])\n#> [1] 43706.4\nseq(0.08,0.2,.01)\n#>  [1] 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.20\nset.seed (26)\nfitControl <- trainControl(method = \"cv\",\n                           number = 10)\n\ngbmGrid <-  expand.grid(interaction.depth = 3, \n                        n.trees = 100, \n                        shrinkage = seq(0.08,0.2,.01),\n                        n.minobsinnode = c(10,20,30))\n                        \nnrow(gbmGrid)\n#> [1] 39\n\n\ngbmFit2 <- train(SalePrice ~ ., data = house_train, \n                 method = \"gbm\", \n                 trControl = fitControl, \n                 verbose = FALSE, \n                 ## Now specify the exact models \n                 ## to evaluate:\n                 tuneGrid = gbmGrid)\ngbmFit2\n#> Stochastic Gradient Boosting \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results across tuning parameters:\n#> \n#>   shrinkage  n.minobsinnode  RMSE      Rsquared   MAE     \n#>   0.08       10              43689.38  0.7757923  26414.49\n#>   0.08       20              43439.41  0.7762678  26253.74\n#>   0.08       30              43718.02  0.7740018  27043.45\n#>   0.09       10              44482.73  0.7657377  26932.51\n#>   0.09       20              44471.18  0.7694100  26930.13\n#>   0.09       30              42765.74  0.7850388  26107.17\n#>   0.10       10              45797.81  0.7565011  27752.53\n#>   0.10       20              43305.74  0.7752004  26133.99\n#>   0.10       30              44014.90  0.7733803  27155.20\n#>   0.11       10              44489.95  0.7656922  26866.05\n#>   0.11       20              44102.22  0.7772802  26763.98\n#>   0.11       30              43173.50  0.7852119  26475.20\n#>   0.12       10              45685.92  0.7560192  27278.29\n#>   0.12       20              43837.29  0.7733656  26780.05\n#>   0.12       30              43632.73  0.7731039  27097.95\n#>   0.13       10              45015.04  0.7633598  27339.32\n#>   0.13       20              44378.70  0.7733293  26922.59\n#>   0.13       30              43729.28  0.7738287  26848.09\n#>   0.14       10              45847.55  0.7616066  26985.59\n#>   0.14       20              43476.83  0.7753577  27154.57\n#>   0.14       30              44204.43  0.7733527  27236.38\n#>   0.15       10              46597.58  0.7505296  27959.85\n#>   0.15       20              45481.20  0.7606624  27931.86\n#>   0.15       30              44495.46  0.7689698  27904.48\n#>   0.16       10              46312.23  0.7551459  28093.47\n#>   0.16       20              44609.52  0.7720711  26788.57\n#>   0.16       30              44293.15  0.7709916  27231.55\n#>   0.17       10              47092.71  0.7503482  27909.55\n#>   0.17       20              45266.73  0.7597926  27838.44\n#>   0.17       30              44495.99  0.7682215  27612.17\n#>   0.18       10              46187.08  0.7560767  27455.96\n#>   0.18       20              45563.69  0.7615617  28022.82\n#>   0.18       30              44019.18  0.7697064  28476.80\n#>   0.19       10              49851.20  0.7284168  29410.44\n#>   0.19       20              46902.27  0.7505154  28841.09\n#>   0.19       30              44854.58  0.7651957  28353.89\n#>   0.20       10              48231.76  0.7329092  29188.07\n#>   0.20       20              44947.66  0.7651168  27865.51\n#>   0.20       30              44618.00  0.7586902  27987.05\n#> \n#> Tuning parameter 'n.trees' was held constant at a value of 100\n#> Tuning\n#>  parameter 'interaction.depth' was held constant at a value of 3\n#> RMSE was used to select the optimal model using the smallest value.\n#> The final values used for the model were n.trees = 100, interaction.depth =\n#>  3, shrinkage = 0.09 and n.minobsinnode = 30.\ntrellis.par.set(caretTheme())\nplot(gbmFit2) \ngbmFit2$bestTune\n#>   n.trees interaction.depth shrinkage n.minobsinnode\n#> 6     100                 3      0.09             30\nset.seed (26)\nfitControl <- trainControl(method = \"cv\",\n                           number = 10)\n\ngbmGrid <-  expand.grid(interaction.depth = 3, \n                        n.trees = 100, \n                        shrinkage = 0.09,\n                        n.minobsinnode = 30)\n                        \n\ngbmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"gbm\", \n                 trControl = fitControl,\n                 verbose = FALSE,tuneGrid = gbmGrid)\ngbmFit1\n#> Stochastic Gradient Boosting \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   43538.88  0.7755887  27051.03\n#> \n#> Tuning parameter 'n.trees' was held constant at a value of 100\n#> Tuning\n#> \n#> Tuning parameter 'shrinkage' was held constant at a value of 0.09\n#> \n#> Tuning parameter 'n.minobsinnode' was held constant at a value of 30"},{"path":"improving-performance.html","id":"analyze-the-best-models-and-their-errors","chapter":"5 Improving Performance","heading":"5.2 Analyze the Best Models and Their Errors","text":"","code":"\nset.seed (26)\n\nlmFit <- train(SalePrice ~ ., data = house_train, \n                 method = \"lm\", \n                 trControl = fitControl)\nlmFit\n#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE     Rsquared   MAE     \n#>   53829.9  0.7130432  32074.47\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\nk2<-10\nset.seed (26)\nfitControl3 <- trainControl(method = \"cv\",\n                           number = k2)\n\nstep <- train(SalePrice ~ ., data = house_train, \n                 method = \"lmStepAIC\", \n                 trControl = fitControl3, trace=F)\nstep\n#> Linear Regression with Stepwise Selection \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE     Rsquared   MAE     \n#>   53183.1  0.7218324  31441.74\nresamps <- resamples(list(GBM = gbmFit1,\n                          lm= lmFit,\n                          step = step))\nsummary(resamps)\n#> \n#> Call:\n#> summary.resamples(object = resamps)\n#> \n#> Models: GBM, lm, step \n#> Number of resamples: 10 \n#> \n#> MAE \n#>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\n#> GBM  16916.01 22683.84 26802.82 27051.03 33250.31 34700.58    0\n#> lm   24099.97 27569.17 32581.94 32074.47 33796.23 46936.58    0\n#> step 23457.60 27519.35 31131.39 31441.74 33246.95 47069.12    0\n#> \n#> RMSE \n#>          Min.  1st Qu.   Median     Mean  3rd Qu.      Max. NA's\n#> GBM  21042.28 29863.83 42580.60 43538.88 53434.67  68983.63    0\n#> lm   29902.95 38797.25 46407.32 53829.90 50676.37 142708.97    0\n#> step 29473.14 38261.54 45661.85 53183.10 49510.85 142365.64    0\n#> \n#> Rsquared \n#>           Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\n#> GBM  0.4466954 0.7499098 0.7749271 0.7755887 0.8692610 0.9222225    0\n#> lm   0.1182236 0.7380041 0.7705471 0.7130432 0.7989847 0.8440776    0\n#> step 0.1201389 0.7623466 0.7765474 0.7218324 0.7931811 0.8461111    0\ntheme1 <- trellis.par.get()\ntheme1$plot.symbol$col = rgb(.2, .2, .2, .4)\ntheme1$plot.symbol$pch = 16\ntheme1$plot.line$col = rgb(1, 0, 0, .7)\ntheme1$plot.line$lwd <- 2\ntrellis.par.set(theme1)\nbwplot(resamps, layout = c(3, 1))"},{"path":"improving-performance.html","id":"evaluate-your-system-on-the-test-set-1","chapter":"5 Improving Performance","heading":"5.3 Evaluate Your System on the Test Set","text":"","code":"\nlibrary(gbm)\ngbm1 <-gbm(SalePrice ~ ., data = house_train, n.trees = 100, shrinkage = 0.09,\ninteraction.depth = 3, distribution = \"gaussian\",bag.fraction = 0.5, train.fraction = 0.5,\nn.minobsinnode = 30, cv.folds = 10, keep.data = TRUE,\nverbose = FALSE)\nbest.iter <- gbm.perf(gbm1, method = \"cv\")\nprint(best.iter)\n#> [1] 85\nhouse_predict<-predict(gbm1, newdata = house_test, n.trees = 100, shrinkage = 0.09,interaction.depth = 3, n.minobsinnode = 30)\n\nsqrt(mean((house_test[,\"SalePrice\"]-house_predict)^2 ,na.rm = T))\n#> [1] 54768.78"},{"path":"clustering.html","id":"clustering","chapter":"6 Clustering","heading":"6 Clustering","text":"Unsupervised learning - ClusteringClustering technique aims group similar data points points group similar features groups. group similar data points called Cluster.example, suppose following data frame, hypothetical data students ages grades course:betther undestandng plot, following plot shows person similar terms age grade.One one identify person group persons similar terms age grade , equivalent say cluster, using Euclidean Distance (ED):\\[d_{euc}(p,q)= \\sqrt{ \\sum_{=1}^{n} (p_{}-q_{}})^{2}\\]\\(p_{}\\), \\(p_{}\\) two points euclidean space. example, two different persons data set. \\(n\\) number features, example two, age anf grade. example, Euclidean Distance person 1 2 :lower (higher) ED two persons, similars (different) , porbably grouped (grouped) cluster.estimate Euclidean Distance persons data set, use funciton “get_dist”, library “factoextra”:see output, result shows ED person. important notice output data frame, “dist” object:previous outpt giving us infromation people grouped clusters, following plot , using function “fviz_dist”, wich first argument “dist” object made last “chunk”:previous plot, red color squares persons higher ED blue ones lower ones.terms scatter plot made , take individual pairs ED less 2, example, get following results:see red dots kind grouped , also yellow ones. sense, say individuals red dots cluster, individuals yellow cluster. repeat procees -color individuales, moment waned explian clusters formed.","code":"\nset.seed(1100)\nx <- round(rnorm(12, 20, 3),0)\ny <- round(rnorm(12, 95, 4),0)\ny<-ifelse(y>100,100,y)\ndf<- data.frame(Age=x, Grade=y)\nrownames(df)<-paste(\"Ind\",rownames(df))\ndf\n#>        Age Grade\n#> Ind 1   21   100\n#> Ind 2   19    98\n#> Ind 3   20    95\n#> Ind 4   17    97\n#> Ind 5   17    95\n#> Ind 6   21    97\n#> Ind 7   19    96\n#> Ind 8   19    97\n#> Ind 9   16    87\n#> Ind 10  25    95\n#> Ind 11  23    97\n#> Ind 12  22   100\nplot(df[,\"Age\"], df[,\"Grade\"], col = \"blue\", pch = 1, cex = 1.5,ylab=\"Grade\",xlab=\"Age\",ylim=c(88,101),xlim=c(16,26))\ntext(df[,\"Age\"] + .3, df[,\"Grade\"] + 0.9, labels = rownames(df))\nsqrt((df[\"Ind 1\",\"Age\"]-df[\"Ind 2\",\"Age\"])^2+(df[\"Ind 1\",\"Grade\"]-df[\"Ind 2\",\"Grade\"])^2)\n#> [1] 2.828427\nlibrary(factoextra) #\ndistance<-get_dist(df, method = \"euclidean\")\ndistance\n#>            Ind 1     Ind 2     Ind 3     Ind 4     Ind 5     Ind 6     Ind 7\n#> Ind 2   2.828427                                                            \n#> Ind 3   5.099020  3.162278                                                  \n#> Ind 4   5.000000  2.236068  3.605551                                        \n#> Ind 5   6.403124  3.605551  3.000000  2.000000                              \n#> Ind 6   3.000000  2.236068  2.236068  4.000000  4.472136                    \n#> Ind 7   4.472136  2.000000  1.414214  2.236068  2.236068  2.236068          \n#> Ind 8   3.605551  1.000000  2.236068  2.000000  2.828427  2.000000  1.000000\n#> Ind 9  13.928388 11.401754  8.944272 10.049876  8.062258 11.180340  9.486833\n#> Ind 10  6.403124  6.708204  5.000000  8.246211  8.000000  4.472136  6.082763\n#> Ind 11  3.605551  4.123106  3.605551  6.000000  6.324555  2.000000  4.123106\n#> Ind 12  1.000000  3.605551  5.385165  5.830952  7.071068  3.162278  5.000000\n#>            Ind 8     Ind 9    Ind 10    Ind 11\n#> Ind 2                                         \n#> Ind 3                                         \n#> Ind 4                                         \n#> Ind 5                                         \n#> Ind 6                                         \n#> Ind 7                                         \n#> Ind 8                                         \n#> Ind 9  10.440307                              \n#> Ind 10  6.324555 12.041595                    \n#> Ind 11  4.000000 12.206556  2.828427          \n#> Ind 12  4.242641 14.317821  5.830952  3.162278\nclass(distance)\n#> [1] \"dist\"\nfviz_dist(distance,  gradient = list(low = \"#00AFBB\", mid = \"white\", high = \"#FC4E07\"))\nplot(df[,\"Age\"], df[,\"Grade\"], col = \"blue\", pch = 1, cex = 1.5,ylab=\"Grade\",xlab=\"Age\",ylim=c(86,101),xlim=c(16,26))\ntext(df[,\"Age\"] + .3, df[,\"Grade\"] + 0.6, labels = rownames(df))\npoints(df[ind[1, ],\"Age\"], df[ind[1, ],\"Grade\"], col = \"orange\", pch = 19, cex = 2)\npoints(df[ind[2, ],\"Age\"], df[ind[2, ],\"Grade\"], col = \"red\", pch = 19, cex = 2)\npoints(df[ind[3, ],\"Age\"], df[ind[3, ],\"Grade\"], col = \"red\", pch = 19, cex = 2)\npoints(df[ind[4, ],\"Age\"], df[ind[4, ],\"Grade\"], col = \"red\", pch = 19, cex = 2)\n#segments(x0 = 19, y0 = 96,x1=20,y1=95) "},{"path":"clustering.html","id":"agglomerative-hierarchical-clustering","chapter":"6 Clustering","heading":"6.1 Agglomerative hierarchical clustering","text":"prove last method, need partition define similarity beetween two individuals, th sale cluster. Hierarchical clustering algorithms doesn´t need predefined partition generate clusters.First, using particular proximity measure dissimilarity matrix constructed data points visually represented bottom dendrogram. closest sets clusters merged level dissimilarity matrix updated correspondingly. process agglomerative merging carried final maximal cluster (contains data objects single cluster) obtained. represent apex dendrogram mark completion merging process. now discuss different kinds proximity measures can used agglomerative hierarchical clustering. Subsequently, also provide complete version agglomerative hierarchical clustering algorithm inThe popular agglomerative clustering methods single link complete link clusterings. single link clustering [36, 46], similarity two clusters similarity similar (nearest neighbor) members. method intuitively gives importance regions clusters closest, neglecting overall structure cluster. Hence, method falls category local similarity-based clustering method. local behavior, single linkage capable effectively clustering nonelliptical, elongated shaped groups data objects. However, one main drawbacks method sensitivity noise outliers data.Complete link clustering [27] measures similarity two clusters similarity dissimilar members. equivalent choosing cluster pair whose merge smallest diameter. method takes cluster structure consideration nonlocal behavior generally obtains compact shaped clusters. However, similar single link clustering, method also sensitive outliers. single link complete link clustering graph-theoretic interpretations [16], clusters obtained single link clustering correspond connected components graph obtained complete link correspond maximal cliques graph.Lance Williams recurrence formula gives distance group k group (ij) formed fusion two groups (j) :\\[ d_{k(ij)}= \\alpha\\ d_{ki}+\\beta\\ d_{ij}+\\gamma\\ |d_{ki}-d_{kj}|, \\]\\(d_{ij}\\) s distance groups j. Lance Williams used formula define new ‘flexible’ scheme, parameter values αi + αj + β = 1, αi = αj, β < 1, γ = 0. allowing β vary, clustering schemes various characteristics can obtained. suggest small negative values β, −0.25, although Scheibler Schneider (1985) suggest −0.50 (Brian S. Everitt 2011).hClustering <- hclust(distance object,method)\nmethod=c(ward.D”, “ward.D2”, “single”, “complete”, “average”, “mcquitty” , “median” “centroid” )plot(hClustering object)chart can used visually inspect number clusters created selected distance threshold . number vertical lines hypothetical straight, horizontal line pass number clusters created distance threshold value. data points (leaves) branch labeled cluster horizontal line passed .members cluster\nmemb <-cutree(hClustering object, k = )k= número de clusters que se deseanh= cut number dendrogram","code":"\nhClustering <-  hclust(distance ,method=\"single\") # cuidado por que le pusimos distance también al de teens\nplot(hClustering)\nmemb <-cutree(hClustering, k = 3)\nhead(memb)\n#> Ind 1 Ind 2 Ind 3 Ind 4 Ind 5 Ind 6 \n#>     1     1     1     1     1     1\ntail(memb)\n#>  Ind 7  Ind 8  Ind 9 Ind 10 Ind 11 Ind 12 \n#>      1      1      2      3      1      1\ncent <- NULL\nfor(k in 1:10){\n  cent <- rbind(cent, colMeans(df[memb == k, , drop = FALSE]))\n}"},{"path":"clustering.html","id":"k-means-clustering","chapter":"6 Clustering","heading":"6.2 K-Means Clustering","text":"K-means clustering commonly used unsupervised machine learning algorithm partitioning given data set set k groups (.e. k clusters), k represents number groups pre-specified analyst. classifies objects multiple groups (.e., clusters), objects within cluster similar possible (.e., high intra-class similarity), whereas objects different clusters dissimilar possible (.e., low inter-class similarity). k-means clustering, cluster represented center (.e, centroid) corresponds mean points assigned cluster.Basic IdeaThe basic idea behind k-means clustering consists defining clusters total intra-cluster variation (known total within-cluster variation) minimized. several k-means algorithms available. standard algorithm Hartigan-Wong algorithm (1979), defines total within-cluster variation sum squared distances Euclidean distances items corresponding centroid:\\[ W(C_{k})=\\sum_{x_{}\\C_{k}}(x_{}- \\mu_{k})^2\\]\\(x_{}\\) data point belonging cluster Ck._{k} mean value points assigned cluster CkEach observation (xi) assigned given cluster sum squares (SS) distance observation assigned cluster centers (μk) minimized.define total within-cluster variation follows:\n\\[ tot.withiness=\\sum_{k=1}^k W(C_{k})=\\sum_{k=1}^k \\sum_{x_{}\\C_{k}}(x_{}- \\mu_{k})^2\\]total within-cluster sum square measures compactness (.e goodness) clustering want small possible.kmeans(df object, centers = )\ncenters number clustersnstart, Select randomly k objects data set initial cluster centers meansfviz_cluster(kmenas object, data =, stand=F)ylim=c(90,101),xlim=c(17,27)Elbow MethodRecall , basic idea behind cluster partitioning methods, k-means clustering, define clusters total intra-cluster variation (known total within-cluster variation total within-cluster sum square) minimized:Average Silhouette MethodIn short, average silhouette approach measures quality clustering. , determines well object lies within cluster. high average silhouette width indicates good clustering. average silhouette method computes average silhouette observations different values k. optimal number clusters k one maximizes average silhouette range possible values k.2We can use silhouette function cluster package compuate average silhouette width. following code computes approach 1-15 clusters. results show 2 clusters maximize average silhouette values 4 clusters coming second optimal number clusters.","code":"\nset.seed(1234)\n# regresamos a df con dos variables\nteens<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/teens_clean.csv\")\n\nset.seed(200)\nteens_na<-na.omit(teens)\n#dim arroja el npumero de renglones y columas de un data frame\ndim<-dim(teens_na)\n# genera números del 1 al 27,276(dim[1]) pero solo arrojame 1,000. \nsamp<-sample(dim[1],10000)\n# Del objeto teens_na, toma solo las observaciones que hay en samp\nteens_2<-teens_na[samp,]\nteens_2[,\"gender\"]<-ifelse(teens_2[,\"gender\"]==\"F\",1,0)\n\nkm<-kmeans(teens_2, centers = 3) # centers es el número de clusters\nfviz_cluster(km, data = teens_2 , stand=F)\nset.seed(123)\nfviz_nbclust(teens_2 , kmeans, method = \"wss\")\nset.seed(123)\nfviz_nbclust(teens_2, kmeans, method = \"wss\")\nset.seed(123)\nfviz_nbclust(df, kmeans, method = \"silhouette\")"},{"path":"clustering.html","id":"cluster-intuition","chapter":"6 Clustering","heading":"6.3 Cluster intuition","text":"cluster intuition k-means, apply methods, hierarchical clustering.teen_clusters <- kmeans(data, k)Transforming matrix, making plot.\n.matrix(teen_clusters$centers)Function make bar plot","code":"\nteens_scale<-as.data.frame(lapply(teens_2[,2:41], scale))\nsummary(teens_scale)\n#>      gender             age               friends          basketball     \n#>  Min.   :-2.0727   Min.   :-3.306980   Min.   :-0.8569   Min.   :-0.3403  \n#>  1st Qu.: 0.4824   1st Qu.:-0.829209   1st Qu.:-0.7455   1st Qu.:-0.3403  \n#>  Median : 0.4824   Median :-0.007369   Median :-0.2720   Median :-0.3403  \n#>  Mean   : 0.0000   Mean   : 0.000000   Mean   : 0.0000   Mean   : 0.0000  \n#>  3rd Qu.: 0.4824   3rd Qu.: 0.843353   3rd Qu.: 0.3687   3rd Qu.:-0.3403  \n#>  Max.   : 0.4824   Max.   : 2.396008   Max.   :11.8721   Max.   :15.4215  \n#>     football           soccer           softball         volleyball     \n#>  Min.   :-0.3696   Min.   :-0.2452   Min.   :-0.2245   Min.   :-0.2259  \n#>  1st Qu.:-0.3696   1st Qu.:-0.2452   1st Qu.:-0.2245   1st Qu.:-0.2259  \n#>  Median :-0.3696   Median :-0.2452   Median :-0.2245   Median :-0.2259  \n#>  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  \n#>  3rd Qu.:-0.3696   3rd Qu.:-0.2452   3rd Qu.:-0.2245   3rd Qu.:-0.2259  \n#>  Max.   :13.8005   Max.   :28.5005   Max.   :16.2346   Max.   :17.2642  \n#>     swimming        cheerleading       baseball          tennis       \n#>  Min.   :-0.2829   Min.   :-0.211   Min.   :-0.193   Min.   :-0.1663  \n#>  1st Qu.:-0.2829   1st Qu.:-0.211   1st Qu.:-0.193   1st Qu.:-0.1663  \n#>  Median :-0.2829   Median :-0.211   Median :-0.193   Median :-0.1663  \n#>  Mean   : 0.0000   Mean   : 0.000   Mean   : 0.000   Mean   : 0.0000  \n#>  3rd Qu.:-0.2829   3rd Qu.:-0.211   3rd Qu.:-0.193   3rd Qu.:-0.1663  \n#>  Max.   :15.8853   Max.   :16.050   Max.   :25.838   Max.   :22.9600  \n#>      sports             cute              sex               sexy        \n#>  Min.   :-0.2982   Min.   :-0.4074   Min.   :-0.2128   Min.   :-0.2697  \n#>  1st Qu.:-0.2982   1st Qu.:-0.4074   1st Qu.:-0.2128   1st Qu.:-0.2697  \n#>  Median :-0.2982   Median :-0.4074   Median :-0.2128   Median :-0.2697  \n#>  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  \n#>  3rd Qu.:-0.2982   3rd Qu.:-0.4074   3rd Qu.:-0.2128   3rd Qu.:-0.2697  \n#>  Max.   :25.1558   Max.   :18.1970   Max.   :46.3166   Max.   :22.5086  \n#>       hot              kissed            dance              band        \n#>  Min.   :-0.2614   Min.   :-0.1958   Min.   :-0.3761   Min.   :-0.2958  \n#>  1st Qu.:-0.2614   1st Qu.:-0.1958   1st Qu.:-0.3761   1st Qu.:-0.2958  \n#>  Median :-0.2614   Median :-0.1958   Median :-0.3761   Median :-0.2958  \n#>  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  \n#>  3rd Qu.:-0.2614   3rd Qu.:-0.1958   3rd Qu.:-0.3761   3rd Qu.:-0.2958  \n#>  Max.   :18.5623   Max.   :45.3319   Max.   :18.7830   Max.   :19.2610  \n#>     marching           music              rock             god         \n#>  Min.   :-0.1366   Min.   :-0.6308   Min.   :-0.339   Min.   :-0.4049  \n#>  1st Qu.:-0.1366   1st Qu.:-0.6308   1st Qu.:-0.339   1st Qu.:-0.4049  \n#>  Median :-0.1366   Median :-0.6308   Median :-0.339   Median :-0.4049  \n#>  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.000   Mean   : 0.0000  \n#>  3rd Qu.:-0.1366   3rd Qu.: 0.1974   3rd Qu.:-0.339   3rd Qu.: 0.4508  \n#>  Max.   :33.7073   Max.   :21.7306   Max.   :24.272   Max.   :21.8440  \n#>      church            jesus            bible             hair        \n#>  Min.   :-0.2773   Min.   :-0.194   Min.   :-0.105   Min.   :-0.4028  \n#>  1st Qu.:-0.2773   1st Qu.:-0.194   1st Qu.:-0.105   1st Qu.:-0.4028  \n#>  Median :-0.2773   Median :-0.194   Median :-0.105   Median :-0.4028  \n#>  Mean   : 0.0000   Mean   : 0.000   Mean   : 0.000   Mean   : 0.0000  \n#>  3rd Qu.:-0.2773   3rd Qu.:-0.194   3rd Qu.:-0.105   3rd Qu.:-0.4028  \n#>  Max.   :47.2192   Max.   :49.328   Max.   :37.729   Max.   :17.0580  \n#>      dress             blonde             mall            shopping      \n#>  Min.   :-0.2432   Min.   :-0.1838   Min.   :-0.3705   Min.   :-0.4936  \n#>  1st Qu.:-0.2432   1st Qu.:-0.1838   1st Qu.:-0.3705   1st Qu.:-0.4936  \n#>  Median :-0.2432   Median :-0.1838   Median :-0.3705   Median :-0.4936  \n#>  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  \n#>  3rd Qu.:-0.2432   3rd Qu.:-0.1838   3rd Qu.:-0.3705   3rd Qu.: 0.8737  \n#>  Max.   :20.2934   Max.   :39.8700   Max.   :16.5196   Max.   :10.4445  \n#>     clothes          hollister        abercrombie           die         \n#>  Min.   :-0.3166   Min.   :-0.2004   Min.   :-0.1825   Min.   :-0.3078  \n#>  1st Qu.:-0.3166   1st Qu.:-0.2004   1st Qu.:-0.1825   1st Qu.:-0.3078  \n#>  Median :-0.3166   Median :-0.2004   Median :-0.1825   Median :-0.3078  \n#>  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  \n#>  3rd Qu.:-0.3166   3rd Qu.:-0.2004   3rd Qu.:-0.1825   3rd Qu.:-0.3078  \n#>  Max.   :16.1428   Max.   :22.1627   Max.   :23.7896   Max.   :26.2269  \n#>      death             drunk             drugs             female       \n#>  Min.   :-0.2529   Min.   :-0.2217   Min.   :-0.1757   Min.   :-2.0727  \n#>  1st Qu.:-0.2529   1st Qu.:-0.2217   1st Qu.:-0.1757   1st Qu.: 0.4824  \n#>  Median :-0.2529   Median :-0.2217   Median :-0.1757   Median : 0.4824  \n#>  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  \n#>  3rd Qu.:-0.2529   3rd Qu.:-0.2217   3rd Qu.:-0.1757   3rd Qu.: 0.4824  \n#>  Max.   :30.9186   Max.   :19.6631   Max.   :32.2532   Max.   : 0.4824\nset.seed(2345)\n#Ayer  \nteen_clusters <- kmeans(teens_scale, 2)\n\ncentroids<-teen_clusters$centers\nclass(centroids)\n#> [1] \"matrix\" \"array\"\nfviz_cluster(teen_clusters, data = teens_2 , stand=F)\nbarplot(height =centroids,main=\"Centroids\",legend.text = TRUE,\n        beside = TRUE,col=c(\"red\",\"blue\"),las=2)\n# data is a matrix object with the centroids\n# name is the plot name (main argument)\nmy_plot<-function(data,name){\n  \nbarplot(height =data,main=name,legend.text = TRUE,\n        beside = TRUE,col=c(\"red\",\"blue\"),las=2)}\n\nse<-seq(1,2,1) \nhc_caract<-centroids[,c(\"gender\",\"age\",\"friends\")]\n\nmy_plot(hc_caract,\"Características generales\")"}]
