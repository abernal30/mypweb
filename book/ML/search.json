[{"path":"index.html","id":"machine-learning-introductory-guide","chapter":"Machine learning introductory guide","heading":"Machine learning introductory guide","text":"book Machine learning introductory guide!work Aturo Bernal\nVisit GitHub repository site.","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"text examples aim generate basic guide Machine Learning (ML) methodology. writing book inspired students AI concentration Tecnologico de Monterrey spring 2022.document follows practical example: ) continuous variables California Housing Prices data set presented (Géron 2023); ii) categorical variables, follow Lending Club fintech data set Kaggle analyze credit default, financial institution grants personal loans.following steps may differ books, data scientists, experts many ways deal whit machine learning. precisely richness area expertise. existed one way apply machine learning, everybody use !!R files stored GitHub repository site.","code":""},{"path":"preface.html","id":"outline","chapter":"Preface","heading":"Outline","text":"","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"ml-in-the-bussines-lascape-and-data-collection","chapter":"1 ML in the bussines lascape and data collection","heading":"1 ML in the bussines lascape and data collection","text":"","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"machine-learning-ml","chapter":"1 ML in the bussines lascape and data collection","heading":"1.1 Machine learning (ML)","text":"short, machine learning problem generally relates prediction data available. Machine Learning science (art) programming computers can learn data (Géron 2023). extracting knowledge data, research field intersection statistics, artificial intelligence, computer science. also known predictive analytics statistical learning (Muller?).\nMachine learning programming, programming problems require ML. detect problem facing ML problem, need objective, benefit company (client) apply business (Burton Shah 2013).paragraph, describe examples. describing examples, use terminology may sound unfamiliar , cover chapters.Understanding goal allows us determine kind data expect handle models apply. Suppose facing problem housing market, business objective detect investment opportunities buying sub-valuated (price) houses predicting housing prices. example, expect housing price data, housing location latitude, longitude, median age z, total rooms, etc. case, may apply supervised models linear regression evaluate model performance RMSE. Another example financial sector predicting new bank customer default loan (repay loan ). case, classification problem, use models logit LDA measure performance Confusion Matrix.\nhand, housing prices example, already information mentioned last paragraph, want know crime affects price areas. solve linear regression, wúltnd ML problem, causality one. ML problem want predict house prices certain areas crime increased. Even ML problem, wouldn´t necessarily benefit client us. example, client housing builder, help decide build. Still, client unaffected relationship crime-house prices, ML problem, benefiting client us.conclusion, handling data running algorithms, suggest establishing business goal, detecting ML problem, benefit company (client).","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"business-objectives-and-data-sources","chapter":"1 ML in the bussines lascape and data collection","heading":"1.2 Business objectives and data sources","text":"book, use cross-sectional data set consisting sample houses bank clients taken given time: ) house pricing; ii) credit analysis. time series objectives consist observations variable several variables time, see chapters four five book (Bernal 2023).","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"variables-terminology-and-notation","chapter":"1 ML in the bussines lascape and data collection","heading":"1.3 Variables terminology and notation","text":"Many models cover book kind:\\[y=\\alpha_{0}\\ +\\beta_{1}\\ x_{1}+\\beta_{2}\\ x_{2}+...+\\beta_{n}\\ x_{n}+e\\]\n\\(y\\) called dependent variable, also materials , called explained, output variable response variable. hand, \\(x\\) called independent variables input variables, predictors features. \\(\\beta´s\\) parameters estimated, \\(e\\) error term.regression, idea estimate parameters \\(\\beta_{1}, \\beta_{2},...,\\beta_{n}\\), predict value \\(y\\). happens, represent predicted values estimated parameters :\\[\\hat{y}=\\beta_{0}\\ +\\hat{\\beta_{1}}\\ x_{1}+\\hat{\\beta_{1}}\\ x_{2}+...+\\ \\hat{\\beta_{1}}\\ x_{n}\\]\nAlso, compare \\(y_{}\\) predicted value, call residual, usually denoted \\(\\hat{e}\\). defined :\\[\\hat{e_{}}=y_{}-\\hat{y_{}}=y_{}-\\beta_{0}\\ -\\hat{\\beta_{1}}\\ x_{1i}-\\hat{\\beta_{1}}\\ x_{2i}-,...,-\\ \\hat{\\beta_{1}}\\ x_{ni}\\]\nwords, \\(\\hat{e_{}}\\) residual observation. example, data set \\(n\\) variables \\(m\\) observations, \\(m\\) residuals.","code":""},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"house-pricing","chapter":"1 ML in the bussines lascape and data collection","heading":"1.3.1 House pricing","text":"case, facing problem housing market, business objective detect investment opportunities, buying sub-valuated (price) houses predicting median housing price.can get data GitHub:housing data house media prices, houses location latitude x, longitude y, housing median age z, total rooms, etc. apply following model.\\[median\\_house\\_value=\\beta_{0}\\ +\\beta_{1}\\ longitude+\\beta_{2}\\ latitude+...+\\beta_{n}\\ variable_{n}+e\\]","code":"\nhouse<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/housing.csv\")\nstr(house)\n#> 'data.frame':    584 obs. of  52 variables:\n#>  $ Id           : int  1 2 3 4 5 6 7 8 9 10 ...\n#>  $ SalePrice    : int  181500 223500 140000 250000 307000 129900 118000 345000 279500 325300 ...\n#>  $ MSSubClass   : int  20 60 70 60 20 50 190 60 20 60 ...\n#>  $ MSZoning     : int  4 4 4 4 4 5 4 4 4 4 ...\n#>  $ LotFrontage  : int  80 68 60 84 75 51 50 85 91 101 ...\n#>  $ LotArea      : int  9600 11250 9550 14260 10084 6120 7420 11924 10652 14215 ...\n#>  $ LotShape     : int  4 1 1 1 4 4 4 1 1 1 ...\n#>  $ LotConfig    : int  3 5 1 3 5 5 1 5 5 1 ...\n#>  $ Neighborhood : int  25 6 7 14 21 18 4 16 6 16 ...\n#>  $ Condition1   : int  2 3 3 3 3 1 1 3 3 3 ...\n#>  $ BldgType     : int  1 1 1 1 1 1 2 1 1 1 ...\n#>  $ HouseStyle   : int  3 6 6 6 3 1 2 6 3 6 ...\n#>  $ OverallQual  : int  6 7 7 8 8 7 5 9 7 8 ...\n#>  $ OverallCond  : int  8 5 5 5 5 5 6 5 5 5 ...\n#>  $ YearRemodAdd : int  1976 2002 1970 2000 2005 1950 1950 2006 2007 2006 ...\n#>  $ RoofStyle    : int  2 2 2 2 2 2 2 4 2 2 ...\n#>  $ Exterior1st  : int  9 13 14 13 13 4 9 15 13 13 ...\n#>  $ MasVnrType   : int  3 2 3 2 4 3 3 4 4 2 ...\n#>  $ MasVnrArea   : int  0 162 0 350 186 0 0 286 306 380 ...\n#>  $ ExterQual    : int  4 3 4 3 3 4 4 1 3 3 ...\n#>  $ ExterCond    : int  5 5 5 5 5 5 5 5 5 5 ...\n#>  $ Foundation   : int  2 3 1 3 3 1 1 3 3 3 ...\n#>  $ BsmtQual     : int  3 3 4 3 1 4 4 1 3 1 ...\n#>  $ BsmtExposure : int  2 3 4 1 1 4 4 4 1 1 ...\n#>  $ BsmtFinType1 : int  1 3 1 3 3 6 3 3 6 6 ...\n#>  $ BsmtFinSF1   : int  978 486 216 655 1369 0 851 998 0 0 ...\n#>  $ BsmtUnfSF    : int  284 434 540 490 317 952 140 177 1494 1158 ...\n#>  $ HeatingQC    : int  1 1 3 1 1 3 1 1 1 1 ...\n#>  $ CentralAir   : int  2 2 2 2 2 2 2 2 2 2 ...\n#>  $ Electrical   : int  5 5 5 5 5 2 5 5 5 5 ...\n#>  $ X1stFlrSF    : int  1262 920 961 1145 1694 1022 1077 1182 1494 1158 ...\n#>  $ X2ndFlrSF    : int  0 866 756 1053 0 752 0 1142 0 1218 ...\n#>  $ BsmtFullBath : int  0 1 1 1 1 0 1 1 0 0 ...\n#>  $ BsmtHalfBath : int  1 0 0 0 0 0 0 0 0 0 ...\n#>  $ FullBath     : int  2 2 1 2 2 2 1 3 2 3 ...\n#>  $ HalfBath     : int  0 1 0 1 0 0 0 0 0 1 ...\n#>  $ BedroomAbvGr : int  3 3 3 4 3 2 2 4 3 4 ...\n#>  $ KitchenQual  : int  4 3 3 3 3 4 4 1 3 3 ...\n#>  $ TotRmsAbvGrd : int  6 6 7 9 7 8 5 11 7 9 ...\n#>  $ Fireplaces   : int  1 1 1 1 1 2 2 2 1 1 ...\n#>  $ FireplaceQu  : int  5 5 3 5 3 5 5 3 3 3 ...\n#>  $ GarageType   : int  2 2 6 2 2 6 2 4 2 4 ...\n#>  $ GarageYrBlt  : int  1976 2001 1998 2000 2004 1931 1939 2005 2006 2005 ...\n#>  $ GarageFinish : int  2 2 3 2 2 3 2 1 2 2 ...\n#>  $ GarageArea   : int  460 608 642 836 636 468 205 736 840 853 ...\n#>  $ PavedDrive   : int  3 3 3 3 3 3 3 3 3 3 ...\n#>  $ WoodDeckSF   : int  298 0 0 192 255 90 0 147 160 240 ...\n#>  $ OpenPorchSF  : int  0 42 35 84 57 0 4 21 33 154 ...\n#>  $ MoSold       : int  5 9 2 12 8 4 1 7 8 11 ...\n#>  $ YrSold       : int  2007 2008 2006 2008 2007 2008 2008 2006 2007 2006 ...\n#>  $ SaleType     : int  9 9 9 9 9 9 9 7 7 7 ...\n#>  $ SaleCondition: int  5 5 1 5 5 1 5 6 6 6 ..."},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"the-credit-analysis","chapter":"1 ML in the bussines lascape and data collection","heading":"1.3.2 The credit analysis","text":"credit analysis case, interested predicting new bank customer default loan (repay loan ). classification problem, use models logit LDA. can get data also GitHub.database historical information Lendingclub, https://www.lendingclub.com/ fintech marketplace bank scale. original data set least 2 million observations 150 variables. find 873 observations (rows) 71 columns. row represents Lendingclub client. previously made data cleaning (missing values, correlated variables, Zero- Near Zero-Variance Predictors).case, model .\\[Default=\\beta_{0}\\ +\\beta_{1}\\ term_{1}+\\beta_{2}\\ grade_{2}+...+\\beta_{n}\\ variable_{n}+e\\]variable “Default” winch originally name “loan_status”; two labels:“Charge ” means credit grantor wrote account receivables loss closed future charges. account displays status “charge ,” closed future use, although customer still owns debt. example, consider Charged equivalent Default Fully Paid default.previous output, show “Default” variable class “character,” function apply accept numeric factor variables. transform variable “factor.”","code":"\ncredit<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/credit.csv\")\nstr(credit[,1:5])\n#> 'data.frame':    873 obs. of  5 variables:\n#>  $ Default    : chr  \"Fully Paid\" \"Fully Paid\" \"Fully Paid\" \"Fully Paid\" ...\n#>  $ term       : int  1 1 2 2 1 1 1 1 1 1 ...\n#>  $ installment: num  123 820 433 290 405 ...\n#>  $ grade      : int  3 3 2 6 3 2 2 1 2 3 ...\n#>  $ emp_title  : num  299 209 623 126 633 636 481 540 631 314 ...\ntable(credit[,\"Default\"])\n#> \n#> Charged Off  Fully Paid \n#>         145         728\ncredit[,\"Default\"]<-factor(credit[,\"Default\"])"},{"path":"ml-in-the-bussines-lascape-and-data-collection.html","id":"take-a-quick-look-at-the-data-structure","chapter":"1 ML in the bussines lascape and data collection","heading":"1.4 Take a Quick Look at the Data Structure","text":"ML literature suggests looking data structure see issues, numerical categorical variables, missing values, etc. several books cover , cover book. suggest chapter two book (Bernal 2023). However, include section book? expect book introductory guide ML. , book’s structure steps develop ML analysis without redundant materials.","code":""},{"path":"training-and-evaluating-regression-models.html","id":"training-and-evaluating-regression-models","chapter":"2 Training and evaluating regression models","heading":"2 Training and evaluating regression models","text":"","code":""},{"path":"training-and-evaluating-regression-models.html","id":"model-training","chapter":"2 Training and evaluating regression models","heading":"2.1 Model training","text":"goal machine learning models regression predict dependent variable, \\(y\\). example, house pricing data set described chapter 1, defined dependent variable “SalePrice”, independent variables MSSubClass, MSZoning others data set.\\[SalePrice=\\beta_{0}+\\beta_{1}\\ MSSubClass + \\beta_{2}\\ MSZoning+ ....+x_{n}+ e\\]\\(e\\) error term. regression model aims estimate parameters \\(\\beta_{1}, \\beta_{2},...,\\beta_{n}\\), predict SalePrice. following predicted model. call training.\\[\\hat{SalePrice}=\\hat{\\beta_{0}}+\\hat{\\beta_{1}}MSSubClass+\\hat{\\beta_{2}}MSZoning+....+\\hat{\\beta_{n}}x_{n} \\]hat parameters indicates estimated parameters.\nNote: learning ML, convenient understand models step step. familiar estimating regression prediction, can skip following steps Training test set (Back testing).exemplify ML regression models works, first estimate two independent variables: MSSubClass MSZoning.\\[SalePrice=\\beta_{0}+\\beta_{1}\\ MSSubClass + \\beta_{2}\\ MSZoning + \\epsilon \\]R, use “lm” function run regression model Ordinary Least squaresAs result, get following estimated model:\\[`\\hat{r con[2]`}= 354837.1+-233.4\\ MSSubClass + -29665.2\\ MSZoning\\]Machine Learning (ML), concerned coefficient significance; chapter one, explain differences Machine Learning models causality approach ones explain . ML models, predict dependent variable, case, SalePrice, given certain features independent variables.Suppose want predict SalePrice values variables MSSubClass MSZoning 20 4, respectively. following formula predicts SalePrice taking parameters OLS regression:SalePrice=354837.1+354837.1 * 20+-29665.2*4 = 231508.1The result 231508.1 predicts SalePrice variables MSSubClass MSZoning take values 20 4, respectively.Remember previous result exposition proposes. use “predict” function, gives us result. must add arguments OLS model object data frame features want predict.still determining previous prediction good. moment, can compare observation “house” data set, example, first one:prediction far SalePrice observation “house” data set. course, need add independent variables procedures, cover subsequent sections.","code":"\nhouse<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/housing.csv\")\nhouse_model<-lm(SalePrice~MSSubClass+MSZoning,data=house)\nsummary(house_model)\n#> \n#> Call:\n#> lm(formula = SalePrice ~ MSSubClass + MSZoning, data = house)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -169125  -58658  -26555   43751  532828 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 354837.1    30654.8  11.575  < 2e-16 ***\n#> MSSubClass    -233.4      102.0  -2.289   0.0224 *  \n#> MSZoning    -29665.2     7528.4  -3.940 9.12e-05 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 90790 on 581 degrees of freedom\n#> Multiple R-squared:  0.03625,    Adjusted R-squared:  0.03294 \n#> F-statistic: 10.93 on 2 and 581 DF,  p-value: 2.194e-05\npredict(house_model,house_test)\n#>        1 \n#> 231508.1\nhead(house[1,2:4])\n#>   SalePrice MSSubClass MSZoning\n#> 1    181500         20        4"},{"path":"training-and-evaluating-regression-models.html","id":"training-and-test-set-back-testing","chapter":"2 Training and evaluating regression models","heading":"2.1.1 Training and test set (Back testing)","text":"previous section, made one prediction compared given observation. machine learning literature common apply testing procedure several observations. book, call back-testing, divides data set training testing, often called in_sample out_sample. previous example, house_test must data frame. However, instead one observation two independent variables, contain many observations independent variables.answer need back-testing, think want validate prediction performance, least two alternatives:Alternative 1: Estimate ML model, make prediction wait time, example, 30 days, verify prediction good ; forecast good (close real value), train test , let’s say 30 days .Alternative 2 (one apply): Take aside observations, assuming observations don’t know store data frame called “test.” Train test ML model. making good prediction, train test model get good prediction performance.common practice divide data set training (80% observations) testing (20%). However, authors suggest splitting Training Set, Validation Set Test Set (Lantz 2019). latter case, proposal train model training set (example, 60% data), cross-validation (procedure cover ) validation set (example, 20% data), model good prediction performance, test test set (20% data).book, use methods. start chapter first one, cross-validation chapter, cover second one.housing prices data set, split randomly 80%, applying function sample.“set.seed” function helps us control results getting aleatory partition data; otherwise, get different result every time run R chunk. spirit book compare various methods methodologies without concern possible differences models processes result random partition.compare original house data set previous output, “rownames” (ID) different order selected randomly. Another important distinction observations house_test data set complement house_train. words, observations (IDs) training set aren’t test, vice versa.","code":"\nset.seed (26)\ndim<-dim(house)\ntrain_sample<-sample(dim[1],dim[1]*.8)\nhouse_train <- house[train_sample, ]\nhouse_test  <- house[-train_sample, ]\nhead(house_train[,1:5])\n#>      Id SalePrice MSSubClass MSZoning LotFrontage\n#> 64   64    163000         20        4          80\n#> 540 540    170000         80        4         102\n#> 200 200    155000         70        5          50\n#> 171 171    142000         20        4          65\n#> 41   41    250000         60        2          75\n#> 268 268    155000         60        4          70\nhead(house_test[,1:5])\n#>    Id SalePrice MSSubClass MSZoning LotFrontage\n#> 17 17    165500         20        4          70\n#> 20 20    153000         20        4          74\n#> 26 26    385000         20        4          68\n#> 31 31    317000         60        4          76\n#> 42 42    190000         20        4         105\n#> 43 43    383970         60        4          77"},{"path":"training-and-evaluating-regression-models.html","id":"performance-measure","chapter":"2 Training and evaluating regression models","heading":"2.1.2 Performance Measure","text":"","code":""},{"path":"training-and-evaluating-regression-models.html","id":"rmse","chapter":"2 Training and evaluating regression models","heading":"2.1.3 RMSE","text":"previous section, discussed whether prediction good (prediction performance). section formally defines metrics prediction performance.first metric Root Mean Square Error (RMSE). mathematical formula compute RMSE :\\[RMSE =\\sqrt{\\frac{1}{n}\\ \\sum_{=1}^{n} (y_{}-\\hat{y_{}})^{2}} \\]\\(\\hat{y_{}}\\) prediction ith observation, \\(y_{}\\) ith observation independent variable store test set, n number observations.\\[\\hat{y_{}}=\\hat{\\beta_{0}}+\\hat{\\beta_{1}}x_{1}+,..,+\\hat{\\beta_{n}}x_{n}\\]can estimate RMSE using training data set. generally, care well model works training set. Rather, interested model performance tested unseen data; , try RMSE test data set validation set cross-validation. lower test RMSE, better prediction.estimate RMSE housing example. time use variables data set. train model, use training data set. “lm” function requires adding dot symbol “~.”make prediction, use test data set.previous output, numbers prediction (17,20,26,31, etc.) row number test data frame model predicted. calling RMSE test test test data set. code estimate RMSE :ML’s main idea minimize RMSE test possible. subsequent sections, show accomplish .","code":"\nhouse_model<-lm(SalePrice~.,data=house_train)\nsummary(house_model)\n#> \n#> Call:\n#> lm(formula = SalePrice ~ ., data = house_train)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -311484  -19921   -1159   18474  219630 \n#> \n#> Coefficients:\n#>                 Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)    1.535e+06  3.384e+06   0.454  0.65040    \n#> Id            -1.208e+01  1.268e+01  -0.953  0.34119    \n#> MSSubClass    -2.860e+02  1.367e+02  -2.092  0.03706 *  \n#> MSZoning      -1.286e+03  4.747e+03  -0.271  0.78667    \n#> LotFrontage   -3.126e+02  1.021e+02  -3.061  0.00235 ** \n#> LotArea        5.531e-01  2.113e-01   2.618  0.00918 ** \n#> LotShape      -2.770e+03  1.680e+03  -1.649  0.09984 .  \n#> LotConfig     -1.144e+03  1.422e+03  -0.805  0.42134    \n#> Neighborhood   3.287e+02  4.110e+02   0.800  0.42439    \n#> Condition1    -1.679e+03  2.579e+03  -0.651  0.51547    \n#> BldgType       1.202e+03  4.281e+03   0.281  0.77909    \n#> HouseStyle    -2.336e+03  1.830e+03  -1.276  0.20267    \n#> OverallQual    1.797e+04  3.096e+03   5.806 1.28e-08 ***\n#> OverallCond    9.543e+03  2.960e+03   3.224  0.00136 ** \n#> YearRemodAdd  -1.525e+01  2.074e+02  -0.074  0.94142    \n#> RoofStyle      3.244e+03  2.784e+03   1.165  0.24465    \n#> Exterior1st   -1.142e+03  7.714e+02  -1.481  0.13937    \n#> MasVnrType     1.049e+03  3.500e+03   0.300  0.76450    \n#> MasVnrArea     5.071e+01  1.210e+01   4.189 3.42e-05 ***\n#> ExterQual     -8.256e+03  4.918e+03  -1.679  0.09400 .  \n#> ExterCond      6.708e+02  3.758e+03   0.178  0.85842    \n#> Foundation     7.901e+03  5.232e+03   1.510  0.13179    \n#> BsmtQual      -1.073e+04  3.331e+03  -3.222  0.00137 ** \n#> BsmtExposure  -5.919e+03  2.114e+03  -2.801  0.00534 ** \n#> BsmtFinType1  -3.214e+03  1.588e+03  -2.024  0.04361 *  \n#> BsmtFinSF1    -2.507e+01  9.435e+00  -2.657  0.00819 ** \n#> BsmtUnfSF     -1.827e+01  9.992e+00  -1.828  0.06825 .  \n#> HeatingQC     -6.688e+02  1.636e+03  -0.409  0.68287    \n#> CentralAir     4.803e+03  2.020e+04   0.238  0.81217    \n#> Electrical     7.323e+02  3.113e+03   0.235  0.81414    \n#> X1stFlrSF      3.447e+01  1.291e+01   2.671  0.00786 ** \n#> X2ndFlrSF      2.999e+01  1.101e+01   2.724  0.00672 ** \n#> BsmtFullBath   1.070e+04  6.443e+03   1.661  0.09749 .  \n#> BsmtHalfBath   4.813e+03  8.795e+03   0.547  0.58453    \n#> FullBath       1.772e+04  6.958e+03   2.547  0.01123 *  \n#> HalfBath       1.030e+04  6.666e+03   1.545  0.12303    \n#> BedroomAbvGr  -5.016e+03  4.631e+03  -1.083  0.27937    \n#> KitchenQual   -7.330e+03  3.546e+03  -2.067  0.03936 *  \n#> TotRmsAbvGrd   5.196e+03  2.754e+03   1.887  0.05987 .  \n#> Fireplaces     1.291e+04  6.274e+03   2.057  0.04029 *  \n#> FireplaceQu   -3.753e+03  2.213e+03  -1.696  0.09072 .  \n#> GarageType    -4.360e+02  1.880e+03  -0.232  0.81674    \n#> GarageYrBlt   -1.237e+02  1.902e+02  -0.650  0.51576    \n#> GarageFinish  -2.065e+03  3.550e+03  -0.582  0.56114    \n#> GarageArea     4.217e+01  1.718e+01   2.454  0.01453 *  \n#> PavedDrive     3.140e+03  8.320e+03   0.377  0.70602    \n#> WoodDeckSF     1.127e+01  1.993e+01   0.566  0.57191    \n#> OpenPorchSF   -1.189e+01  3.404e+01  -0.349  0.72699    \n#> MoSold        -4.744e+02  7.750e+02  -0.612  0.54080    \n#> YrSold        -6.036e+02  1.682e+03  -0.359  0.71984    \n#> SaleType      -1.475e+03  1.799e+03  -0.820  0.41280    \n#> SaleCondition  4.838e+03  2.319e+03   2.087  0.03752 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 44510 on 415 degrees of freedom\n#> Multiple R-squared:  0.7822, Adjusted R-squared:  0.7554 \n#> F-statistic: 29.22 on 51 and 415 DF,  p-value: < 2.2e-16\nhouse_predict<-predict(house_model,house_test)\nhead(house_predict)\n#>       17       20       26       31       42       43 \n#> 152651.6 135846.9 321903.0 312590.4 219878.9 331208.6\nchp3_swr<-sqrt(mean((house_test[,\"SalePrice\"]-house_predict)^2 ,na.rm = T))\nchp3_swr\n#> [1] 47889.11"},{"path":"training-and-evaluating-regression-models.html","id":"mean-absolute-error-mae","chapter":"2 Training and evaluating regression models","heading":"2.1.4 Mean absolute error (MAE)","text":"RMSE generally preferred performance measure regression models. However, measuring model performance MAE useful data outliers.\\[MAE =\\frac{1}{n}\\ \\sum_{=1}^{n} |y_{}-\\hat{y_{}}|\\]\nexample, Mean absolute error test (MAE) :","code":"\nmean(abs(house_test[,\"SalePrice\"]-house_predict),na.rm = T)\n#> [1] 28038.65"},{"path":"training-and-evaluating-regression-models.html","id":"r-squared","chapter":"2 Training and evaluating regression models","heading":"2.1.5 R-squared","text":"called Goodness--Fit measure. define R-squared follows:\n\\[R^2=SSE/SST\\]interpret fraction sample variation dependent variable \\(y\\), explained independent variable \\(X\\). \\(SST\\) total sum squares,\\[SST=\\frac{1}{n}\\ \\sum_{=1}^{n}(y_{}-\\overline{y})^{2},\\]\\(\\overline{y}\\) sample average \\(y_{}\\). indicator SST measures total sample variation \\(y_{}\\). measure SSE explained sum squares,\\[SSE=\\frac{1}{n}\\ \\sum_{=1}^{n}(\\hat{y_{}}-\\overline{y})^{2}.\\]\nSSE measures sample variation \\(\\hat{y_{}}\\) (Wooldridge 2020).","code":""},{"path":"training-and-evaluating-regression-models.html","id":"model-selection","chapter":"2 Training and evaluating regression models","heading":"2.1.6 Model Selection","text":"can improve RMSE several ways. first one applying ML methodologies. section starts subset selection, Regularization dimension Reduction.subset selection consists independent variables selection among available independent variables, helps improve model’s predictability performance. housing example 51 independent variables, including ID. must careful choosing among variables. see define train_RMSE:\\[train\\_RMSE =\\sqrt{\\frac{1}{n}\\ \\sum_{=1}^{n} (y_{}-\\hat{y_{}})^{2}}=\\sqrt{\\frac{1}{n}\\ train\\_RSS}\\]:\\[train\\_RSS = \\sum_{=1}^{n} (y_{}-\\hat{y_{}})^{2}=e_{1}^2+e_{2}^2+,..+e_{n}^2 \\]\n\\(train\\_RSS\\) explained sum squares residual sum squares training data set. consequence, RMSE decrease \\(train\\_RSS\\) decrease. According (James et al. 2017), \\(train\\_RSS\\) decrease number independent variables included models increases, even variables unrelated independent variable (significant). Therefore, use statistics select best model training data set, always end model involving variables. problem low \\(RSS\\) indicates model low training error, whereas wish choose model low test error (James et al. 2017). problem overfitting data, term explain (Suzuky 2022).solve , indicators looks minimize RSS penalize inclusion independent variables, example, Akaike Information Criterion AIC:solve problem, use indicators aim minimize RSS, penalizing inclusion independent variables, example, Akaike Information Criterion AIC:\\[AIC=\\frac{1}{n \\hat{\\sigma^2}}(RSS+2d\\hat{\\sigma^2})\\]\\(\\hat{\\sigma^2}\\) estimate variance error term, \\(d\\) number predictors, \\(n\\) number observations. AIC adds penalty \\(2d\\hat{\\sigma^2}\\) training RSS adjust training error tends underestimate test error. penalty increases number predictors model increases; intended adjust corresponding decrease training RSS (statistical_learning?). decision criteria model lower AIC.use function step, chooses variables according AIC.trace=F argument printing models algorithm evaluates. direction=“,” selection methods. Forward selection begins model containing independent variables adds predictors model one time predictors model; finally selects model (combination variables) lowest AIC. important notice algorithm selected among possible combinations. example, case 51 vaiiravles, imply \\(2^{51}=2.2518e+15\\). instead, evaluate \\(RSS = \\sum_{k=o}^{p-1} (p-k)=1+p(p+1)/2=1+50(50+1)/2=1327\\) models (statistical_learning?).hand, backward begins full least squares model containing \\(p\\) predictors interactively removes least useful predictor, one time. “” argument implies applies procedures, forward backward.exposition purposes, print AIC criterion two models, one 51 variables one variable selection based AIC.expected, model using step function lowest AIC. Also, estimate RMSE test data set step model, get:lower one full variables model.","code":"\nstep_house<-step(house_model,house_test,trace = F,direction=\"both\")\nsummary(step_house)\n#> \n#> Call:\n#> lm(formula = SalePrice ~ MSSubClass + LotFrontage + LotArea + \n#>     LotShape + HouseStyle + OverallQual + OverallCond + Exterior1st + \n#>     MasVnrArea + ExterQual + Foundation + BsmtQual + BsmtExposure + \n#>     BsmtFinType1 + BsmtFinSF1 + BsmtUnfSF + X1stFlrSF + X2ndFlrSF + \n#>     BsmtFullBath + FullBath + HalfBath + KitchenQual + TotRmsAbvGrd + \n#>     Fireplaces + FireplaceQu + GarageArea + SaleCondition, data = house_train)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -320194  -19377   -1434   17833  220366 \n#> \n#> Coefficients:\n#>                 Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)    4.120e+04  4.318e+04   0.954 0.340604    \n#> MSSubClass    -2.299e+02  6.787e+01  -3.388 0.000768 ***\n#> LotFrontage   -3.216e+02  9.392e+01  -3.424 0.000674 ***\n#> LotArea        5.828e-01  2.036e-01   2.862 0.004411 ** \n#> LotShape      -2.812e+03  1.537e+03  -1.829 0.068033 .  \n#> HouseStyle    -2.889e+03  1.553e+03  -1.860 0.063500 .  \n#> OverallQual    1.893e+04  2.922e+03   6.478 2.49e-10 ***\n#> OverallCond    9.620e+03  2.386e+03   4.032 6.53e-05 ***\n#> Exterior1st   -1.302e+03  7.056e+02  -1.845 0.065677 .  \n#> MasVnrArea     5.605e+01  1.050e+01   5.338 1.51e-07 ***\n#> ExterQual     -8.628e+03  4.554e+03  -1.894 0.058823 .  \n#> Foundation     8.200e+03  4.347e+03   1.886 0.059902 .  \n#> BsmtQual      -1.178e+04  3.121e+03  -3.774 0.000182 ***\n#> BsmtExposure  -5.687e+03  2.000e+03  -2.844 0.004665 ** \n#> BsmtFinType1  -3.146e+03  1.507e+03  -2.088 0.037393 *  \n#> BsmtFinSF1    -2.498e+01  8.965e+00  -2.786 0.005571 ** \n#> BsmtUnfSF     -2.111e+01  9.549e+00  -2.211 0.027582 *  \n#> X1stFlrSF      3.817e+01  1.159e+01   3.292 0.001074 ** \n#> X2ndFlrSF      2.565e+01  9.388e+00   2.732 0.006540 ** \n#> BsmtFullBath   9.998e+03  5.832e+03   1.714 0.087191 .  \n#> FullBath       1.689e+04  5.966e+03   2.831 0.004847 ** \n#> HalfBath       1.139e+04  6.012e+03   1.895 0.058711 .  \n#> KitchenQual   -7.131e+03  3.345e+03  -2.132 0.033563 *  \n#> TotRmsAbvGrd   4.149e+03  2.422e+03   1.713 0.087404 .  \n#> Fireplaces     1.359e+04  6.017e+03   2.259 0.024362 *  \n#> FireplaceQu   -4.135e+03  2.073e+03  -1.995 0.046680 *  \n#> GarageArea     4.338e+01  1.484e+01   2.923 0.003649 ** \n#> SaleCondition  4.348e+03  2.211e+03   1.967 0.049854 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 43750 on 439 degrees of freedom\n#> Multiple R-squared:  0.7774, Adjusted R-squared:  0.7637 \n#> F-statistic: 56.79 on 27 and 439 DF,  p-value: < 2.2e-16\nprint(extractAIC(step_house)[2])\n#> [1] 10008.02\nprint(extractAIC(house_model)[2])\n#> [1] 10045.9\nstep_house_predict<-predict(step_house,house_test)\nmean(abs(house_test[,\"SalePrice\"]-step_house_predict),na.rm = T)\n#> [1] 28117.64\nsqrt(mean((house_test[,\"SalePrice\"]-house_predict)^2 ,na.rm = T))\n#> [1] 47889.11"},{"path":"training-and-evaluating-regression-models.html","id":"overfittingunderfitting","chapter":"2 Training and evaluating regression models","heading":"2.1.7 Overfitting/Underfitting","text":"Overfitting occurs ML model trained learn noise (.e., non-representative data result chance) rather patterns trends data. following text (James et al. 2017):“general rule, use flexible methods, variance increase bias decrease. case, increase flexibility, bias tends initially decrease faster variance increases.Consequently, expected test MSE declines. However, point increasing flexibility little impact bias starts significantly increase variance.happens test MSE increases” .TTo explain better, use MSE decomposition. expected MSE decomposed following.\\[E(MSE) =E(\\frac{1}{n}\\ \\sum_{=1}^{n} (y-\\hat{y})^2)= E(\\epsilon^2)+E ((y-\\hat{y})^2)=Var(e)+Var(\\hat{y})+[Bias(\\hat{y})]^2\\]\n\\[Bias(\\hat{y})=y-E(\\hat{y})\\]\\[Var(\\hat{y})=E((y-E(\\hat{y}))^2)\\]See proof Appendix chapter.idea evaluating methodologies based notion Bias-Variance Trade-:\\(Var[e]\\) variance error term, call irreducible part.\\(E (y_{0}-\\hat{y})^{2}\\) average MSE test","code":""},{"path":"training-and-evaluating-regression-models.html","id":"appendix","chapter":"2 Training and evaluating regression models","heading":"2.2 Appendix","text":"","code":""},{"path":"training-and-evaluating-regression-models.html","id":"proof-of-emse-varepsilonvarhatybiashaty2","chapter":"2 Training and evaluating regression models","heading":"2.2.1 Proof of \\(E(MSE) =Var(\\epsilon)+Var(\\hat{y})+[Bias(\\hat{y})]^2\\)","text":"\\[E ((y-\\hat{y})^2)=E((y-E(\\hat{y})+E(\\hat{y})-\\hat{y})^2)=(y-E(\\hat{y}))^2+E((E(\\hat{y})-y)^2)+2E(y-E(\\hat{y}))\\ E(E(\\hat{y})-\\hat{y})\\]\\[2E(y-E(\\hat{y}))\\ E(E(\\hat{y})-\\hat{y})=2E(y-E(\\hat{y}))\\ (E(\\hat{y})-E(\\hat{y}))=0\\]\\[2E(y-E(\\hat{y}))\\ E(E(\\hat{y})-\\hat{y})=2E(y-E(\\hat{y}))\\ (E(\\hat{y})-E(\\hat{y}))=0\\]","code":""},{"path":"training-and-evaluating-clasification-models.html","id":"training-and-evaluating-clasification-models","chapter":"3 Training and evaluating clasification models","heading":"3 Training and evaluating clasification models","text":"linear regression, OLS, dependent variable continuous, SalePrice variable, sense house price $62,383 $755000. However, situations dependent variable two categories: women men, finance, signal buy sell, etc. case, call variables categorical. One popular classification models logistic regression linear discriminant analysis.\nsection, work credit data set. Remember describe credit data set chapter one, define model:section work credit data set. Remember describe credit data set chapter one, define model:\\[ Default=\\beta_{0}+\\beta_{1}\\ x_{1} + \\beta_{2}\\ x_{2}+ ....+\\beta_{n} x_{n}+\\epsilon \\]variable default categorical variable becasue takes folowing two values:function run logistic model R doesn´t accept character values, numeric factor. transform variable “factor.”split training test data sets, housing example.function run logistic model “glm”.paragraph , explain warning red: “glm.fit: fitted probabilities numerically 0 1 occurred”.use predict function make prediction.However, expected prediction either Charged Fully Paid, prediction numbers cero one.IIn following paragraph, explain type=“response” argument getting result, mainly, correct .\nalgorithm first transforms categories “Charged ” “Fully Paid” numerical values, Zero one. assigns probability tha \\(y\\) takes value one \\(P(y=1)= \\pi\\) takes value cero \\(P(y=0)= 1-\\pi\\). statistical analysis aims investigate relationship probability \\(\\pi(X)\\) independent variables \\(X=x_{1}, x_{2}...x_{n}\\) . convenient construct model capable describing effect \\(pi\\) changes \\(X=x_{1}, x_{2}...x_{n}\\), form function \\(g(\\pi)\\) (McCullagh? \nNelder (1989)).logic model function \\(g(\\pi)=\\log{(\\pi/(1-\\pi))}\\)\\[g(\\pi)=\\log{(\\pi/(1-\\pi))}=beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n} \\]Taking exponential sides, get:\\[\\pi/(1-\\pi)= \\exp{(beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n})}\\]\nresult equation probability; example, result :last code doesn´t include type=“response” argument. can see, results one less zero.get probability, need transformation like :\\[\\pi= \\frac{\\exp{(beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n})}}{1+\\exp{(beta_{0}+\\beta_{1}x_{1}+,..,+\\beta_{n}x_{n})}}\\]parameters estimate “glm” function, adding family=binomial() type= “response”, parameters last equation. Consequently, make prediction, get probability.\nFinally, must still resolve whether prediction Charged Fully Paid. transform following code.transform forecast category, establish threshold 0.5; prediction higher 0.5, convert “Fully Paid” otherwise “Charged .” “ok” wonder threshold 0.5. estimating prediction accuracy model, change threshold improve prediction performance.suggest verifying comparing resulting structure original data structure. case, “Charged ” 18 % observations (31 / (31+144)).complete data set (train + test), percentage 17%, consistent result. inconsistent result 87% prediction.","code":"\ncredit<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/credit.csv\")\ntable(credit[,\"Default\"])\n#> \n#> Charged Off  Fully Paid \n#>         145         728\ncredit[,\"Default\"]<-factor(credit[,\"Default\"])\n\nset.seed (43)\ndim<-dim(credit)\ntrain_sample<-sample(dim[1],dim[1]*.8)\ncredit_train <- credit[train_sample, ]\ncredit_test  <- credit[-train_sample, ]\ncredit_model<-glm(Default ~ .,data= credit_train ,family=binomial())\nsummary(credit_model)\n#> \n#> Call:\n#> glm(formula = Default ~ ., family = binomial(), data = credit_train)\n#> \n#> Deviance Residuals: \n#>        Min          1Q      Median          3Q         Max  \n#> -6.626e-05   2.100e-08   2.100e-08   2.100e-08   8.169e-05  \n#> \n#> Coefficients:\n#>                         Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)           -2.897e+02  2.242e+06   0.000    1.000\n#> term                  -8.976e+01  6.971e+04  -0.001    0.999\n#> installment           -1.223e-02  2.300e+02   0.000    1.000\n#> grade                  1.242e+01  3.695e+04   0.000    1.000\n#> emp_title              1.979e-02  2.551e+02   0.000    1.000\n#> emp_length             8.469e-01  2.485e+04   0.000    1.000\n#> home_ownership         9.860e+00  2.016e+04   0.000    1.000\n#> annual_inc            -9.569e-05  3.390e+00   0.000    1.000\n#> verification_status    4.514e+00  3.047e+04   0.000    1.000\n#> purpose               -4.467e+00  2.071e+04   0.000    1.000\n#> title                  1.085e+00  2.569e+04   0.000    1.000\n#> zip_code              -2.512e-02  8.173e+02   0.000    1.000\n#> addr_state             2.288e-01  3.921e+03   0.000    1.000\n#> dti                   -1.426e+00  8.380e+03   0.000    1.000\n#> delinq_2yrs           -3.129e+00  2.009e+04   0.000    1.000\n#> earliest_cr_line       3.055e-02  3.341e+02   0.000    1.000\n#> fico_range_high        5.329e-02  3.646e+03   0.000    1.000\n#> inq_last_6mths        -2.822e+00  4.734e+04   0.000    1.000\n#> pub_rec               -6.300e-01  1.310e+05   0.000    1.000\n#> revol_bal              1.205e-03  4.719e+00   0.000    1.000\n#> revol_util             8.785e-02  8.591e+03   0.000    1.000\n#> total_acc             -1.151e+01  5.819e+04   0.000    1.000\n#> total_rec_int          4.211e-03  1.308e+01   0.000    1.000\n#> recoveries            -1.110e-01  2.909e+02   0.000    1.000\n#> last_pymnt_d          -7.074e-01  2.275e+03   0.000    1.000\n#> last_pymnt_amnt        6.044e-03  1.338e+01   0.000    1.000\n#> last_credit_pull_d    -7.841e-01  4.390e+03   0.000    1.000\n#> last_fico_range_high   6.891e-01  4.561e+02   0.002    0.999\n#> last_fico_range_low   -4.923e-03  2.849e+02   0.000    1.000\n#> tot_coll_amt          -1.224e-03  2.466e+00   0.000    1.000\n#> tot_cur_bal           -2.562e-05  3.973e-01   0.000    1.000\n#> open_acc_6m           -1.177e+01  6.376e+04   0.000    1.000\n#> open_act_il           -6.880e+00  3.555e+04   0.000    1.000\n#> open_il_12m            9.614e+00  1.184e+05   0.000    1.000\n#> open_il_24m           -6.398e+00  4.427e+04   0.000    1.000\n#> mths_since_rcnt_il    -3.689e-01  1.095e+03   0.000    1.000\n#> total_bal_il          -1.374e-04  2.479e+00   0.000    1.000\n#> il_util               -3.744e-01  3.611e+03   0.000    1.000\n#> open_rv_12m            1.147e+01  7.695e+04   0.000    1.000\n#> open_rv_24m           -1.252e+01  4.016e+04   0.000    1.000\n#> max_bal_bc            -5.577e-04  1.057e+01   0.000    1.000\n#> all_util              -3.889e-01  4.471e+03   0.000    1.000\n#> total_rev_hi_lim      -3.081e-04  3.123e+00   0.000    1.000\n#> inq_fi                 1.414e-02  1.968e+04   0.000    1.000\n#> total_cu_tl           -3.728e+00  9.716e+03   0.000    1.000\n#> inq_last_12m          -8.275e-01  3.789e+04   0.000    1.000\n#> acc_open_past_24mths   1.146e+01  4.153e+04   0.000    1.000\n#> avg_cur_bal            1.149e-04  1.849e+00   0.000    1.000\n#> bc_open_to_buy         5.062e-04  1.554e+01   0.000    1.000\n#> bc_util                5.402e-02  1.391e+03   0.000    1.000\n#> mo_sin_old_il_acct     5.365e-02  4.233e+02   0.000    1.000\n#> mo_sin_old_rev_tl_op  -6.397e-03  8.812e+02   0.000    1.000\n#> mo_sin_rcnt_rev_tl_op -2.013e-01  3.696e+03   0.000    1.000\n#> mo_sin_rcnt_tl        -3.205e-02  2.013e+03   0.000    1.000\n#> mort_acc               1.140e+01  7.505e+04   0.000    1.000\n#> mths_since_recent_bc  -8.572e-03  3.642e+03   0.000    1.000\n#> mths_since_recent_inq  1.035e+00  4.052e+03   0.000    1.000\n#> num_accts_ever_120_pd  4.406e+00  2.104e+04   0.000    1.000\n#> num_actv_bc_tl        -2.636e+00  7.399e+04   0.000    1.000\n#> num_bc_sats            4.123e+00  8.698e+04   0.000    1.000\n#> num_bc_tl             -3.302e+00  4.186e+04   0.000    1.000\n#> num_il_tl              1.397e+01  6.543e+04   0.000    1.000\n#> num_op_rev_tl         -6.232e+00  6.346e+04   0.000    1.000\n#> num_rev_accts          1.211e+01  4.019e+04   0.000    1.000\n#> num_rev_tl_bal_gt_0   -8.575e-01  6.424e+04   0.000    1.000\n#> num_sats               5.882e+00  3.720e+04   0.000    1.000\n#> num_tl_op_past_12m    -5.371e+00  9.234e+04   0.000    1.000\n#> pct_tl_nvr_dlq        -1.125e-01  3.589e+03   0.000    1.000\n#> percent_bc_gt_75       4.595e-02  3.134e+03   0.000    1.000\n#> pub_rec_bankruptcies   7.226e+00  1.451e+05   0.000    1.000\n#> total_bc_limit        -1.527e-04  1.590e+01   0.000    1.000\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 6.3112e+02  on 697  degrees of freedom\n#> Residual deviance: 8.7225e-08  on 627  degrees of freedom\n#> AIC: 142\n#> \n#> Number of Fisher Scoring iterations: 25\ncredit_predict<-predict(credit_model, newdata=credit_test, type=\"response\")\nhead(credit_predict)\n#> 15 19 24 26 32 34 \n#>  1  1  1  1  1  1\nsummary(credit_predict)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>  0.0000  1.0000  1.0000  0.8246  1.0000  1.0000\ncredit_predict<-predict(credit_model, newdata=credit_test)\nsummary(credit_predict)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#> -723.24   42.34  100.77   73.04  134.64  316.01\ncredit_predict_char<-ifelse(credit_predict>.5,\"Fully Paid\",\"Charged Off\")\ntable(credit_predict_char)\n#> credit_predict_char\n#> Charged Off  Fully Paid \n#>          31         144"},{"path":"training-and-evaluating-clasification-models.html","id":"performance-measure-in-clasification","chapter":"3 Training and evaluating clasification models","heading":"3.0.1 Performance Measure in clasification","text":"Now measure prediction accuracy, applying confusion Matrix:Confusion matrixIt table categorizes predictions according whether match actual value. One table’s dimensions indicates possible categories predicted values, shows actual values. Although seen 2 x 2 confusion matrices far, matrix can created models predict number class values. following figure shows generic confusion matrix.\nFigure 3.1: Confusion matrix.\nTrue Positive (TP): Correctly classified class interest. True Negative (TN) Correctly classified class interest. False Positive (FP) Incorrectly classified class interest. False Negative (FN): Incorrectly classified class interest.\nuse confusionMatrix function library “caret” credit analysis example. first argument prediction, second argument reference, case, variable “Default” credit_test data set; variables must factors, true variable inside credit_test.review consistency data structure. case, consistent.\nimportant keep consistency levels; case, write first “Charged ” reference data set starts label first:Finally, apply function. case, assuming positive class, class interest, “Charged ”:several indicators output, “confusing.” analyze parts. start table:matrix’s left-superior/right-inferior numbers true positive/true negative number observations prediction equals reference. left-inferior/ right-superior numbers matrix true positive/ true negative number observations prediction “” equal reference.numbers get following metrics.accuracy :\\[ accuracy =\\frac{TP+TN}{TP+TN+FP+FN}\\]importance measure relative important analysis. example, imagine scenario company high default rate. case, may problematic predicting someone going pay credit ( “Fully Paid”) reality going pay (“Charged ”) predicting someone going pay credit (“Charged ”) reality pay ( “Fully Paid”). case, sensitivity good indicator.sensitivity 89.29% may high expected, example, follow 95% higher rule. hand, scenario company low default rate expecting expand business. problematic predict someone going pay credit (“Charged ”) reality, pay ( “Fully Paid”).case, class interest may “Fully Paid.” measure sensitivity making respective adjustments measure specificity.specificity measures proportion negatives correctly classified:\\[ specificity =\\frac{TN}{TN+FP}\\]latter implies 89.29% time, predicting well class “Fully Paid.”","code":"\nlibrary(\"caret\")\nDefaultf<-factor(credit_predict_char,levels=c(\"Charged Off\",\"Fully Paid\"))\ntable(Defaultf)\n#> Defaultf\n#> Charged Off  Fully Paid \n#>          31         144\nhead(credit_test[,\"Default\"])\n#> [1] Fully Paid Fully Paid Fully Paid Fully Paid Fully Paid Fully Paid\n#> Levels: Charged Off Fully Paid\nconfu<-confusionMatrix(Defaultf,credit_test[,\"Default\"],positive=\"Charged Off\")\nconfu\n#> Confusion Matrix and Statistics\n#> \n#>              Reference\n#> Prediction    Charged Off Fully Paid\n#>   Charged Off          25          6\n#>   Fully Paid            3        141\n#>                                           \n#>                Accuracy : 0.9486          \n#>                  95% CI : (0.9046, 0.9762)\n#>     No Information Rate : 0.84            \n#>     P-Value [Acc > NIR] : 8.743e-06       \n#>                                           \n#>                   Kappa : 0.8166          \n#>                                           \n#>  Mcnemar's Test P-Value : 0.505           \n#>                                           \n#>             Sensitivity : 0.8929          \n#>             Specificity : 0.9592          \n#>          Pos Pred Value : 0.8065          \n#>          Neg Pred Value : 0.9792          \n#>              Prevalence : 0.1600          \n#>          Detection Rate : 0.1429          \n#>    Detection Prevalence : 0.1771          \n#>       Balanced Accuracy : 0.9260          \n#>                                           \n#>        'Positive' Class : Charged Off     \n#> \nconfu$table\n#>              Reference\n#> Prediction    Charged Off Fully Paid\n#>   Charged Off          25          6\n#>   Fully Paid            3        141\nconfu$table[1]+confu$table[2]\n#> [1] 28\nconfu$overall[1]\n#>  Accuracy \n#> 0.9485714\nconfu$byClass[1]\n#> Sensitivity \n#>   0.8928571\nconfu$byClass[2]\n#> Specificity \n#>   0.9591837"},{"path":"cross-validation.html","id":"cross-validation","chapter":"4 Cross Validation","heading":"4 Cross Validation","text":"previous chapter, split sample training testing. partition different samples? Remember last chapter, got RMSE house_test data set 4.7889106^{4}. used another seed partition got lower, worse, higher RMSE? Don´t think better make many partitions estimate time RMSE verify consistent RMSE ? cross-validation. Instead dividing sample , cross-validation involves splitting sample several times estimating RMSE, MAE R-squared . several cross validations methods. common Leave-One-Cross-Validation (LOOCV) k-Fold Cross-Validation (k-fold).","code":""},{"path":"cross-validation.html","id":"leave-one-out-cross-validation-loocv","chapter":"4 Cross Validation","heading":"4.0.1 Leave-One-Out Cross-Validation (LOOCV)","text":"Understanding question. “id” previous output order (.e., 1,2,3,…,n)?Continuing housing example, split sample “n” parts. “n” number rows data set. Cross-validation training dataset; case, \\(n\\) 584.first fold partition taking first observation. see previous output, 1rst observation one id=77.first fold partition taking first observation. see previous output, 1rst observation one id=77.second fold taking second, one id=480And , get \\(n\\) folds, case, 467. One folds, usually first, validation set (like test data set). \\(n−1\\) model must trained tested, making prediction fold1 estimating performance metric, RMSE. example:processes repeat n-2 folds, training fold3 testing fold1. end, get n-1 performance measures. average RMSEs LOOCV.\\[LOOCV =\\frac{1}{n}\\ \\sum_{=1}^{n} RMSE_{} \\]last formula, use RMSE, metric, MAE Rsquared.Fortunately, function “train” library “caret” formerly described processes (Kuhn 2019).train function similar structure “lm” function.train(SalePrice ~ ., data = house_train,\nmethod = “lm”,\ntrControl = )first argument equation, second database. cross-validation, use train data set need specify model, case, “lm”. function allows 238 writing book, “lm” one . name says, argument “trControl” control cross-validation parameters.convenience, library developers suggest separating “trControl” argument argument ruled another function, “trainControl”, many parameters. start creating object function, argument method, case, “LOOCV”.use function train, specifying model “lm”, trControl use object fitControl.previous result, got RMSE 5.4486353^{4}, average n-1 RMSE. see implication previous result, remember previous chapter, got RMSE house_test data set 4.7889106^{4}, result one partition. last result, cross-validation, tells us, case, taking RMSE 4.7889106^{4} -estimating (thinking good model ) (thinking good model ) model performance.arguments “trainControl” function, preprocessing, indicate want process data, example, center scale.“preprocessing” message previous output indicates didn´t select option. preprocess option improve model performance. example, adding “nzv”, Zero- Near Zero-Variance Predictors, BoxCox transforming Predictors preprocess. explanation preprocess alternatives, see library Caret (Kuhn 2019).Another alternative preProcess=c(“center”, “scale”,“YeoJohnson”)\n“center”, “scale” centering scaling methods. “YeoJohnson” another transforming Predictors preprocess option.see previous output, “Preprocessing” indicates four variables removed, suggests improve model performance removing four variables. get remaining variables, use code:Regarding re-sampling: cross-validation name method. summary sample sizes always \\(n−1\\), case case 466. RMSE 466 average \\(n−1\\) test predictions. Finally, message “tuning parameter ‘intercept’ …”, “trControl” argument “train” function accepts arguments parameter tuning process, cover next chapter.Finally, message “Tuning parameter ‘intercept’ held constant value TRUE” argument changed tuning parameters, cover next chapter.","code":"#>      Id SalePrice MSSubClass MSZoning\n#> 64   64    163000         20        4\n#> 540 540    170000         80        4\n#> 200 200    155000         70        5\n#> 171 171    142000         20        4\n#> 41   41    250000         60        2\n#> 268 268    155000         60        4\n#>      Id SalePrice MSSubClass MSZoning\n#> 77   77    274900         20        4\n#> 480 480    186700         20        4\n#> 452 452    135000         50        4\n#> 580 580    240000         60        4\n#> 139 139    207000        120        5\n#> 162 162    245500        120        4\nfold1<- house_train[2:dim[1],] \nhead(fold1[,1:4])\n#>      Id SalePrice MSSubClass MSZoning\n#> 540 540    170000         80        4\n#> 200 200    155000         70        5\n#> 171 171    142000         20        4\n#> 41   41    250000         60        2\n#> 268 268    155000         60        4\n#> 566 566    175900        120        4\ntail(fold1[,1:4])\n#>      Id SalePrice MSSubClass MSZoning\n#> 77   77    274900         20        4\n#> 480 480    186700         20        4\n#> 452 452    135000         50        4\n#> 580 580    240000         60        4\n#> 139 139    207000        120        5\n#> 162 162    245500        120        4\nfold2<- house_train[c(1,3:dim[1]),] \nhead(fold2[,1:4])\n#>      Id SalePrice MSSubClass MSZoning\n#> 64   64    163000         20        4\n#> 200 200    155000         70        5\n#> 171 171    142000         20        4\n#> 41   41    250000         60        2\n#> 268 268    155000         60        4\n#> 566 566    175900        120        4\ntail(fold2[,1:4])\n#>      Id SalePrice MSSubClass MSZoning\n#> 77   77    274900         20        4\n#> 480 480    186700         20        4\n#> 452 452    135000         50        4\n#> 580 580    240000         60        4\n#> 139 139    207000        120        5\n#> 162 162    245500        120        4\nhouse_model<-lm(SalePrice~.,data=fold2)\nhouse_predict<-predict(house_model,fold1)\nsqrt(mean((fold1[,\"SalePrice\"]-house_predict)^2 ,na.rm = T))\n#> [1] 41984.83\nlibrary(caret)\n\nfitControl <- trainControl(method = \"LOOCV\")                   \ngbmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"lm\", \n                 trControl = fitControl)\ngbmFit1\n#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Leave-One-Out Cross-Validation \n#> Summary of sample sizes: 466, 466, 466, 466, 466, 466, ... \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   54486.35  0.6468026  31103.23\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\n\ngbmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"lm\", \n                 trControl = fitControl, preProcess= c(\"BoxCox\",\"nzv\"))\n\ngbmFit1\n#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> Pre-processing: Box-Cox transformation (36), remove (4) \n#> Resampling: Leave-One-Out Cross-Validation \n#> Summary of sample sizes: 466, 466, 466, 466, 466, 466, ... \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   50277.51  0.6939262  29454.77\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\nhead(gbmFit1$finalModel$xNames)\n#> [1] \"Id\"          \"MSSubClass\"  \"MSZoning\"    \"LotFrontage\" \"LotArea\"    \n#> [6] \"LotShape\""},{"path":"cross-validation.html","id":"k-fold-cross-validation-k-foldcv","chapter":"4 Cross Validation","heading":"4.0.2 k-fold Cross Validation (k-FoldCV)","text":"k-FoldCV similar LOOCV, except instead making \\(n\\) partitions, just requires \\(k\\). difference LOOCV usually, \\(k\\) less \\(n\\); example, \\(k=10\\). Another difference \\(k\\) partitions randomly selected. example, first partition called Fold1. takes database, example, house_train, randomly splits 80% training 20% validation data set. model estimated training, prediction validated validation set estimating metrics. process repeated \\(k\\) times.see , “train” function rule determine % training validation sets. following formula summarizes procedure RMSE.\\[k-FoldCV =\\frac{1}{k}\\ \\sum_{=1}^{k} RMSE_{} \\]use “train” function example LOOCV method. apply ten folds \\(k=10\\)case, k-FoldCV method “cv.” argument “number” indicates number folds \\(k\\)arguments “train” function similar LOOCV method.previous output, “Summary sample sizes” shows, fold, number observations training set, case 90% sample size, case 467. Resampling results, RMSE, Rsquared MAE average 10 folds. next plot, show 10 results.“train” function programmed different partitions number k-folds. example, k=5 partition 80. \\(k\\), % partition.Authors (James et al. 2017), consider k-FoldCV advantage less computationally intensive method like LOOCV. Also, exemplifies results k-Fol=10 LOOV similar regarding bias-variance trade-.“train” function allows repetition fold. example, want repeat fold two times, need add arguments, method = “repeatedcv”, number repeats, case, 2. result, end 20 results.algorithm “train” function developed, get different results use k=20 k=10 repeated 2 times.example, following plots, upper side, show different examples “repeatedcv”. bottom, show different examples similar, number, “cv” méthod. cases seed.results cv method concentrated bottom. Meanwhile, repeated-cv dispersion higher. result, RMSE average lower “cv”.valid question , better method? need evaluate model test data set (validation) answer . now, answer results tell us , depending resampling method, getting quite different results, implies probably need something else get stable results methods.example, can make cross-validation variable selection.Remember RMSE variables 5.3829898^{4}. get variables final model:","code":"\nk<-10\nfitControl <- trainControl(method = \"cv\",\n                           number = k)\nset.seed (26)\n\nlmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"lm\", \n                 trControl = fitControl)\nlmFit1\n#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE     Rsquared   MAE     \n#>   53829.9  0.7130432  32074.47\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE#> [1] \"420 467 90\"\ny<-as.data.frame(lmFit1$resample)[,\"RMSE\"] # this data frame has the RMSE results \np1<-lmFit1$results[,\"RMSE\"] # this object has the average RMSE \n\nplot(y, ylab=\"RMSE\", xlab=\"k-Folds\", pch = 16, main= paste(\"k-FoldsCV results for k=\",k))\nabline(p1,0,col=\"black\",lwd=2,lty = 2)\nlegend(x= \"topright\", legend = c(paste(\"average RMSE\",round(p1,0))),lty = 2,lwd=2,col=c(\"black\"))\ntext(x =3, y = p1*1.1, labels = round(p1,0),pos = 3)#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold, repeated 2 times) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   52572.29  0.7112406  31826.41\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\nk2<-10\nset.seed (26)\nfitControl3 <- trainControl(method = \"cv\",\n                           number = k2)\n\nstep <- train(SalePrice ~ ., data = house_train, \n                 method = \"lmStepAIC\", \n                 trControl = fitControl3, trace=F)\nstep\n#> Linear Regression with Stepwise Selection \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE     Rsquared   MAE     \n#>   53183.1  0.7218324  31441.74\nmo<-colnames(step$finalModel$model)[-1]\nmo\n#>  [1] \"MSSubClass\"    \"LotFrontage\"   \"LotArea\"       \"LotShape\"     \n#>  [5] \"HouseStyle\"    \"OverallQual\"   \"OverallCond\"   \"Exterior1st\"  \n#>  [9] \"MasVnrArea\"    \"ExterQual\"     \"Foundation\"    \"BsmtQual\"     \n#> [13] \"BsmtExposure\"  \"BsmtFinType1\"  \"BsmtFinSF1\"    \"BsmtUnfSF\"    \n#> [17] \"X1stFlrSF\"     \"X2ndFlrSF\"     \"BsmtFullBath\"  \"FullBath\"     \n#> [21] \"HalfBath\"      \"KitchenQual\"   \"TotRmsAbvGrd\"  \"Fireplaces\"   \n#> [25] \"FireplaceQu\"   \"GarageArea\"    \"SaleCondition\""},{"path":"cross-validation.html","id":"stochastic-gradient-boosting","chapter":"4 Cross Validation","heading":"4.0.3 Stochastic Gradient Boosting","text":"https://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdf","code":"\nset.seed (26)\nfitControl <- trainControl(method = \"cv\",\n                           number = 10)\n\ngbmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"gbm\", \n                 trControl = fitControl,\n                 ## This last option is actually one\n                 ## for gbm() that passes through\n                 verbose = FALSE)\ngbmFit1\n#> Stochastic Gradient Boosting \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results across tuning parameters:\n#> \n#>   interaction.depth  n.trees  RMSE      Rsquared   MAE     \n#>   1                   50      47239.17  0.7444321  30600.93\n#>   1                  100      46147.22  0.7537532  29225.96\n#>   1                  150      45741.85  0.7555015  28969.01\n#>   2                   50      45232.87  0.7570658  28665.82\n#>   2                  100      44866.17  0.7601488  27908.81\n#>   2                  150      45748.88  0.7554831  27734.49\n#>   3                   50      44032.44  0.7708265  27661.85\n#>   3                  100      43706.40  0.7775313  26762.67\n#>   3                  150      44620.73  0.7733739  27046.71\n#> \n#> Tuning parameter 'shrinkage' was held constant at a value of 0.1\n#> \n#> Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n#> RMSE was used to select the optimal model using the smallest value.\n#> The final values used for the model were n.trees = 100, interaction.depth =\n#>  3, shrinkage = 0.1 and n.minobsinnode = 10.\nmin(gbmFit1$results[,\"RMSE\"])\n#> [1] 43706.4"},{"path":"tuning-parameters-for-improving-performance.html","id":"tuning-parameters-for-improving-performance","chapter":"5 Tuning parameters for improving performance","heading":"5 Tuning parameters for improving performance","text":"","code":""},{"path":"tuning-parameters-for-improving-performance.html","id":"parameter","chapter":"5 Tuning parameters for improving performance","heading":"5.1 Parameter","text":"Hyperparameters model parameters specified training model – .e., parameters different model parameters – weights AI/ML model learns model training.many machine learning problems, finding best hyperparameters iterative potentially time-intensive process called “hyperparameter optimization.Hyperparameters directly impact performance trained machine-learning model. Choosing right hyperparameters can dramatically improve prediction accuracy. However, can challenging optimize often large combination possible hyperparameter values.Tuning machine learning model iterative process. Data scientists typically run numerous experiments train evaluate models, trying different features, different loss functions, different AI/ML models, adjusting model parameters hyperparameters. Examples steps involved tuning training machine learning model include feature engineering, loss function formulation, model testing selection, regularization, selection hyperparameters Krishnan (2022).Let’s assume now shortlist promising models. help now fine-tuned . Let’s look ways can .retrieved optimum values individual model parameters, can use grid search obtain combination hyperparameter (parameters also known hyperparameters) values model can give us highest accuracy.Grid Search evaluates possible combinations parameter values.Grid Search exhaustive uses brute force evaluate accurate values. Therefore computationally intensive task.","code":"\nhouse<-read.csv(\"https://raw.githubusercontent.com/abernal30/ml_book/main/housing.csv\")\nset.seed (26)\ndim<-dim(house)\ntrain_sample<-sample(dim[1],dim[1]*.8)\nhouse_train <- house[train_sample, ]\nhouse_test  <- house[-train_sample, ]\nlibrary(caret)\nset.seed (26)\nfitControl <- trainControl(method = \"cv\",\n                           number = 10)\n\ngbmFit <- train(SalePrice ~ ., data = house_train, \n                 method = \"gbm\", \n                 trControl = fitControl, \n                 verbose = FALSE)\ngbmFit\n#> Stochastic Gradient Boosting \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results across tuning parameters:\n#> \n#>   interaction.depth  n.trees  RMSE      Rsquared   MAE     \n#>   1                   50      47239.17  0.7444321  30600.93\n#>   1                  100      46147.22  0.7537532  29225.96\n#>   1                  150      45741.85  0.7555015  28969.01\n#>   2                   50      45232.87  0.7570658  28665.82\n#>   2                  100      44866.17  0.7601488  27908.81\n#>   2                  150      45748.88  0.7554831  27734.49\n#>   3                   50      44032.44  0.7708265  27661.85\n#>   3                  100      43706.40  0.7775313  26762.67\n#>   3                  150      44620.73  0.7733739  27046.71\n#> \n#> Tuning parameter 'shrinkage' was held constant at a value of 0.1\n#> \n#> Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n#> RMSE was used to select the optimal model using the smallest value.\n#> The final values used for the model were n.trees = 100, interaction.depth =\n#>  3, shrinkage = 0.1 and n.minobsinnode = 10.\nmin(gbmFit$results[,\"RMSE\"])\n#> [1] 43706.4\nseq(0.08,0.2,.01)\n#>  [1] 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.20\nset.seed (26)\nfitControl <- trainControl(method = \"cv\",\n                           number = 10)\n\ngbmGrid <-  expand.grid(interaction.depth = 3, \n                        n.trees = 100, \n                        shrinkage = seq(0.08,0.2,.01),\n                        n.minobsinnode = c(10,20,30))\n                        \nnrow(gbmGrid)\n#> [1] 39\n\n\ngbmFit2 <- train(SalePrice ~ ., data = house_train, \n                 method = \"gbm\", \n                 trControl = fitControl, \n                 verbose = FALSE, \n                 ## Now specify the exact models \n                 ## to evaluate:\n                 tuneGrid = gbmGrid)\ngbmFit2\n#> Stochastic Gradient Boosting \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results across tuning parameters:\n#> \n#>   shrinkage  n.minobsinnode  RMSE      Rsquared   MAE     \n#>   0.08       10              43689.38  0.7757923  26414.49\n#>   0.08       20              43439.41  0.7762678  26253.74\n#>   0.08       30              43718.02  0.7740018  27043.45\n#>   0.09       10              44482.73  0.7657377  26932.51\n#>   0.09       20              44471.18  0.7694100  26930.13\n#>   0.09       30              42765.74  0.7850388  26107.17\n#>   0.10       10              45797.81  0.7565011  27752.53\n#>   0.10       20              43305.74  0.7752004  26133.99\n#>   0.10       30              44014.90  0.7733803  27155.20\n#>   0.11       10              44489.95  0.7656922  26866.05\n#>   0.11       20              44102.22  0.7772802  26763.98\n#>   0.11       30              43173.50  0.7852119  26475.20\n#>   0.12       10              45685.92  0.7560192  27278.29\n#>   0.12       20              43837.29  0.7733656  26780.05\n#>   0.12       30              43632.73  0.7731039  27097.95\n#>   0.13       10              45015.04  0.7633598  27339.32\n#>   0.13       20              44378.70  0.7733293  26922.59\n#>   0.13       30              43729.28  0.7738287  26848.09\n#>   0.14       10              45847.55  0.7616066  26985.59\n#>   0.14       20              43476.83  0.7753577  27154.57\n#>   0.14       30              44204.43  0.7733527  27236.38\n#>   0.15       10              46597.58  0.7505296  27959.85\n#>   0.15       20              45481.20  0.7606624  27931.86\n#>   0.15       30              44495.46  0.7689698  27904.48\n#>   0.16       10              46312.23  0.7551459  28093.47\n#>   0.16       20              44609.52  0.7720711  26788.57\n#>   0.16       30              44293.15  0.7709916  27231.55\n#>   0.17       10              47092.71  0.7503482  27909.55\n#>   0.17       20              45266.73  0.7597926  27838.44\n#>   0.17       30              44495.99  0.7682215  27612.17\n#>   0.18       10              46187.08  0.7560767  27455.96\n#>   0.18       20              45563.69  0.7615617  28022.82\n#>   0.18       30              44019.18  0.7697064  28476.80\n#>   0.19       10              49851.20  0.7284168  29410.44\n#>   0.19       20              46902.27  0.7505154  28841.09\n#>   0.19       30              44854.58  0.7651957  28353.89\n#>   0.20       10              48231.76  0.7329092  29188.07\n#>   0.20       20              44947.66  0.7651168  27865.51\n#>   0.20       30              44618.00  0.7586902  27987.05\n#> \n#> Tuning parameter 'n.trees' was held constant at a value of 100\n#> Tuning\n#>  parameter 'interaction.depth' was held constant at a value of 3\n#> RMSE was used to select the optimal model using the smallest value.\n#> The final values used for the model were n.trees = 100, interaction.depth =\n#>  3, shrinkage = 0.09 and n.minobsinnode = 30.\ntrellis.par.set(caretTheme())\nplot(gbmFit2) \ngbmFit2$bestTune\n#>   n.trees interaction.depth shrinkage n.minobsinnode\n#> 6     100                 3      0.09             30\nset.seed (26)\nfitControl <- trainControl(method = \"cv\",\n                           number = 10)\n\ngbmGrid <-  expand.grid(interaction.depth = 3, \n                        n.trees = 100, \n                        shrinkage = 0.09,\n                        n.minobsinnode = 30)\n                        \n\ngbmFit1 <- train(SalePrice ~ ., data = house_train, \n                 method = \"gbm\", \n                 trControl = fitControl,\n                 verbose = FALSE,tuneGrid = gbmGrid)\ngbmFit1\n#> Stochastic Gradient Boosting \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   43538.88  0.7755887  27051.03\n#> \n#> Tuning parameter 'n.trees' was held constant at a value of 100\n#> Tuning\n#> \n#> Tuning parameter 'shrinkage' was held constant at a value of 0.09\n#> \n#> Tuning parameter 'n.minobsinnode' was held constant at a value of 30"},{"path":"tuning-parameters-for-improving-performance.html","id":"analyze-the-best-models-and-their-errors","chapter":"5 Tuning parameters for improving performance","heading":"5.2 Analyze the Best Models and Their Errors","text":"","code":"\nset.seed (26)\n\nlmFit <- train(SalePrice ~ ., data = house_train, \n                 method = \"lm\", \n                 trControl = fitControl)\nlmFit\n#> Linear Regression \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE     Rsquared   MAE     \n#>   53829.9  0.7130432  32074.47\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\nk2<-10\nset.seed (26)\nfitControl3 <- trainControl(method = \"cv\",\n                           number = k2)\n\nstep <- train(SalePrice ~ ., data = house_train, \n                 method = \"lmStepAIC\", \n                 trControl = fitControl3, trace=F)\nstep\n#> Linear Regression with Stepwise Selection \n#> \n#> 467 samples\n#>  51 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (10 fold) \n#> Summary of sample sizes: 420, 421, 421, 419, 420, 421, ... \n#> Resampling results:\n#> \n#>   RMSE     Rsquared   MAE     \n#>   53183.1  0.7218324  31441.74\nresamps <- resamples(list(GBM = gbmFit1,\n                          lm= lmFit,\n                          step = step))\nsummary(resamps)\n#> \n#> Call:\n#> summary.resamples(object = resamps)\n#> \n#> Models: GBM, lm, step \n#> Number of resamples: 10 \n#> \n#> MAE \n#>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\n#> GBM  16916.01 22683.84 26802.82 27051.03 33250.31 34700.58    0\n#> lm   24099.97 27569.17 32581.94 32074.47 33796.23 46936.58    0\n#> step 23457.60 27519.35 31131.39 31441.74 33246.95 47069.12    0\n#> \n#> RMSE \n#>          Min.  1st Qu.   Median     Mean  3rd Qu.      Max. NA's\n#> GBM  21042.28 29863.83 42580.60 43538.88 53434.67  68983.63    0\n#> lm   29902.95 38797.25 46407.32 53829.90 50676.37 142708.97    0\n#> step 29473.14 38261.54 45661.85 53183.10 49510.85 142365.64    0\n#> \n#> Rsquared \n#>           Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\n#> GBM  0.4466954 0.7499098 0.7749271 0.7755887 0.8692610 0.9222225    0\n#> lm   0.1182236 0.7380041 0.7705471 0.7130432 0.7989847 0.8440776    0\n#> step 0.1201389 0.7623466 0.7765474 0.7218324 0.7931811 0.8461111    0\ntheme1 <- trellis.par.get()\ntheme1$plot.symbol$col = rgb(.2, .2, .2, .4)\ntheme1$plot.symbol$pch = 16\ntheme1$plot.line$col = rgb(1, 0, 0, .7)\ntheme1$plot.line$lwd <- 2\ntrellis.par.set(theme1)\nbwplot(resamps, layout = c(3, 1))"}]
