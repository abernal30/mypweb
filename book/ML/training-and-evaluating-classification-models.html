<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>3 Training and evaluating classification models | Machine learning introductory guide</title>
<meta name="author" content="L. Arturo Bernal">
<meta name="description" content="The linear regression, such as OLS, the dependent variable is continuous, such as the SalePrice variable, in the sense that the house price could be between $62,383 and $755000. However, there are...">
<meta name="generator" content="bookdown 0.33 with bs4_book()">
<meta property="og:title" content="3 Training and evaluating classification models | Machine learning introductory guide">
<meta property="og:type" content="book">
<meta property="og:url" content="https://www.arturo-bernal.com/book/training-and-evaluating-classification-models.html">
<meta property="og:image" content="https://www.arturo-bernal.com/book/images/Picture1.jpg">
<meta property="og:description" content="The linear regression, such as OLS, the dependent variable is continuous, such as the SalePrice variable, in the sense that the house price could be between $62,383 and $755000. However, there are...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="3 Training and evaluating classification models | Machine learning introductory guide">
<meta name="twitter:description" content="The linear regression, such as OLS, the dependent variable is continuous, such as the SalePrice variable, in the sense that the house price could be between $62,383 and $755000. However, there are...">
<meta name="twitter:image" content="https://www.arturo-bernal.com/book/images/Picture1.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Machine learning introductory guide</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Machine learning introductory guide</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="ml-in-the-bussines-lascape-and-data-collection.html"><span class="header-section-number">1</span> ML in the bussines lascape and data collection</a></li>
<li><a class="" href="training-and-evaluating-regression-models.html"><span class="header-section-number">2</span> Training and evaluating regression models</a></li>
<li><a class="active" href="training-and-evaluating-classification-models.html"><span class="header-section-number">3</span> Training and evaluating classification models</a></li>
<li><a class="" href="cross-validation.html"><span class="header-section-number">4</span> Cross Validation</a></li>
<li><a class="" href="improving-performance.html"><span class="header-section-number">5</span> Improving Performance</a></li>
<li><a class="" href="clustering.html"><span class="header-section-number">6</span> Clustering</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="training-and-evaluating-classification-models" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Training and evaluating classification models<a class="anchor" aria-label="anchor" href="#training-and-evaluating-classification-models"><i class="fas fa-link"></i></a>
</h1>
<p>The linear regression, such as OLS, the dependent variable is continuous, such as the SalePrice variable, in the sense that the house price could be between $62,383 and $755000. However, there are other situations where the dependent variable has two categories: women or men, or in finance, a signal to buy or sell, etc. In that case, we call those variables categorical. One of the most popular classification models is logistic regression and linear discriminant analysis.</p>
<div id="logit-model" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Logit model<a class="anchor" aria-label="anchor" href="#logit-model"><i class="fas fa-link"></i></a>
</h2>
<p>For this section we will work on the credit data set. Remember that we describe the credit data set in chapter one, where we define the model:</p>
<p><span class="math display">\[ Default=\beta_{0}+\beta_{1}\ x_{1} + \beta_{2}\ x_{2}+ ....+\beta_{n} x_{n}+\epsilon \]</span></p>
<p>The algorithm or procedures that runs the binary response models, such as logit, first transforms the categories, in this case “Charged Off” or “Fully Paid”, into numerical values, zero and one. It assigns the probability that <span class="math inline">\(y\)</span> takes the value of one <span class="math inline">\(P(y=1)= \pi\)</span> and that takes the value of zero <span class="math inline">\(P(y=0)= 1-\pi\)</span>. The statistical analysis aims to investigate the relationship between the probability <span class="math inline">\(\pi(X)\)</span> and the independent variables <span class="math inline">\(X=x_{1}, x_{2}...x_{n}\)</span> . It is convenient to construct a model capable of describing the effect on <span class="math inline">\(pi\)</span> of changes in <span class="math inline">\(X=x_{1}, x_{2}...x_{n}\)</span>, in the form of a function <span class="math inline">\(g(\pi)\)</span> <span class="citation">(<a href="clustering.html#ref-glm" role="doc-biblioref">McCullagh and FRS 1989</a>)</span>.</p>
<p>For the logic model the function is <span class="math inline">\(g(\pi)=\log{(\pi/(1-\pi))}\)</span></p>
<p>Then</p>
<p><span class="math display">\[g(\pi)=\log{(\pi/(1-\pi))}=beta_{0}+\beta_{1}x_{1}+,..,+\beta_{n}x_{n} \]</span></p>
<p>Taking the exponential of both sides, we get:</p>
<p><span class="math display">\[\pi/(1-\pi)= \exp{(beta_{0}+\beta_{1}x_{1}+,..,+\beta_{n}x_{n})}\]</span></p>
<p>To get a probability, we need a transformation like this:</p>
<p><span class="math display">\[\pi= \frac{\exp{(beta_{0}+\beta_{1}x_{1}+,..,+\beta_{n}x_{n})}}{1+\exp{(beta_{0}+\beta_{1}x_{1}+,..,+\beta_{n}x_{n})}}\]</span></p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">credit</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"https://raw.githubusercontent.com/abernal30/ml_book/main/credit.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">c2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">credit</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">==</span><span class="st">"Charged Off"</span> ,<span class="st">"No_default"</span>,<span class="st">"default"</span><span class="op">)</span> </span>
<span><span class="va">credit</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">&lt;-</span><span class="va">c2</span></span></code></pre></div>
<p>The variable default is a categorical variable becasue it takes the folowing two values:</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">credit</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;    default No_default </span></span>
<span><span class="co">#&gt;        728        145</span></span></code></pre></div>
<p>The function to run a logistic model in R doesn´t accept character values, only numeric or factor. We transform that variable into a “factor.”</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">credit</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">credit</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<p>We split into training and test data sets, as we did in the housing example.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span> <span class="op">(</span><span class="fl">43</span><span class="op">)</span></span>
<span><span class="va">dim</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">credit</span><span class="op">)</span></span>
<span><span class="va">train_sample</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">dim</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="va">dim</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">*</span><span class="fl">.8</span><span class="op">)</span></span>
<span><span class="va">credit_train</span> <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">[</span><span class="va">train_sample</span>, <span class="op">]</span></span>
<span><span class="va">credit_test</span>  <span class="op">&lt;-</span> <span class="va">credit</span><span class="op">[</span><span class="op">-</span><span class="va">train_sample</span>, <span class="op">]</span></span></code></pre></div>
<p>The function to run the logistic model is “glm”.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">credit_model</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Default</span> <span class="op">~</span> <span class="va">.</span>,data<span class="op">=</span> <span class="va">credit_train</span> ,family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">credit_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = Default ~ ., family = binomial(), data = credit_train)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Deviance Residuals: </span></span>
<span><span class="co">#&gt;        Min          1Q      Median          3Q         Max  </span></span>
<span><span class="co">#&gt; -8.169e-05  -2.100e-08  -2.100e-08  -2.100e-08   6.626e-05  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                         Estimate Std. Error z value Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept)            2.897e+02  2.242e+06   0.000    1.000</span></span>
<span><span class="co">#&gt; term                   8.976e+01  6.971e+04   0.001    0.999</span></span>
<span><span class="co">#&gt; installment            1.223e-02  2.300e+02   0.000    1.000</span></span>
<span><span class="co">#&gt; grade                 -1.242e+01  3.695e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; emp_title             -1.979e-02  2.551e+02   0.000    1.000</span></span>
<span><span class="co">#&gt; emp_length            -8.469e-01  2.485e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; home_ownership        -9.860e+00  2.016e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; annual_inc             9.569e-05  3.390e+00   0.000    1.000</span></span>
<span><span class="co">#&gt; verification_status   -4.514e+00  3.047e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; purpose                4.467e+00  2.071e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; title                 -1.085e+00  2.569e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; zip_code               2.512e-02  8.173e+02   0.000    1.000</span></span>
<span><span class="co">#&gt; addr_state            -2.288e-01  3.921e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; dti                    1.426e+00  8.380e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; delinq_2yrs            3.129e+00  2.009e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; earliest_cr_line      -3.055e-02  3.341e+02   0.000    1.000</span></span>
<span><span class="co">#&gt; fico_range_high       -5.329e-02  3.646e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; inq_last_6mths         2.822e+00  4.734e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; pub_rec                6.300e-01  1.310e+05   0.000    1.000</span></span>
<span><span class="co">#&gt; revol_bal             -1.205e-03  4.719e+00   0.000    1.000</span></span>
<span><span class="co">#&gt; revol_util            -8.785e-02  8.591e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; total_acc              1.151e+01  5.819e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; total_rec_int         -4.211e-03  1.308e+01   0.000    1.000</span></span>
<span><span class="co">#&gt; recoveries             1.110e-01  2.909e+02   0.000    1.000</span></span>
<span><span class="co">#&gt; last_pymnt_d           7.074e-01  2.275e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; last_pymnt_amnt       -6.044e-03  1.338e+01   0.000    1.000</span></span>
<span><span class="co">#&gt; last_credit_pull_d     7.841e-01  4.390e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; last_fico_range_high  -6.891e-01  4.561e+02  -0.002    0.999</span></span>
<span><span class="co">#&gt; last_fico_range_low    4.923e-03  2.849e+02   0.000    1.000</span></span>
<span><span class="co">#&gt; tot_coll_amt           1.224e-03  2.466e+00   0.000    1.000</span></span>
<span><span class="co">#&gt; tot_cur_bal            2.562e-05  3.973e-01   0.000    1.000</span></span>
<span><span class="co">#&gt; open_acc_6m            1.177e+01  6.376e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; open_act_il            6.880e+00  3.555e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; open_il_12m           -9.614e+00  1.184e+05   0.000    1.000</span></span>
<span><span class="co">#&gt; open_il_24m            6.398e+00  4.427e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; mths_since_rcnt_il     3.689e-01  1.095e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; total_bal_il           1.374e-04  2.479e+00   0.000    1.000</span></span>
<span><span class="co">#&gt; il_util                3.744e-01  3.611e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; open_rv_12m           -1.147e+01  7.695e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; open_rv_24m            1.252e+01  4.016e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; max_bal_bc             5.577e-04  1.057e+01   0.000    1.000</span></span>
<span><span class="co">#&gt; all_util               3.889e-01  4.471e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; total_rev_hi_lim       3.081e-04  3.123e+00   0.000    1.000</span></span>
<span><span class="co">#&gt; inq_fi                -1.414e-02  1.968e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; total_cu_tl            3.728e+00  9.716e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; inq_last_12m           8.275e-01  3.789e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; acc_open_past_24mths  -1.146e+01  4.153e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; avg_cur_bal           -1.149e-04  1.849e+00   0.000    1.000</span></span>
<span><span class="co">#&gt; bc_open_to_buy        -5.062e-04  1.554e+01   0.000    1.000</span></span>
<span><span class="co">#&gt; bc_util               -5.402e-02  1.391e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; mo_sin_old_il_acct    -5.365e-02  4.233e+02   0.000    1.000</span></span>
<span><span class="co">#&gt; mo_sin_old_rev_tl_op   6.397e-03  8.812e+02   0.000    1.000</span></span>
<span><span class="co">#&gt; mo_sin_rcnt_rev_tl_op  2.013e-01  3.696e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; mo_sin_rcnt_tl         3.205e-02  2.013e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; mort_acc              -1.140e+01  7.505e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; mths_since_recent_bc   8.572e-03  3.642e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; mths_since_recent_inq -1.035e+00  4.052e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; num_accts_ever_120_pd -4.406e+00  2.104e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_actv_bc_tl         2.636e+00  7.399e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_bc_sats           -4.123e+00  8.698e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_bc_tl              3.302e+00  4.186e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_il_tl             -1.397e+01  6.543e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_op_rev_tl          6.232e+00  6.346e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_rev_accts         -1.211e+01  4.019e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_rev_tl_bal_gt_0    8.575e-01  6.424e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_sats              -5.882e+00  3.720e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; num_tl_op_past_12m     5.371e+00  9.234e+04   0.000    1.000</span></span>
<span><span class="co">#&gt; pct_tl_nvr_dlq         1.125e-01  3.589e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; percent_bc_gt_75      -4.595e-02  3.134e+03   0.000    1.000</span></span>
<span><span class="co">#&gt; pub_rec_bankruptcies  -7.226e+00  1.451e+05   0.000    1.000</span></span>
<span><span class="co">#&gt; total_bc_limit         1.527e-04  1.590e+01   0.000    1.000</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 6.3112e+02  on 697  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 8.7225e-08  on 627  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 142</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 25</span></span></code></pre></div>
<p>In a paragraph below, we explain the warning in red: “glm.fit: fitted probabilities numerically 0 or 1 occurred”.</p>
<p>We use the predict function to make the prediction.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">credit_predict</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">credit_model</span>, newdata<span class="op">=</span><span class="va">credit_test</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">credit_predict</span><span class="op">)</span></span>
<span><span class="co">#&gt;           15           19           24           26           32           34 </span></span>
<span><span class="co">#&gt; 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16</span></span></code></pre></div>
<p>The parameters we estimate with the “glm” function, adding the family=binomial() and the type= “response”, are the parameters of the equation.</p>
<p><span class="math display">\[\pi= \frac{\exp{(beta_{0}+\beta_{1}x_{1}+,..,+\beta_{n}x_{n})}}{1+\exp{(beta_{0}+\beta_{1}x_{1}+,..,+\beta_{n}x_{n})}}\]</span></p>
<p>Consequently, when we make the prediction, we get a probability.</p>
<p>However, the expected prediction should be either Charged Off or Fully Paid, and our prediction has numbers between cero and one.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">credit_predict</span><span class="op">)</span></span>
<span><span class="co">#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span><span class="co">#&gt;  0.0000  0.0000  0.0000  0.1754  0.0000  1.0000</span></span></code></pre></div>
<p>Finally, we must still resolve whether the prediction should be Charged Off or Fully Paid. We will transform with the following code.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">credit</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;    default No_default </span></span>
<span><span class="co">#&gt;        728        145</span></span></code></pre></div>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">credit_predict_char</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">credit_predict</span><span class="op">&gt;</span><span class="fl">.5</span>,<span class="st">"No_default"</span>,<span class="st">"default"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">credit_predict_char</span><span class="op">)</span></span>
<span><span class="co">#&gt; credit_predict_char</span></span>
<span><span class="co">#&gt;    default No_default </span></span>
<span><span class="co">#&gt;        144         31</span></span></code></pre></div>
<p>When we transform our forecast in that category, we establish a threshold of 0.5; if our prediction is higher than 0.5, we convert it into “Fully Paid” and otherwise “Charged Off.” It is “ok” if you wonder why our threshold is 0.5. After estimating the prediction accuracy of our model, we could change this threshold to improve the prediction performance.</p>
<p>Is suggest verifying and comparing the resulting structure with the original data structure. In this case, “Charged Off” is 82 % of the observations (144 / (144+31)).</p>
<p>In the complete data set (train + test), that percentage is 83%, which is a consistent result. An inconsistent result is 87% in our prediction.</p>
</div>
<div id="performance-measure-in-clasification" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Performance Measure in clasification<a class="anchor" aria-label="anchor" href="#performance-measure-in-clasification"><i class="fas fa-link"></i></a>
</h2>
<p>Now we measure the prediction accuracy, applying the confusion Matrix:</p>
<p>Confusion matrix</p>
<p>It is a table that categorizes predictions according to whether they match the actual value. One of the table’s dimensions indicates the possible categories of predicted values, while the other shows the same for actual values. Although we have only seen 2 x 2 confusion matrices so far, a matrix can be created for models that predict any number of class values. The following figure shows a generic confusion matrix.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="images/cm3.jpg" alt="Confusion matrix." width="40%"><p class="caption">
Figure 3.1: Confusion matrix.
</p>
</div>
<p>Where True Positive (TP): Correctly classified as the class of interest. True Negative (TN) is Correctly classified as not the class of interest. False Positive (FP) is Incorrectly classified as the class of interest. False Negative (FN): Incorrectly classified as not the class of interest.</p>
<p>We use the confusionMatrix function from the library “caret” for the credit analysis example. The first argument is our prediction, and the second argument is the reference, in this case, the variable “Default” in the credit_test data set; both variables must be factors, which is only true for the variable inside credit_test.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/topepo/caret/">"caret"</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Defaultf</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">credit_predict_char</span>,levels<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"No_default"</span>,<span class="st">"default"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">Defaultf</span><span class="op">)</span></span>
<span><span class="co">#&gt; Defaultf</span></span>
<span><span class="co">#&gt; No_default    default </span></span>
<span><span class="co">#&gt;         31        144</span></span></code></pre></div>
<p>Again I review the consistency of the data structure. In this case, it is consistent. It is important to keep the consistency of the levels; in this case, we write first “Charged Off” because the reference data set starts with that label first:</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">credit_test</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] default default default default default default</span></span>
<span><span class="co">#&gt; Levels: default No_default</span></span></code></pre></div>
<p>Finally, we apply the function. In this case, we are assuming that the positive class, the class of interest, is “Charged Off”:</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">confu</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">Defaultf</span>,<span class="va">credit_test</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span>,positive<span class="op">=</span><span class="st">"default"</span><span class="op">)</span></span>
<span><span class="va">confu</span></span>
<span><span class="co">#&gt; Confusion Matrix and Statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             Reference</span></span>
<span><span class="co">#&gt; Prediction   default No_default</span></span>
<span><span class="co">#&gt;   default        141          3</span></span>
<span><span class="co">#&gt;   No_default       6         25</span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                Accuracy : 0.9486          </span></span>
<span><span class="co">#&gt;                  95% CI : (0.9046, 0.9762)</span></span>
<span><span class="co">#&gt;     No Information Rate : 0.84            </span></span>
<span><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 8.743e-06       </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;                   Kappa : 0.8166          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;  Mcnemar's Test P-Value : 0.505           </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;             Sensitivity : 0.9592          </span></span>
<span><span class="co">#&gt;             Specificity : 0.8929          </span></span>
<span><span class="co">#&gt;          Pos Pred Value : 0.9792          </span></span>
<span><span class="co">#&gt;          Neg Pred Value : 0.8065          </span></span>
<span><span class="co">#&gt;              Prevalence : 0.8400          </span></span>
<span><span class="co">#&gt;          Detection Rate : 0.8057          </span></span>
<span><span class="co">#&gt;    Detection Prevalence : 0.8229          </span></span>
<span><span class="co">#&gt;       Balanced Accuracy : 0.9260          </span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt;        'Positive' Class : default         </span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>There are several indicators in the output, which could be “confusing.” We analyze it in parts. We start with the table:</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">confu</span><span class="op">$</span><span class="va">table</span></span>
<span><span class="co">#&gt;             Reference</span></span>
<span><span class="co">#&gt; Prediction   default No_default</span></span>
<span><span class="co">#&gt;   default        141          3</span></span>
<span><span class="co">#&gt;   No_default       6         25</span></span></code></pre></div>
<p>The matrix’s left-superior/right-inferior numbers are the true positive/true negative or the number of observations where our prediction equals the reference. The left-inferior/ right-superior numbers in the matrix are the true positive/ true negative or the number of observations where our prediction is “Not” equal to the reference.</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">confu</span><span class="op">$</span><span class="va">table</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">+</span><span class="va">confu</span><span class="op">$</span><span class="va">table</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="co">#&gt; [1] 147</span></span></code></pre></div>
<p>From those numbers we get the following metrics.</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">confu</span><span class="op">$</span><span class="va">overall</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="co">#&gt;  Accuracy </span></span>
<span><span class="co">#&gt; 0.9485714</span></span></code></pre></div>
<p>The accuracy is:</p>
<p><span class="math display">\[ accuracy =\frac{TP+TN}{TP+TN+FP+FN}\]</span></p>
<div id="the-accuracy" class="section level3" number="3.2.1">
<h3>
<span class="header-section-number">3.2.1</span> The <strong>accuracy</strong>:<a class="anchor" aria-label="anchor" href="#the-accuracy"><i class="fas fa-link"></i></a>
</h3>
<p>Is the proportion of true positives and true negatives, divided by the total number of predictions. At the beginning it could be tempting to tuning a model to increase the Accuracy, increase the true predictions of default or no default, which would be fin. However, the machine larning clasficiation theory suggest considering other measures.</p>
<p>In therms of the confusion matrix, it would be the sum of the green squares of the toal number of observations.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-20"></span>
<img src="images/cm4.jpg" alt="Confusion matrix." width="40%"><p class="caption">
Figure 3.2: Confusion matrix.
</p>
</div>
<p>To explain why we may need other measures, in our example, imagine a scenario where the company is concern of the default rates, because it has been increasing. A first thought to correct it, is tuning a model that predict almost always that a new customer is not going to pay, “Charge of”. As consequence, the model would be discriminating bad new customers, that probably would´t pay the loan, but also good ones. The problem with that for a bank, is that ot may end with no business, a bank that does´t make loans, winch could has a negative effect on profits.</p>
<p>On the contrary, tuning a model that predict almost always that a new customer is going to pay, could cause granting loans to some customers that probably sould not pay, which also would have a negative on the profits to.</p>
</div>
<div id="the-sensitivity-or-recall-also-called-the-true-positive-rate" class="section level3" number="3.2.2">
<h3>
<span class="header-section-number">3.2.2</span> The <strong>sensitivity or Recall (also called the true positive rate)</strong><a class="anchor" aria-label="anchor" href="#the-sensitivity-or-recall-also-called-the-true-positive-rate"><i class="fas fa-link"></i></a>
</h3>
<p>Measures how well we are predicting the variable of interest regarding the total positive observations in the reference:</p>
<p><span class="math display">\[ Sensitivity\ or\ Recall =\frac{TP}{TP+FN}\]</span></p>
In therms of the confusion matrix, it would be the blue vector:
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-21"></span>
<img src="images/cm7.jpg" alt="Confusion matrix." width="40%"><p class="caption">
Figure 3.3: Confusion matrix.
</p>
</div>
<p>The importance of this measure is relative to what is important for who is doing the analysis. In our example, imagine a scenario where the company is concern of the default rates, because it has been increasing. Mabe a first tougth to correct it, is a restrictive model to</p>
<p>In that case, it may be more problematic predicting that someone is going to pay a credit ( “Fully Paid”) when in reality is not going to pay (“Charged Off”) than predicting someone is not going to pay a credit (“Charged Off”) when in reality she will pay it ( “Fully Paid”). in that case, the sensitivity would be a good indicator.</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">confu</span><span class="op">$</span><span class="va">byClass</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="co">#&gt; Sensitivity </span></span>
<span><span class="co">#&gt;   0.9591837</span></span></code></pre></div>
<p>A sensitivity of 95.92% may not be high as expected, for example, if we follow the 95% or higher rule. On the other hand, in a scenario where the company has a low default rate and is expecting to expand the business. It could be more problematic to predict that someone is not going to pay a credit (“Charged Off”) when in reality, she will pay it ( “Fully Paid”).</p>
<p>In that case, the class of interest may be “Fully Paid.”</p>
<p>Sensitivity by itself it´s a good measure, but wee need to complement it with other ones, because there could be some issues, even when it is very high, such as 100%, and it does´n necessarily mean it is a good. For example suppose the unlikely case that all our predictions are positive ones, or that every person is not going to pay the loan, let´s call it noisy model:</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pre_pos</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"default"</span>,<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">Defaultf</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">pre_pos_f</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">pre_pos</span>,levels<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"default"</span>,<span class="st">"No_default"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">noisy</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/confusionMatrix.html">confusionMatrix</a></span><span class="op">(</span><span class="va">pre_pos_f</span>,<span class="va">credit_test</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span>,positive<span class="op">=</span><span class="st">"default"</span><span class="op">)</span></span>
<span><span class="va">noisy</span></span>
<span><span class="co">#&gt; Confusion Matrix and Statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             Reference</span></span>
<span><span class="co">#&gt; Prediction   default No_default</span></span>
<span><span class="co">#&gt;   default        147         28</span></span>
<span><span class="co">#&gt;   No_default       0          0</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt;                Accuracy : 0.84           </span></span>
<span><span class="co">#&gt;                  95% CI : (0.7771, 0.891)</span></span>
<span><span class="co">#&gt;     No Information Rate : 0.84           </span></span>
<span><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 0.5502         </span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt;                   Kappa : 0              </span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt;  Mcnemar's Test P-Value : 3.352e-07      </span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt;             Sensitivity : 1.00           </span></span>
<span><span class="co">#&gt;             Specificity : 0.00           </span></span>
<span><span class="co">#&gt;          Pos Pred Value : 0.84           </span></span>
<span><span class="co">#&gt;          Neg Pred Value :  NaN           </span></span>
<span><span class="co">#&gt;              Prevalence : 0.84           </span></span>
<span><span class="co">#&gt;          Detection Rate : 0.84           </span></span>
<span><span class="co">#&gt;    Detection Prevalence : 1.00           </span></span>
<span><span class="co">#&gt;       Balanced Accuracy : 0.50           </span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt;        'Positive' Class : default        </span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>We would have a sensitivity of 100%, but something is wrong, among other things by rejecting any credit application, whic is the problem of ending with no business and negative effect on profits. To prevent this, or something similar, there other metrics as the Precision.</p>
</div>
<div id="precision-or-positive-predicted-values" class="section level3" number="3.2.3">
<h3>
<span class="header-section-number">3.2.3</span> <em>Precision or Positive Predicted Values</em><a class="anchor" aria-label="anchor" href="#precision-or-positive-predicted-values"><i class="fas fa-link"></i></a>
</h3>
<p>Measures how well we are predicting the variable of interest regarding the total positive observations in the prediction:</p>
<p><span class="math display">\[ Precision =\frac{TP}{TP+FP}\]</span></p>
<p>Is the proportion of true positive predictions of the positive predictions.The Sensitivity and Precision are similar because both measure the proportion of true positives, but, the former of the total positive values in the reference and the latter of the total positive values of the prediction.</p>
<p>In our example, the precision would penalize a model like the noisy one, which would be 0.84. It is intended to indicate how interesting and relevant a model’s results are, or whether the predictions are diluted by meaningless noise <span class="citation">(<a href="clustering.html#ref-Lantz" role="doc-biblioref">Lantz 2019</a>)</span>.</p>
<p>The Precision in the original model is:</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pre</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">confu</span><span class="op">$</span><span class="va">byClass</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>,<span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">pre</span></span>
<span><span class="co">#&gt; Pos Pred Value </span></span>
<span><span class="co">#&gt;         0.9792</span></span></code></pre></div>
<pre><code>#&gt; [1] 0.9792</code></pre>
<p>A higher Precision model is not also something good by itself. For example, we could have a model that predicted few positive predictions, like 2, and by chance those two are well classified, then TP is 2, FP is zero, and Precision of 100%. But what if the reference, has 28 positive observations in total, like in our example, that would mean that we are very short in the number of positive observations we are predicting. In term of the bank-business, that would imply that the model will not be able to identify a large portion of customers who will default a credit, which is the other side of the problem that would have a negative on the profits.</p>
<p>Then we would need to have a balance between sensitivity (Recall) and precision.
A very good classification model may achieve 100% precision and 100% sensitivity, but in reality that is very unlikely to happens. Models usually trade off between precision and recall; typically the higher the precision, the lower the recall, and vicevers. In our noisy model precision is 0.84% and sensitivity 95.92% <span class="citation">(<a href="clustering.html#ref-c3" role="doc-biblioref">Krishnan 2020</a>)</span>.</p>
</div>
<div id="the-f1-score" class="section level3" number="3.2.4">
<h3>
<span class="header-section-number">3.2.4</span> The <strong>F1 Score</strong><a class="anchor" aria-label="anchor" href="#the-f1-score"><i class="fas fa-link"></i></a>
</h3>
<p>This metric measure how balanced is the relationship between sensitivity (Recall) and precision. The formula i called harmonic mean.</p>
<span class="math display">\[F1\ Score= \frac{2*Precision*Recall}{Recall+Precision}\]</span>
In therms of the confusion matrix, it would be the blue vector against the grey one.<br><div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-28"></span>
<img src="images/cm6.jpg" alt="Confusion matrix." width="40%"><p class="caption">
Figure 3.4: Confusion matrix.
</p>
</div>
<p>A model will have a high F1 score if both precision and recall are high. However, a model will have a low F1 score if one factor is low, even if the other is 100 percent <span class="citation">(<a href="clustering.html#ref-c3" role="doc-biblioref">Krishnan 2020</a>)</span>. In our example, the F1 Score is:</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="va">sen</span><span class="op">*</span><span class="va">pre_v</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="va">sen</span><span class="op">+</span><span class="va">pre_v</span><span class="op">)</span>,<span class="fl">4</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.9386</span></span></code></pre></div>
</div>
<div id="the-specificity-true-negative-rate-measures-the-proportion-of-negatives-that-were-correctly-classified" class="section level3" number="3.2.5">
<h3>
<span class="header-section-number">3.2.5</span> The <strong>specificity</strong> (true negative rate) measures the proportion of negatives that were correctly classified:<a class="anchor" aria-label="anchor" href="#the-specificity-true-negative-rate-measures-the-proportion-of-negatives-that-were-correctly-classified"><i class="fas fa-link"></i></a>
</h3>
<p><span class="math display">\[ specificity =\frac{TN}{TN+FP}\]</span></p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">confu</span><span class="op">$</span><span class="va">byClass</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="co">#&gt; Specificity </span></span>
<span><span class="co">#&gt;   0.8928571</span></span></code></pre></div>
<p>The latter implies that only 95.92% of the time, we are predicting well the class “Fully Paid.</p>
</div>
<div id="kappa" class="section level3" number="3.2.6">
<h3>
<span class="header-section-number">3.2.6</span> kappa<a class="anchor" aria-label="anchor" href="#kappa"><i class="fas fa-link"></i></a>
</h3>
<p>Adjusts accuracy by taking into account the class imbalance, which refers to the trouble associated with data having a large majority of records belonging to a single class. The kappa statistic adjust for data sets with severe class imbalance because a classifier can obtain high accuracy simply by always guessing the most frequent class <span class="citation">(<a href="clustering.html#ref-Lantz" role="doc-biblioref">Lantz 2019</a>)</span>. It call agreement to the actual proportions of the the classes.</p>
<pre><code>Poor agreement = less than 0.20
Fair agreement = 0.20 to 0.40
Moderate agreement = 0.40 to 0.60
Good agreement = 0.60 to 0.80
Very good agreement = 0.80 to 1.00</code></pre>
<p><span class="math display">\[\kappa=\frac{Pr(a)-Pr(e)}{1-Pr(e)} \]</span>
Where Pr(a) is the proportion of the actual agreement and Pr(e) refers to the expected agreement between the classifier and the true values, under the assumption that they were chosen at random</p>
</div>
<div id="the-roc-curve" class="section level3" number="3.2.7">
<h3>
<span class="header-section-number">3.2.7</span> The <strong>ROC Curve</strong><a class="anchor" aria-label="anchor" href="#the-roc-curve"><i class="fas fa-link"></i></a>
</h3>
<p>The receiver operating characteristic (ROC) looks to do a similar balance, such as the Precision/Recall, but between the Recall and the false positive rate (FPR). It focus on the total</p>
<p><span class="math display">\[false\_positive\_rate (FPR)=(1-Specificity)= \frac{FP}{FP+TN}\]</span></p>
<p>In therms of the confusion matrix, it would be the blue vector against the grey one. The proportion TP, well positive predicted, of the positive total in the reference against the proportion of FP, bad positive predicted, of the negative total in the reference.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-32"></span>
<img src="images/cm5.jpg" alt="Confusion matrix." width="40%"><p class="caption">
Figure 3.5: Confusion matrix.
</p>
</div>
<p>We use the function “roc” of the “pROC” library <span class="citation">(<a href="clustering.html#ref-Roc" role="doc-biblioref">Robin et al. 2011</a>)</span>.<br>
The first argument is the reference (or the “response”) and the second one is the prediction(“predictor”), in probablity.</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://expasy.org/tools/pROC/">pROC</a></span><span class="op">)</span></span>
<span><span class="va">ref</span><span class="op">&lt;-</span> <span class="va">credit_test</span><span class="op">[</span>,<span class="st">"Default"</span><span class="op">]</span></span>
<span><span class="va">predict_glm</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">credit_model</span>, newdata<span class="op">=</span><span class="va">credit_test</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">predict_glm</span><span class="op">)</span></span>
<span><span class="co">#&gt;           15           19           24           26           32           34 </span></span>
<span><span class="co">#&gt; 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16 2.220446e-16</span></span></code></pre></div>
<p>Also we need to add the levels:</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">ref</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "default"    "No_default"</span></span></code></pre></div>
<p>Here we apply the function:</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">roc0</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/pROC/man/roc.html">roc</a></span><span class="op">(</span><span class="va">ref</span>, <span class="va">predict_glm</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">ref</span><span class="op">)</span><span class="op">)</span>,ret<span class="op">=</span><span class="st">"coords"</span><span class="op">)</span> </span>
<span><span class="va">roc0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; roc.default(response = ref, predictor = predict_glm, levels = rev(levels(ref)),     ret = "coords")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Data: predict_glm in 28 controls (ref No_default) &gt; 147 cases (ref default).</span></span>
<span><span class="co">#&gt; Area under the curve: 0.982</span></span></code></pre></div>
<p>In the reults, the message direction is comparing the group where the median is higher and take the direction accordingly. It is used to generates some Sensitivities and specificity’s given some probabilities (Thresholds). Remember that in previous chunk we trasnform the prediction, in porbability, into labels c(“Fully Paid”,“Charged Off”), and we used the a code like this:</p>
<p>ifelse(credit_predict&gt;.5,“Fully Paid”,“Charged Off”). In that example, we arbitrarily selected Thresholds of 0.5. The function generates several thresholds considering the means between any two consecutive values observed in the data. In our example it generated 17 thresholds, then it estimate 17 sensitibities and `specificity’s.</p>
<p>print.thres.pattern=“thresholds: %.3f : %.3f : %.3f”)</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># This function prints the ROC Curve. </span></span>
<span><span class="co"># roc0  is a object type "roc"</span></span>
<span><span class="co"># p is a vector of probabilities </span></span>
<span><span class="co"># best is a method to estimate the best model (see an expination below)</span></span>
<span><span class="va">My_roc</span><span class="op">&lt;-</span><span class="kw">function</span><span class="op">(</span><span class="va">roc0</span>,<span class="va">best</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"FALSE"</span>,<span class="st">"youden"</span>,<span class="st">"closest.topleft"</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">{</span></span>
<span>  <span class="va">yl</span><span class="op">&lt;-</span><span class="st">"Recall or sensitivity"</span></span>
<span>  <span class="va">xl</span><span class="op">&lt;-</span><span class="st">"False pos or (1-specificity)"</span></span>
<span>  <span class="va">pat</span><span class="op">&lt;-</span><span class="st">"thresholds: %.3f \n\nSp: %.3f \nSens: %.3f"</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">best</span><span class="op">==</span><span class="cn">F</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">roc0</span>,print.auc<span class="op">=</span><span class="cn">TRUE</span>, ylab<span class="op">=</span><span class="va">yl</span>, xlab<span class="op">=</span><span class="va">xl</span>,auc.polygon<span class="op">=</span><span class="cn">TRUE</span>, </span>
<span>         </span>
<span>         legacy.axes<span class="op">=</span><span class="cn">T</span>,</span>
<span>         auc.polygon.col<span class="op">=</span><span class="st">"lightblue"</span>,</span>
<span>         print.thres <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.5</span><span class="op">)</span>,</span>
<span>         print.thres.pattern<span class="op">=</span><span class="va">pat</span>,</span>
<span>         max.auc.polygon<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>         print.thres.pch<span class="op">=</span><span class="fl">16</span><span class="op">)</span></span>
<span>     </span>
<span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="kw">if</span> <span class="op">(</span><span class="va">best</span><span class="op">==</span><span class="st">"youden"</span><span class="op">)</span> <span class="op">{</span>  </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">roc0</span>,  ylab<span class="op">=</span><span class="va">yl</span>, xlab<span class="op">=</span><span class="va">xl</span>, print.thres<span class="op">=</span><span class="st">"best"</span>, print.thres.best.method<span class="op">=</span><span class="st">"youden"</span>, </span>
<span>         legacy.axes<span class="op">=</span><span class="cn">TRUE</span>, </span>
<span>         print.auc<span class="op">=</span><span class="cn">TRUE</span>, auc.polygon<span class="op">=</span><span class="cn">TRUE</span>,auc.polygon.col<span class="op">=</span><span class="st">"lightblue"</span>,</span>
<span>         print.thres.cex <span class="op">=</span> <span class="fl">.9</span> ,print.thres.pattern<span class="op">=</span><span class="va">pat</span>,max.auc.polygon<span class="op">=</span><span class="cn">TRUE</span>,print.thres.pch<span class="op">=</span><span class="fl">16</span><span class="op">)</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="kw">if</span> <span class="op">(</span><span class="va">best</span><span class="op">==</span><span class="st">"closest.topleft"</span><span class="op">)</span>  <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">roc0</span>,  ylab<span class="op">=</span><span class="va">yl</span>, xlab<span class="op">=</span><span class="va">xl</span>, print.thres<span class="op">=</span><span class="st">"best"</span>, </span>
<span>         legacy.axes<span class="op">=</span><span class="cn">TRUE</span>, </span>
<span>         print.thres.best.method<span class="op">=</span><span class="st">"closest.topleft"</span>,print.auc<span class="op">=</span><span class="cn">TRUE</span>,</span>
<span>         auc.polygon<span class="op">=</span><span class="cn">TRUE</span>,auc.polygon.col<span class="op">=</span><span class="st">"lightblue"</span>,</span>
<span>         print.thres.cex <span class="op">=</span> <span class="fl">.9</span>,</span>
<span>         print.thres.pattern<span class="op">=</span><span class="va">pat</span>,max.auc.polygon<span class="op">=</span><span class="cn">TRUE</span>,print.thres.pch<span class="op">=</span><span class="fl">16</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu">My_roc</span><span class="op">(</span><span class="va">roc0</span>,best<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-train_clasification_files/figure-html/unnamed-chunk-37-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Best = “T” argument controls how the optimal threshold is determined.</p>
<p>The “youden” Youden’s J statistic (Youden, 1950) is employed. The optimal cut-off is the threshold that maximizes the distance to the identity (diagonal) line. Can be shortened to “y”. The optimality criterion is:</p>
<p><span class="math display">\[max(sensitivities + specificities)\]</span></p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">My_roc</span><span class="op">(</span><span class="va">roc0</span>,best<span class="op">=</span><span class="st">"youden"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-train_clasification_files/figure-html/unnamed-chunk-38-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>The “closest.topleft” The optimal threshold is the point closest to the top-left part of the plot with perfect sensitivity or specificity. Can be shortened to “c” or “t”.
The optimality criterion is <span class="citation">(<a href="clustering.html#ref-Roc" role="doc-biblioref">Robin et al. 2011</a>)</span>:</p>
<p><span class="math display">\[min((1-sensitivities)^2 + (1-specificities)^2)\]</span></p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">My_roc</span><span class="op">(</span><span class="va">roc0</span>,best<span class="op">=</span><span class="st">"closest.topleft"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="03-train_clasification_files/figure-html/unnamed-chunk-39-1.png" width="90%" style="display: block; margin: auto;"></div>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="training-and-evaluating-regression-models.html"><span class="header-section-number">2</span> Training and evaluating regression models</a></div>
<div class="next"><a href="cross-validation.html"><span class="header-section-number">4</span> Cross Validation</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#training-and-evaluating-classification-models"><span class="header-section-number">3</span> Training and evaluating classification models</a></li>
<li><a class="nav-link" href="#logit-model"><span class="header-section-number">3.1</span> Logit model</a></li>
<li>
<a class="nav-link" href="#performance-measure-in-clasification"><span class="header-section-number">3.2</span> Performance Measure in clasification</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-accuracy"><span class="header-section-number">3.2.1</span> The accuracy:</a></li>
<li><a class="nav-link" href="#the-sensitivity-or-recall-also-called-the-true-positive-rate"><span class="header-section-number">3.2.2</span> The sensitivity or Recall (also called the true positive rate)</a></li>
<li><a class="nav-link" href="#precision-or-positive-predicted-values"><span class="header-section-number">3.2.3</span> Precision or Positive Predicted Values</a></li>
<li><a class="nav-link" href="#the-f1-score"><span class="header-section-number">3.2.4</span> The F1 Score</a></li>
<li><a class="nav-link" href="#the-specificity-true-negative-rate-measures-the-proportion-of-negatives-that-were-correctly-classified"><span class="header-section-number">3.2.5</span> The specificity (true negative rate) measures the proportion of negatives that were correctly classified:</a></li>
<li><a class="nav-link" href="#kappa"><span class="header-section-number">3.2.6</span> kappa</a></li>
<li><a class="nav-link" href="#the-roc-curve"><span class="header-section-number">3.2.7</span> The ROC Curve</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Machine learning introductory guide</strong>" was written by L. Arturo Bernal. It was last built on 2023-03-27.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
