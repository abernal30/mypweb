<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 4 Prepare the Data for Machine Learning Algorithms | Machine learning introductory guide in R. v.1.2</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="4 4 Prepare the Data for Machine Learning Algorithms | Machine learning introductory guide in R. v.1.2" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 4 Prepare the Data for Machine Learning Algorithms | Machine learning introductory guide in R. v.1.2" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Arturo Bernal" />


<meta name="date" content="2022-03-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="discover-and-visualize-the-data-to-gain-insights.html"/>
<link rel="next" href="select-and-train-and-evaluate-the-model.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="big-picture.html"><a href="big-picture.html"><i class="fa fa-check"></i><b>1</b> Big picture<span></span></a>
<ul>
<li class="chapter" data-level="1.1" data-path="big-picture.html"><a href="big-picture.html#frame-the-problem"><i class="fa fa-check"></i><b>1.1</b> Frame the Problem<span></span></a></li>
<li class="chapter" data-level="1.2" data-path="big-picture.html"><a href="big-picture.html#select-a-performance-measure"><i class="fa fa-check"></i><b>1.2</b> Select a Performance Measure<span></span></a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="big-picture.html"><a href="big-picture.html#for-continuous-variables"><i class="fa fa-check"></i><b>1.2.1</b> For continuous variables<span></span></a></li>
<li class="chapter" data-level="1.2.2" data-path="big-picture.html"><a href="big-picture.html#for-categorical-variables-classification-methods"><i class="fa fa-check"></i><b>1.2.2</b> For categorical variables (classification methods)<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-collection.html"><a href="data-collection.html"><i class="fa fa-check"></i><b>2</b> Data collection<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-collection.html"><a href="data-collection.html#take-a-quick-look-at-the-data-structure"><i class="fa fa-check"></i><b>2.1</b> Take a Quick Look at the Data Structure<span></span></a></li>
<li class="chapter" data-level="2.2" data-path="data-collection.html"><a href="data-collection.html#create-the-training-and-test-set"><i class="fa fa-check"></i><b>2.2</b> Create the training and Test Set<span></span></a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="data-collection.html"><a href="data-collection.html#for-cros-sectional-data-or-no-time-series"><i class="fa fa-check"></i><b>2.2.1</b> For cros sectional data or no time series<span></span></a></li>
<li class="chapter" data-level="2.2.2" data-path="data-collection.html"><a href="data-collection.html#for-time-series"><i class="fa fa-check"></i><b>2.2.2</b> For time series<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="discover-and-visualize-the-data-to-gain-insights.html"><a href="discover-and-visualize-the-data-to-gain-insights.html"><i class="fa fa-check"></i><b>3</b> 3 Discover and Visualize the Data to Gain Insights<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="discover-and-visualize-the-data-to-gain-insights.html"><a href="discover-and-visualize-the-data-to-gain-insights.html#looking-for-relationships-among-features-and-correlations"><i class="fa fa-check"></i><b>3.1</b> Looking for relationships among features and Correlations<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="discover-and-visualize-the-data-to-gain-insights.html"><a href="discover-and-visualize-the-data-to-gain-insights.html#experimenting-with-attribute-combinations"><i class="fa fa-check"></i><b>3.2</b> Experimenting with Attribute Combinations<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="prepare-the-data-for-machine-learning-algorithms.html"><a href="prepare-the-data-for-machine-learning-algorithms.html"><i class="fa fa-check"></i><b>4</b> 4 Prepare the Data for Machine Learning Algorithms<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="prepare-the-data-for-machine-learning-algorithms.html"><a href="prepare-the-data-for-machine-learning-algorithms.html#data-cleaning"><i class="fa fa-check"></i><b>4.1</b> Data Cleaning<span></span></a></li>
<li class="chapter" data-level="4.2" data-path="prepare-the-data-for-machine-learning-algorithms.html"><a href="prepare-the-data-for-machine-learning-algorithms.html#missing-values"><i class="fa fa-check"></i><b>4.2</b> Missing values<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="prepare-the-data-for-machine-learning-algorithms.html"><a href="prepare-the-data-for-machine-learning-algorithms.html#handling-text-and-categorical-attributes"><i class="fa fa-check"></i><b>4.3</b> Handling Text and Categorical Attributes<span></span></a></li>
<li class="chapter" data-level="4.4" data-path="prepare-the-data-for-machine-learning-algorithms.html"><a href="prepare-the-data-for-machine-learning-algorithms.html#feature-scaling"><i class="fa fa-check"></i><b>4.4</b> Feature Scaling<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="select-and-train-and-evaluate-the-model.html"><a href="select-and-train-and-evaluate-the-model.html"><i class="fa fa-check"></i><b>5</b> 5 Select and Train and evaluate the Model<span></span></a>
<ul>
<li class="chapter" data-level="5.1" data-path="select-and-train-and-evaluate-the-model.html"><a href="select-and-train-and-evaluate-the-model.html#for-continuous-variables-1"><i class="fa fa-check"></i><b>5.1</b> For continuous variables<span></span></a></li>
<li class="chapter" data-level="5.2" data-path="select-and-train-and-evaluate-the-model.html"><a href="select-and-train-and-evaluate-the-model.html#select-the-model-for-categorical-variables"><i class="fa fa-check"></i><b>5.2</b> Select the model for categorical variables<span></span></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="select-and-train-and-evaluate-the-model.html"><a href="select-and-train-and-evaluate-the-model.html#clasification-models"><i class="fa fa-check"></i><b>5.2.1</b> Clasification models<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="select-and-train-and-evaluate-the-model.html"><a href="select-and-train-and-evaluate-the-model.html#training-and-evaluating-on-the-training-set"><i class="fa fa-check"></i><b>5.2.2</b> Training and Evaluating on the Training Set<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="select-and-train-and-evaluate-the-model.html"><a href="select-and-train-and-evaluate-the-model.html#resampling-cross-validation"><i class="fa fa-check"></i><b>5.3</b> Resampling (cross-validation)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="fine-tune-or-tune-the-ml-model.html"><a href="fine-tune-or-tune-the-ml-model.html"><i class="fa fa-check"></i><b>6</b> 6 Fine-Tune or Tune the ML Model<span></span></a>
<ul>
<li class="chapter" data-level="6.1" data-path="fine-tune-or-tune-the-ml-model.html"><a href="fine-tune-or-tune-the-ml-model.html#analyze-the-best-models-and-their-errors"><i class="fa fa-check"></i><b>6.1</b> Analyze the Best Models and Their Errors<span></span></a></li>
<li class="chapter" data-level="6.2" data-path="fine-tune-or-tune-the-ml-model.html"><a href="fine-tune-or-tune-the-ml-model.html#evaluate-your-system-on-the-test-set"><i class="fa fa-check"></i><b>6.2</b> Evaluate Your System on the Test Set<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References<span></span></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine learning introductory guide in R. v.1.2</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prepare-the-data-for-machine-learning-algorithms" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> 4 Prepare the Data for Machine Learning Algorithms<a href="prepare-the-data-for-machine-learning-algorithms.html#prepare-the-data-for-machine-learning-algorithms" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="data-cleaning" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Data Cleaning<a href="prepare-the-data-for-machine-learning-algorithms.html#data-cleaning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Common data quality issues:</p>
<ol style="list-style-type: lower-roman">
<li>There might be missing or erroneous values in the data set</li>
<li>There might be categorical (Textual, Boolean) values in the data set and not all algorithms work well with textual values.</li>
<li>Some features might have larger values than others and are required to be transformed for equal importance.</li>
</ol>
</div>
<div id="missing-values" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Missing values<a href="prepare-the-data-for-machine-learning-algorithms.html#missing-values" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Most Machine Learning algorithms cannot work with missing values, so analyze the best way to deal white them. We saw earlier that the total_bedrooms attribute has some missing values, so let’s fix this. You have, at least, three options:</p>
<ol style="list-style-type: lower-roman">
<li>Get rid of the corresponding districts (rows).</li>
<li>Get rid of the whole attribute (column).</li>
<li>Set the values to some value (zero, the mean, the median, etc.).</li>
</ol>
</div>
<div id="handling-text-and-categorical-attributes" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Handling Text and Categorical Attributes<a href="prepare-the-data-for-machine-learning-algorithms.html#handling-text-and-categorical-attributes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There might be missing or erroneous values in the data set
There might be categorical (Textual, Boolean) values in the data set and not all algorithms work well with textual values.
Some features might have larger values than others and are required to be transformed for equal importance.</p>
<p>If you run a regression including ocean_proximity, you will notice that the regression estimates a coefficient by each category of the variable ocean_proximity. When applying Machine Learning ML for forecasting pourpuses, is more convenient to transform the categorical . We need only one coefficient associated with the variable ocean_proximity. Then we need to transform the variable into numeric.</p>
<p>According to Jame et al. (2017), the expected test of the MSE, for a given value of x(0), can be decomposed into the sum of three fundamental quantities:</p>
<p><span class="math display">\[E (y_{0}-\hat{f(x_{0}))^{2}}= Var(\hat{f(x_{0}))}+[Bias\ \hat{f(x_{0}))}]^2+Var[\epsilon] \]</span>
where <span class="math inline">\(E (y_{0}-\hat{f(x_{0}))^{2}}\)</span> is the expected test MSE. It has the meaning of the expected average test MSE that we would obtain if we repeatedly estimated test MSE <em>f</em> using a large number of training sets, and tested at x0. The overall expected test MSE can be computed by averaging.</p>
<p>Variance refers to the amount by which <span class="math inline">\(\hat{f}\)</span> would change if we estimated it using a different training data set. Since the training data are used to fit the statistical learning method, different training data sets will result in a different <span class="math inline">\(\hat{f}\)</span>.</p>
<p>On the other hand, bias refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model.For example, linear regression assumes that there is a linear relationship between Y and X1,X2, . . . , Xp. It is unlikely that any real-life problem truly has such a simple linear relationship, and so performing linear regression will undoubtedly result in some bias in the estimate of <em>f</em>.</p>
<p>Finally, <span class="math inline">\(\epsilon\)</span> is the error term.</p>
<p>When the number of observations, n, is much larger than the number of independent variables, <em>x</em>, then the least squares estimates tend to also have low variance, <span class="math inline">\(Var(\hat{f(x_{0}))}\)</span>, and consequently reducing expected test of the MSE, <span class="math inline">\(E (y_{0}-\hat{f(x_{0}))^{2}}\)</span>, improving the accuracy. However, the more the number of <em>x</em>, relative to the number of observations, the then there can be a lot of variability in the least squares fit, resulting in overfitting and consequently poor predictions on future observations not used in model training. In terms of the equation</p>
<p><span class="math display">\[\\begin{equation} \label{eq1}
Var(\hat{f(x_{i})}) &amp;=\Var(\hat{\beta_{0}}+\hat{\beta_{1}}x_{1}+,..,+\hat{\beta_{n}}x_{n}) &amp;\\
\end{equation}\]</span></p>
<p>Then, the more parameters would be estimated, the biger the variance would be, and</p>
<p>When do we not apply when we are applying Ordinary Least Squares OLS looking for a causality, or trying to explain the dependent variable,</p>
<p>When you looked at the top five rows, you probably noticed that the values in the ocean_proximity column were repetitive, which means that it is probably a categorical attribute. You can find out what categories exist and how many districts belong to each category applying the duplicated function:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="prepare-the-data-for-machine-learning-algorithms.html#cb24-1" aria-hidden="true" tabindex="-1"></a>col<span class="ot">=</span><span class="st">&quot;ocean_proximity&quot;</span></span>
<span id="cb24-2"><a href="prepare-the-data-for-machine-learning-algorithms.html#cb24-2" aria-hidden="true" tabindex="-1"></a>house_train[,col][<span class="sc">!</span><span class="fu">duplicated</span>(house_train[,col])]</span></code></pre></div>
<pre><code>## [1] &quot;INLAND&quot;     &quot;NEAR BAY&quot;   &quot;NEAR OCEAN&quot; &quot;&lt;1H OCEAN&quot;  &quot;ISLAND&quot;</code></pre>
<p>If you run a regression including ocean_proximity, you will notice that the regression estimates a coefficient by each category of the variable ocean_proximity. When applying Machine Learning ML for forecasting pourpuses, is more convenient to transform the categorical . We need only one coefficient associated with the variable ocean_proximity. Then we need to transform the variable into numeric.</p>
<p>When do we not apply when we are applying Ordinary Least Squares OLS looking for a causality, or trying to explain the dependent variable,</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="prepare-the-data-for-machine-learning-algorithms.html#cb26-1" aria-hidden="true" tabindex="-1"></a>dep<span class="ot">&lt;-</span><span class="st">&quot;median_house_value&quot;</span></span>
<span id="cb26-2"><a href="prepare-the-data-for-machine-learning-algorithms.html#cb26-2" aria-hidden="true" tabindex="-1"></a>model<span class="ot">&lt;-</span><span class="fu">lm</span>(median_house_value<span class="sc">~</span>.,<span class="at">data=</span>house_train)</span>
<span id="cb26-3"><a href="prepare-the-data-for-machine-learning-algorithms.html#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = median_house_value ~ ., data = house_train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -571827  -41816  -10045   28437  802528 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               -2.402e+06  9.871e+04 -24.335  &lt; 2e-16 ***
## longitude                 -2.739e+04  1.141e+03 -24.001  &lt; 2e-16 ***
## latitude                  -2.601e+04  1.128e+03 -23.063  &lt; 2e-16 ***
## housing_median_age         1.071e+03  4.879e+01  21.961  &lt; 2e-16 ***
## total_rooms                1.310e+00  1.030e+00   1.272  0.20339    
## total_bedrooms             2.261e+01  8.874e+00   2.547  0.01086 *  
## population                -3.964e+01  1.219e+00 -32.523  &lt; 2e-16 ***
## households                 9.863e+01  9.362e+00  10.535  &lt; 2e-16 ***
## median_income              4.160e+04  4.179e+02  99.547  &lt; 2e-16 ***
## ocean_proximityINLAND     -3.416e+04  1.950e+03 -17.513  &lt; 2e-16 ***
## ocean_proximityISLAND      2.296e+05  4.814e+04   4.768 1.87e-06 ***
## ocean_proximityNEAR BAY   -3.736e+03  2.124e+03  -1.759  0.07863 .  
## ocean_proximityNEAR OCEAN  4.583e+03  1.743e+03   2.629  0.00856 ** 
## rooms_per_household        2.591e+03  3.159e+02   8.201 2.56e-16 ***
## bedrooms_per_room          2.658e+05  1.522e+04  17.462  &lt; 2e-16 ***
## population_per_household   6.717e+01  4.727e+01   1.421  0.15532    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 68040 on 16329 degrees of freedom
##   (167 observations deleted due to missingness)
## Multiple R-squared:  0.6541, Adjusted R-squared:  0.6538 
## F-statistic:  2059 on 15 and 16329 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>For this case, the objective is to make a forecast, so is convenient to transform the categorical values into numeric.</p>
</div>
<div id="feature-scaling" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Feature Scaling<a href="prepare-the-data-for-machine-learning-algorithms.html#feature-scaling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One of the most important transformations you need to apply to your data is feature scaling. With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales. This is the case for the housing data: the total number of rooms ranges from about 6 to 39,320, while the median incomes only range from 0 to 15. Note that scaling the target values (y, dependent variable) is generally not required.</p>
<p>There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.</p>
<p>Min-max scaling (many people call this normalization) is the simplest: values are shifted and rescaled so that they end up ranging from 0 to 1. We do this by subtracting the min value and dividing by the max minus the min.</p>
<p>Standardization. first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="discover-and-visualize-the-data-to-gain-insights.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="select-and-train-and-evaluate-the-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": false,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
